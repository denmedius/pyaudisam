{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Auto table of contents -->\n",
    "<h1 class='tocIgnore'>Visionature : Préparation données points d'écoute printaniers pour le DS</h1>\n",
    "<ul>\n",
    "  <li>à partir des traces GPS,</li>\n",
    "  <li>présentes dans les formulaires à partir Naturalist V0.128 (ou beta mai 2019),</li>\n",
    "  <li>à condition de cocher la case \"Enregistrer ma trace\" en début de formulaire,</li>\n",
    "  <li>via l'export Excel exclusivement\n",
    "      (pas encore d'API pour ça, et absent des exports XML, JSON, KML, CSV en décembre 2019),</li>\n",
    "  <li>avec la colonne \"trace\" sélectionnée dans l'export,</li>\n",
    "  <li>uniquement via Faune-France (pas dispo. via les sites régionaux).</li>\n",
    "</ul>\n",
    "<div style=\"overflow-y: auto\">\n",
    "  <h2 class='tocIgnore'>Table des matières</h2>\n",
    "  <div id=\"toc\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pathlib as pl\n",
    "import datetime as dt\n",
    "from lxml import etree\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import folium\n",
    "import folium.plugins\n",
    "\n",
    "import pyproj\n",
    "from shapely import geometry\n",
    "\n",
    "#import overpy\n",
    "import geojson\n",
    "import osm2geojson as o2g\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict as odict\n",
    "import json\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import autods as ads\n",
    "import visionat as vsn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration.\n",
    "ads.logger('ads', level=ads.INFO, handlers=[sys.stdout, 'tmp/vndon.log'], verbose=True)\n",
    "#ads.logger('ads.eng', level=ads.INFO)\n",
    "#ads.logger('ads.opn', level=ads.DEBUG)\n",
    "#ads.logger('ads.opr', level=ads.DEBUG)\n",
    "\n",
    "ads.logger('visionat', level=ads.INFO, handlers=[sys.stdout, 'tmp/vndon.log'], verbose=True)\n",
    "\n",
    "logger = ads.logger('vndon', level=ads.DEBUG, handlers=[sys.stdout, 'tmp/vndon.log'], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Chargement des données (issues d'exports de Faune-France)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paramètres d'import / filtrage (fichier, observateur, commentaire liste, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par défaut.\n",
    "feuille = 0\n",
    "source = 'FA' # Faune-Auvergne\n",
    "ignorerLignes = []\n",
    "renommerCols = None\n",
    "titreCarte = None\n",
    "\n",
    "colLongTrace = None\n",
    "avecTraces = False\n",
    "garderCols = ['ID liste', 'Liste complète ?', 'Commentaire de la liste',\n",
    "              'Date', 'Ref', 'Horaire', 'Lieu-dit', 'Commune', 'Nom latin',\n",
    "              'Estimation', 'Nombre', 'Détails', 'Code atlas',\n",
    "              'Lat (WGS84)', 'Lon (WGS84)', 'UTM X [m]', 'UTM Y [m]', 'Remarque', 'Trace']\n",
    "garderAutreCols = []\n",
    "calculerCols = dict()\n",
    "\n",
    "groupage = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZPS Crêtes du Cantal 2020 (Mathis Vérité)\n",
    "dossier = 'donnees/cretes-cantal'\n",
    "ficSrcVN = [dossier+'/Export PE Monts du Cantal - nettoyé.xlsx']\n",
    "source = 'FF' # Faune-France\n",
    "nomEtude = 'CretesPlombCantalZPS2020'\n",
    "titreCarte = 'ZPS Crêtes et Plomb du Cantal 2020'\n",
    "ignorerLignes = [0]\n",
    "avecTraces = True\n",
    "\n",
    "def numeroPoint(sObs):\n",
    "    return int(re.compile('PE\\s+(\\d+)\\s+').match(sObs['Commentaire de la liste']).group(1))\n",
    "calculerCols = {'Num Point': numeroPoint}\n",
    "garderAutreCols = ['Num Point']\n",
    "\n",
    "dZoneEtude = dict(Zone='ZPS Cretes Plomb Cantal', Surface=6416) # ha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert source in ['FA', 'FF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sightCountsParser = vsn.SexCatSightingCountsParser(atlasCodex='EBCC' if source == 'FF' else ''\n",
    "                                                   categoryCols=['nMalAd', 'nAutAd', 'nJuv', 'nVol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not renommerCols:\n",
    "    renommerCols = dict()\n",
    "if source == 'FF':\n",
    "    renommerCols['Nom scientifique'] = 'Nom latin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds = vsn.VisionatureDataSet(ficSrcVN, sheet=feuille, skipRows=ignorerLignes,\n",
    "                              dRenameCols=renommerCols, dComputeCols=calculerCols, \n",
    "                              keepCols=garderCols, listExtraCols=garderAutreCols,\n",
    "                              listsHaveTrace=avecTraces, listTraceLengthCol=colLongTrace,\n",
    "                              sightCountsParser=sightCountsParser,\n",
    "                              sightDistComperClass=vsn.PointTransectSightingDistanceComputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vnds.toExcel('tmp/sample.xlsx', subset=['Lat (WGS84)', 'Lon (WGS84)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Filtrage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Examen / correction des traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ZPS Crêtes et Plomb du Cantal\n",
    "\n",
    "(traces Naturalist + 3 manquantes lues dans KML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Les traces Naturalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTraces = vnds.listTraces()\n",
    "dfTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfTraces['ID liste'].unique(), dfTraces['ID liste'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} traces manquantes ... mais voir ci-dessous !'.format(len(vnds.lists()) - dfTraces['ID liste'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Les points sans trace (par oubli), via KML complémentaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmlRoot = etree.ElementTree().parse('donnees/cretes-cantal/Traces manquantes.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterPlacemarks(kmlDoc, kmlNameSpaces):\n",
    "    for pm in kmlDoc.findall('kml:Document/kml:Folder/kml:Placemark', namespaces=kmlNameSpaces):\n",
    "        name = pm.find('kml:ExtendedData/kml:SchemaData/kml:SimpleData', namespaces=kmlNameSpaces).text\n",
    "        long, lat = pm.find('kml:Point/kml:coordinates', namespaces=kmlNameSpaces).text.split(',')\n",
    "        yield {'Num Point': int(name), 'lon':float(long), 'lat':float(lat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPointsManq = pd.DataFrame(data=list(iterPlacemarks(kmlRoot, vsn.KKmlNameSpaces)))\n",
    "dfPointsManq.set_index('Num Point', inplace=True)\n",
    "dfPointsManq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Les 'ID liste' associés au numéros de point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNumPoint2IdList = vnds.lists()[['ID liste', 'Num Point']].drop_duplicates().set_index('Num Point')\n",
    "dfNumPoint2IdList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPointsManq = dfPointsManq.join(dfNumPoint2IdList)\n",
    "dfPointsManq['ptIndx'] = 0\n",
    "dfPointsManq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Remplacer les traces manquantes avec ces points complémentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.setListTraces(dfPointsManq)\n",
    "dfTraces = vnds.listTraces()\n",
    "dfTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfTraces['ID liste'].unique(), dfTraces['ID liste'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Amélioration des traces : réduction au point moyen (outliers exclus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.improveTraces(keepPtsPct=70, maxMltStd=1.0)\n",
    "\n",
    "vnds.listTraces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f. Les points prévus à l'origine (théoriques), via KML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmlRoot = etree.ElementTree().parse('donnees/cretes-cantal/POINTS_ECOUTE.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoints = pd.DataFrame(data=list(iterPlacemarks(kmlRoot, vsn.KKmlNameSpaces)))\n",
    "dfPoints.set_index('Num Point', inplace=True)\n",
    "dfPoints = dfPoints.join(dfNumPoint2IdList)\n",
    "dfPoints['ptIndx'] = 0\n",
    "dfPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Limites géographiques à superposer sur la carte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ZPS Crêtes et Plomb du Cantal\n",
    "\n",
    "(polygones des limites de la zone d'étude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmlRoot = etree.ElementTree().parse('donnees/cretes-cantal/LIMITES_ZPS_ETENDUE.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterPolygons(kmlDoc, kmlNameSpaces):\n",
    "    polyInd = 0\n",
    "    for polyCoords in kmlDoc.findall('kml:Document/kml:Folder/kml:Placemark/kml:MultiGeometry/'\n",
    "                                     'kml:Polygon/kml:outerBoundaryIs/kml:LinearRing/kml:coordinates',\n",
    "                                     namespaces=kmlNameSpaces):\n",
    "        polyCoords = polyCoords.text\n",
    "        dfPoly = pd.DataFrame(data=[[float(v) for v in point.split(',')] for point in polyCoords.split(' ')],\n",
    "                              columns=['long', 'lat'])\n",
    "        yield dfPoly\n",
    "        polyInd += 1\n",
    "\n",
    "gjZone = geojson.MultiPolygon([([tuple(nt)[1:] for nt in dfPoly.itertuples()],)\n",
    "                               for dfPoly in iterPolygons(kmlRoot, vsn.KKmlNameSpaces)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry.MultiPolygon()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Décodage des effectifs comptés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.computeSightingCounts()\n",
    "\n",
    "vnds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData[['ID liste', 'Horaire', 'Date', 'Nom latin',\n",
    "             'Nombre', 'Détails', 'Code atlas', 'nMalAd', 'nAutAd', 'nJuv', 'nVol']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs = vnds.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison globale Détails et Nombre * Code Atlas\n",
    "dfObs[['nMalAd', 'nAutAd', 'nJuv', 'nVol']].sum().sum(), dfObs['Nombre'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les données avec Détails et Nombre * Code Atlas incohérents\n",
    "dfObs.loc[dfObs['Nombre'] != dfObs[['nMalAd', 'nAutAd', 'nJuv', 'nVol']].sum(axis='columns'),\n",
    "          ['ID liste', 'Horaire', 'Date', 'Nom latin',\n",
    "           'Nombre', 'Détails', 'Code atlas', 'nMalAd', 'nAutAd', 'nJuv', 'nVol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.toExcel('tmp/after.xlsx') # => Vérifier à l'oeil les effectifs de détail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData['Détails'].fillna('').str.contains('vol').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData.loc[vnds.dfData['Détails'].fillna('').str.contains('vol'),\n",
    "                ['ID liste', 'Horaire', 'Date', 'Nom latin',\n",
    "                 'Nombre', 'Détails', 'Code atlas', 'nMalAd', 'nAutAd', 'nJuv', 'nVol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData.loc[vnds.dfData['Code atlas'] == 2,\n",
    "                ['ID liste', 'Horaire', 'Date', 'Nom latin',\n",
    "                 'Nombre', 'Détails', 'Code atlas', 'nMalAd', 'nAutAd', 'nJuv', 'nVol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Calcul des distances observateur - oiseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.computeTraceSightDistances(distanceCol='Distance')\n",
    "\n",
    "vnds.dfData[['ID liste', 'Horaire', 'Date', 'Nom latin',\n",
    "             'Nombre', 'Détails', 'Code atlas', 'nMalAd', 'nAutAd', 'nJuv', 'nVol', 'Distance']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(vnds.dfData.Distance, bins=10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vnds.dfData.Distance.hist(figsize=(16, 4), bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Cartographie des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sight2String(sSight, fmt='{date} {heure}<br>{espece} {nombre} (code {atlas}) {distance} {obseur}<br>{comment}'):\n",
    "    \n",
    "    ref = sSight['Ref'] if 'Ref' in sSight.index else ''\n",
    "    \n",
    "    esp = ''.join(w[:4].title() for w in sSight['Nom latin'].split()) if 'Nom latin' in sSight.index else ''\n",
    "    \n",
    "    if 'nMalAd' in sSight.index:\n",
    "        nbre = ', '.join(f'{col}={int(sSight[col])}' \\\n",
    "                         for col in ['nMalAd', 'nAutAd', 'nJuv', 'nVol'] \\\n",
    "                         if col in sSight.index and not pd.isnull(sSight[col]) and sSight[col] > 0)\n",
    "    elif 'M' in sSight.index:\n",
    "        nbres = dict()\n",
    "        for col in ['M', 'F', 'Juv']:\n",
    "            if col in sSight.index and not pd.isnull(sSight[col]):\n",
    "                nbres[col] = sSight[col]\n",
    "                if isinstance(sSight[col], float):\n",
    "                    nbres[col] = int(nbres[col])\n",
    "        nbre = ', '.join(f'{col}={nbres[col]}' for col in nbres)\n",
    "    else:\n",
    "        nbre = str(int(sSight.Nombre))\n",
    "        if not pd.isnull(sSight['Détails']):\n",
    "            nbre += f\"[{sSight['Détails']}]\"\n",
    "        \n",
    "    dist = ('d={}m'.format(int(sSight['Distance'])) if 'Distance' in sSight.index else ''\n",
    "    \n",
    "    codAtlas = 0 if pd.isnull(sSight['Code atlas']) else int(sSight['Code atlas'])\n",
    "    \n",
    "    date = sSight.Date.date().isoformat() if 'Date' in sSight.index else ''\n",
    "                                \n",
    "    heure = sSight.Horaire if 'Horaire' in sSight.index else ''\n",
    "                                \n",
    "    obseur = sSight.Observateur if 'Observateur' in sSight.index else ''\n",
    "                                \n",
    "    comment = sSight.Commentaires if 'Commentaires' in sSight.index and not pd.isnull(sSight.Commentaires) else ''\n",
    "                                \n",
    "    return fmt.format(date=date, heure=heure, espece=esp, nombre=nbre, atlas=codAtlas,\n",
    "                      distance=dist, obseur=obseur, comment=comment).strip().replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serveurs et couches carto. pour folium / Leaflet\n",
    "mdOSM = dict(tiles='http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', \n",
    "             attr='Open Street Map',\n",
    "             name='Open Street Map', max_zoom=22, photo=False)\n",
    "\n",
    "mdOTM = dict(tiles='http://{s}.tile.opentopomap.org/{z}/{x}/{y}.png',\n",
    "             attr='<a href=\"https://opentopomap.org/\">OpenTopoMap</a> '\n",
    "                  '(<a href=\"https://creativecommons.org/licenses/by-sa/3.0/\">CC-BY-SA</a>)',\n",
    "             name='Open Topo Map', max_zoom=22, photo=False)\n",
    "mdThOut = dict(tiles='https://{s}.tile.thunderforest.com/outdoors/{z}/{x}/{y}.png',\n",
    "               attr='Thunderforest Outdoors', \n",
    "               name='Thunderforest Outdoors', max_zoom=22, photo=False)\n",
    "\n",
    "mdSatArcGis = dict(tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "                   attr='Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid,'\n",
    "                        ' IGN, IGP, UPR-EGP, and the GIS User Community',\n",
    "                   name='ArcGIS Satellite', max_zoom=22, photo=True)\n",
    "\n",
    "mdIGNMaps = dict(tiles='https://wxs.ign.fr/pratique/geoportail/wmts?'\n",
    "                       '&REQUEST=GetTile&SERVICE=WMTS&VERSION=1.0.0&TILEMATRIXSET=PM'\n",
    "                       '&LAYER=GEOGRAPHICALGRIDSYSTEMS.MAPS&STYLE=normal&FORMAT=image/jpeg'\n",
    "                       '&TILECOL={x}&TILEROW={y}&TILEMATRIX={z}',\n",
    "                 attr='&copy; <a href=\"http://www.ign.fr/\">IGN</a>',\n",
    "                 name='Cartes IGN', max_zoom=22, photo=False)\n",
    "mdIGNOPhoto = dict(tiles='https://wxs.ign.fr/pratique/geoportail/wmts?'\n",
    "                         '&REQUEST=GetTile&SERVICE=WMTS&VERSION=1.0.0&TILEMATRIXSET=PM'\n",
    "                         '&LAYER=ORTHOIMAGERY.ORTHOPHOTOS&STYLE=normal&FORMAT=image/jpeg'\n",
    "                         '&TILECOL={x}&TILEROW={y}&TILEMATRIX={z}',\n",
    "                   attr='&copy; <a href=\"http://www.ign.fr/\">IGN</a>',\n",
    "                   name='OrthoPhoto IGN', max_zoom=22, photo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors for sightings (with atlas code) and traces,\n",
    "# whether the map layer is a photo (True => dark) or not (False => clear).\n",
    "DColors = { True: dict(sight=dict(none='blue', poss='yellow', prob='orange', sure='red', stroke='gold'),\n",
    "                       trace=dict(point='yellowgreen', segment='yellowgreen')), \n",
    "            False: dict(sight=dict(none='blue', poss='yellow', prob='orange', sure='red', stroke='gold'),\n",
    "                        trace=dict(point='green', segment='green')) }\n",
    "\n",
    "def atlasCode2NestingCode(atlasCode): #atlasCodex='Biolovision'):\n",
    "    if atlasCode in [None, 0, 99]:\n",
    "        return 'none'\n",
    "    elif atlasCode >= 9:\n",
    "        return 'sure'\n",
    "    elif atlasCode >= 4:\n",
    "        return 'prob'\n",
    "    else:\n",
    "        return 'poss'\n",
    "    \n",
    "def color(mapSrc, sightPoint=False, stroke=False, atlasCode=None, tracePoint=False, traceSegment=False):\n",
    "    isMapDark = mapSrc['photo']\n",
    "    dColors = DColors[isMapDark]\n",
    "    if sightPoint:\n",
    "        clr = dColors['sight']['stroke' if stroke else atlasCode2NestingCode(atlasCode)]\n",
    "    elif tracePoint:\n",
    "        clr = dColors['trace']['point']\n",
    "    elif traceSegment:\n",
    "        clr = dColors['trace']['segment']\n",
    "    else:\n",
    "        raise Exception('No target selected for color')\n",
    "        \n",
    "    return clr\n",
    "    \n",
    "def buildMap(dfSights=None, sightTitle='Observations', dfTraces=None, tracesTitle='Trace',\n",
    "             dfPoints1=None, points1Title='Points1', dfPoints2=None, points2Title='Points2',\n",
    "             geoBounds=None, geoBoundsTitle='Limites', mapLayers=[], mapTitle='Carte', scale=True,\n",
    "             sightLatLonCols=['Lat (WGS84)', 'Lon (WGS84)'], clusterSights=False,\n",
    "             sightFmt='{date} {heure}<br>{espece}{nombre} (code {atlas}) {distance}',\n",
    "             tracesLatLonCols=['lat', 'lon'], tracesPointIndexCol='ptIndx', tracesListIndexCol='ID liste'):\n",
    "    \n",
    "    if not isinstance(mapLayers, list):\n",
    "        mapLayers = [mapLayers]\n",
    "\n",
    "    mp = folium.Map(tiles=None, control_scale=scale)\n",
    "    \n",
    "    for mapLayer in mapLayers:\n",
    "        folium.TileLayer(**mapLayer).add_to(mp)\n",
    "        \n",
    "    # Boundaries layer\n",
    "    if geoBounds:\n",
    "        gb = folium.GeoJson(geoBounds, name=geoBoundsTitle)\n",
    "        mp.add_child(gb)\n",
    "        \n",
    "    # Points1 layer\n",
    "    latCol, lonCol = tracesLatLonCols\n",
    "    if dfPoints1 is not None and not dfPoints1.empty:\n",
    "        \n",
    "        fg = folium.FeatureGroup(name=points1Title or 'Points1')\n",
    "\n",
    "        # Prepare traces (lines between points).\n",
    "        dfPoints1 = dfPoints1[[tracesListIndexCol, tracesPointIndexCol] + tracesLatLonCols]\n",
    "        dfPoints1.set_index(tracesListIndexCol, drop=True, inplace=True)\n",
    "\n",
    "        # Draw each points\n",
    "        for trcId, sPt in dfPoints1.iterrows():\n",
    "            mrk = folium.CircleMarker(location=(sPt[latCol], sPt[lonCol]), \n",
    "                                      popup=folium.Popup('#{}'.format(trcId)),\n",
    "                                      color='red', radius=4, weight=2, fill=True)\n",
    "            mrk.add_to(fg)\n",
    "                \n",
    "        fg.add_to(mp)\n",
    "\n",
    "    # Points2 layer\n",
    "    if dfPoints2 is not None and not dfPoints2.empty:\n",
    "        \n",
    "        fg = folium.FeatureGroup(name=points2Title or 'Points2')\n",
    "\n",
    "        # Prepare traces (lines between points).\n",
    "        dfPoints2 = dfPoints2[[tracesListIndexCol, tracesPointIndexCol] + tracesLatLonCols]\n",
    "        dfPoints2.set_index(tracesListIndexCol, drop=True, inplace=True)\n",
    "\n",
    "        # Draw each points\n",
    "        for trcId, sPt in dfPoints2.iterrows():\n",
    "            mrk = folium.CircleMarker(location=(sPt[latCol], sPt[lonCol]), \n",
    "                                      popup=folium.Popup('#{}'.format(trcId)),\n",
    "                                      color='blue', radius=4, weight=2, fill=True)\n",
    "            mrk.add_to(fg)\n",
    "                \n",
    "        fg.add_to(mp)\n",
    "\n",
    "    # Traces layer\n",
    "    if dfTraces is not None and not dfTraces.empty:\n",
    "        \n",
    "        fg = folium.FeatureGroup(name=tracesTitle or 'Traces')\n",
    "\n",
    "        # Prepare traces (lines between points).\n",
    "        dfTraces = dfTraces[[tracesListIndexCol, tracesPointIndexCol] + tracesLatLonCols]\n",
    "        dfTraces.set_index(tracesListIndexCol, drop=True, inplace=True)\n",
    "\n",
    "        # Draw each trace\n",
    "        for trcId in dfTraces.index.unique():\n",
    "\n",
    "            dfTrace = dfTraces.loc[trcId:trcId]  # Make sure we get a DataFrame even if only 1 row\n",
    "            if len(dfTrace) > 1:\n",
    "                \n",
    "                dfTrace = dfTrace.append(dfTrace.iloc[-1])  # Duplicate last points to them keep all after shift below\n",
    "                dfTrace[lonCol+'_sfd'] = dfTrace[lonCol].shift(-1)\n",
    "                dfTrace[latCol+'_sfd'] = dfTrace[latCol].shift(-1)\n",
    "                dfTrace.dropna(inplace=True)\n",
    "            \n",
    "                # a. Lines between points points\n",
    "                lines = list(zip(zip(dfTrace[latCol], dfTrace[lonCol]),\n",
    "                                 zip(dfTrace[latCol+'_sfd'], dfTrace[lonCol+'_sfd'])))[:-1]\n",
    "                pline = folium.PolyLine(lines, color=color(mapLayers[0], traceSegment=True),\n",
    "                                        weight=1, opacity=0.6, popup=folium.Popup(f'Trace #{trcId}'))\n",
    "                pline.add_to(fg)\n",
    "\n",
    "            # b. Points\n",
    "            for _, sPt in dfTrace.iterrows():\n",
    "                mrk = folium.CircleMarker(location=(sPt[latCol], sPt[lonCol]), \n",
    "                                          popup=folium.Popup('#{}: {}'.format(trcId, sPt[tracesPointIndexCol])),\n",
    "                                          color=color(mapLayers[0], tracePoint=True),\n",
    "                                          radius=2, weight=2, fill=True)\n",
    "                mrk.add_to(fg)\n",
    "                \n",
    "        fg.add_to(mp)\n",
    "\n",
    "    # Sightings\n",
    "    if dfSights is not None and not dfSights.empty:\n",
    "        \n",
    "        fg = folium.FeatureGroup(name=sightTitle or 'Observations')\n",
    "\n",
    "        latCol, lonCol = sightLatLonCols\n",
    "        if clusterSights:\n",
    "            mc = folium.plugins.MarkerCluster(name=sightTitle, control=False, \n",
    "                                              options=dict(maxClusterRadius=160, spiderfyOnMaxZoom=True,\n",
    "                                                           disableClusteringAtZoom=12))\n",
    "            fg.add_child(mc)\n",
    "        else:\n",
    "            mc = fg\n",
    "\n",
    "        for indSight, sSight in dfSights.iterrows():\n",
    "            mrk = folium.CircleMarker(location=(sSight[latCol], sSight[lonCol]),\n",
    "                                      color=color(mapLayers[0], sightPoint=True, stroke=True),\n",
    "                                      radius=8, weight=1, fill_opacity=0.8,\n",
    "                                      fill_color=color(mapLayers[0], sightPoint=True, atlasCode=sSight['Code atlas']),\n",
    "                                      popup=folium.Popup(sight2String(sSight, sightFmt), max_width=256))\n",
    "            mc.add_child(mrk)\n",
    "        \n",
    "        fg.add_to(mp)\n",
    "\n",
    "    # Layer control.\n",
    "    if len(mapLayers) > 1 or geoBounds or dfTraces is not None or dfSights is not None:\n",
    "        lc = folium.LayerControl(collapsed=False)\n",
    "        mp.add_child(lc)\n",
    "\n",
    "    # Title\n",
    "    if mapTitle:\n",
    "        #mapTitle = codecs.decode(codecs.encode(mapTitle, encoding='utf-8'), encoding='utf-8-sig')\n",
    "        htmlTitle = f\"\"\"\n",
    "          <div style=\"position: fixed; bottom: 0px; left: 100px; z-index:9999\">\n",
    "            <p style=\"font-size:20px; padding: 1px 1px 1px 5px; background-color: white; border-radius: 5px;\n",
    "                      box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.2);\">{mapTitle}</p>\n",
    "          </div>\n",
    "          \"\"\"\n",
    "        mp.get_root().html.add_child(folium.Element(htmlTitle))\n",
    "                \n",
    "    mp.fit_bounds(mp.get_bounds())\n",
    "    \n",
    "    return mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carte avec limites zone d'étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Carte avec limites zone d'étude\n",
    "mp = buildMap(vnds.dfData, sightTitle='Données', clusterSights=True,\n",
    "              dfTraces=dfTraces, tracesTitle='Traces GPS', \n",
    "              dfPoints1=vnds.listTraces(), points1Title='Points retenus',\n",
    "              dfPoints2=dfPoints, points2Title='Points prévus',\n",
    "              geoBounds=gjZone, geoBoundsTitle='Zone d\\'étude',\n",
    "              mapLayers=[mdOTM, mdSatArcGis, mdIGNOPhoto, mdIGNMaps], mapTitle=titreCarte,\n",
    "              sightFmt='{date} {heure}<br>{espece} {nombre} (code {atlas}) {distance}<br>{comment}')\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save map as shareable / web-publishable interactive one.\n",
    "mp.save(f'tmp/{nomEtude}.html')\n",
    "\n",
    "# Note: For auto selection of 1 map layer, remove / comment-out its \"tile_layer_<uuid>.remove()\" line\n",
    "# after searching for its uuid by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.toExcel('tmp/_.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Extraction des inventaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les inventaires (les transects)\n",
    "dfTransects = vnds.lists(columns=['ID liste', 'Date', 'Num Point']).copy()\n",
    "dfTransects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects['Num Point'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII. Individualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes d'effectifs à prendre en compte (on ignore les autres)\n",
    "countCols =  ['nMalAd', 'nAutAd']\n",
    "\n",
    "# Calcul des catégories : 1 seule, \"Adulte\" = Mâle ou Autre.\n",
    "def count2AdultCat(sCounts):\n",
    "    return 'm' if 'Mal' in sCounts[sCounts > 0].index[0] else 'a'\n",
    "\n",
    "# Création d'un FieldDataSet\n",
    "fds = ads.FieldDataSet(vnds.sightings(), countCols=countCols, addMonoCatCols={ 'Adulte': count2AdultCat })\n",
    "\n",
    "# ... pour individualiser et catégoriser les données.\n",
    "dfObsCatIndiv = fds.individualise()\n",
    "print(dfObsCatIndiv[countCols].sum().to_dict(), 'individus')\n",
    "\n",
    "# On ne garde que les colonnes utiles (comptes à 0 ou 1 <=> catégories), et avec des noms améliorés\n",
    "dfObsCatIndiv = dfObsCatIndiv[['ID liste', 'Date', 'Num Point', 'Nom latin', 'Distance', 'Adulte']].copy()\n",
    "dfObsCatIndiv.rename(columns={ 'Nom latin': 'Espèce' }, inplace=True)\n",
    "\n",
    "print(len(dfObsCatIndiv), 'individus au total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsCatIndiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des données et inventaires.\n",
    "nomFicCible = pl.Path(dossier) / f'{nomEtude}-ObsIndiv.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(nomFicCible) as xlsWriter:\n",
    "    \n",
    "    dfObsCatIndiv.to_excel(xlsWriter, index=False, sheet_name='Donnees')\n",
    "    dfTransects.to_excel(xlsWriter, index=False, sheet_name='Inventaires')\n",
    "    \n",
    "print(nomFicCible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IX. Export pour analyses dans Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "especes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examen des données : Nombre d'individus par espèce, pour voir quelles espèces on va analyser\n",
    "if groupage: # Clustering lors des analyses DS\n",
    "    dfIndivCounts = dfObsCatIndiv[['Espèce', 'Nombre']].groupby('Espèce').sum()\n",
    "    dfIndivCounts.rename(columns=dict(Nombre='Individus'), inplace=True)\n",
    "else:\n",
    "    dfIndivCounts = dfObsCatIndiv[['Espèce', 'Distance']].groupby('Espèce').count()\n",
    "    dfIndivCounts.rename(columns=dict(Distance='Individus'), inplace=True)\n",
    "\n",
    "dfIndivCounts.sort_values(by='Individus', ascending=False, inplace=True)\n",
    "\n",
    "dfIndivCounts[dfIndivCounts.Individus >= especes if isinstance(especes, int) else 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec. implicite des variantes (=> combinaisons à générer automatiquement)\n",
    "# a. 1 variante espèce ... par espèce <8-]\n",
    "assert isinstance(especes, list) or isinstance(especes, int)\n",
    "if isinstance(especes, list):\n",
    "    varEspeces = especes\n",
    "else:\n",
    "    varEspeces = list(dfIndivCounts[dfIndivCounts.Individus >= especes].index)\n",
    "\n",
    "# b. Variantes adultes.\n",
    "varAdultes = ['m', 'm+a'] # Tous les adultes ensemble => 1 variante\n",
    "\n",
    "# c. Variantes passages (= dates, car pas plus d'1 passage par jour).\n",
    "varPassages = [''] # Tous les passages ensemble => 1 variante\n",
    "\n",
    "# c. La spec. des variantes\n",
    "dImplSamples = { 'Espèce': varEspeces, 'Adulte': varAdultes, 'Passage': varPassages }\n",
    "dImplSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitation des specs.\n",
    "dfExplSampleSpecs = ads.DSAnalyser.explicitVariantSpecs(odict([('echant_impl', dImplSamples)]))\n",
    "dfExplSampleSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsCatIndiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu de données individualisées.\n",
    "mds = ads.MonoCategoryDataSet(dfObsCatIndiv, dfTransects=dfTransects, dSurveyArea=dZoneEtude,\n",
    "                              transectPlaceCols=['Num Point'], passIdCol='Passage', effortCol='Effort',\n",
    "                              sampleDecFields=['Distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaîne courte d'identification d'une spec. d'échantillon.\n",
    "def sampleAbbreviation(sSample):\n",
    "    \n",
    "    abrvSpe = ''.join(word[:4].title() for word in sSample['Espèce'].split(' ')[:2])\n",
    "    \n",
    "    sampAbbrev = '{}-{}'.format(abrvSpe, sSample.Adulte.replace('+', ''))\n",
    "    \n",
    "    return sampAbbrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Export au format Distance : C\\'est parti ...')\n",
    "\n",
    "# Moteur MCDS pour l'export.\n",
    "mcds = ads.MCDSEngine(workDir=dossier,\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial', clustering=groupage)\n",
    "\n",
    "# Pour chaque échantillon :\n",
    "for sampInd, sSamp in dfExplSampleSpecs.iterrows():\n",
    "    \n",
    "    sampAbbrev = sampleAbbreviation(sSamp)\n",
    "\n",
    "    # Selection des données\n",
    "    sds = mds.sampleDataSet(sSamp)\n",
    "    if not sds:\n",
    "        logger.info('#{:02d} : {} => Pas de données, pas de fichier'.format(sampInd+1, sampAbbrev))\n",
    "        continue\n",
    "\n",
    "    # Export au format Distance\n",
    "    fpn = pl.Path(dossier) / f'{sampAbbrev}-dist.txt'\n",
    "    fpn = mcds.buildDistanceDataFile(sds, tgtFilePathName=fpn)\n",
    "\n",
    "    logger.info('#{:02d} : {} => {}'.format(sampInd+1, sampAbbrev, fpn.name))\n",
    "\n",
    "# Arrêt moteur.\n",
    "mcds.shutdown()\n",
    "\n",
    "# Terminé.\n",
    "logger.info('Terminé.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Mise au point : Amélioration traces en mode \"point transect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyLine2MeanPoint(dfTrc, keepPtsPct=70, maxMltStd=1.0):\n",
    "\n",
    "    \"\"\"Reduce given WGS84 trace to its mean point, after removing outlier points\n",
    "    \n",
    "    Parameters:\n",
    "    :param dfTrc: the trace to improve, as a DataFrame with at least TraceWgs84Cols columns\n",
    "    :param keepPtsPct: min percentage of points to keep for final mean computation\n",
    "    :param maxMltStd: max number of std value times for keeping points for final mean computation\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute raw mean point and standard deviation (independently for lat and long)\n",
    "    sRawMean = dfTrc[['lon', 'lat']].mean()\n",
    "    sRawStd = dfTrc[['lon', 'lat']].std()\n",
    "    \n",
    "    # Compute distance to raw mean for each point\n",
    "    dfImpTrc = dfTrc.copy()  # Don't change input trace\n",
    "    dfImpTrc['dmlon'] = (dfImpTrc['lon'] - sRawMean['lon']).abs()\n",
    "    dfImpTrc['dmlat'] = (dfImpTrc['lat'] - sRawMean['lat']).abs()\n",
    "    \n",
    "    # Keep only non-outlier points: numerous enough (keepPtsPct), or close enough to mean (maxMltStd)\n",
    "    dfImpTrc = dfImpTrc[(dfImpTrc['dmlat'] <= max(dfImpTrc['dmlat'].quantile(keepPtsPct/100),\n",
    "                                                  maxMltStd*sRawStd['lat']))\n",
    "                        & (dfImpTrc['dmlon'] <= max(dfImpTrc['dmlon'].quantile(keepPtsPct/100),\n",
    "                                                    maxMltStd*sRawStd['lon']))]\n",
    "         \n",
    "    return pd.Series(data=[0, dfTrc['lon'].mean(), dfTrc['lat'].mean()],\n",
    "                     index=['ptIndx', 'lon', 'lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KImproveTraceKeepPtsPct = 70\n",
    "KImproveTraceMaxMltStd = 1.0\n",
    "dfImpTraces = dfTraces.groupby('ID liste') \\\n",
    "                      .apply(polyLine2MeanPoint, keepPtsPct=KImproveTraceKeepPtsPct, maxMltStd=KImproveTraceMaxMltStd) \\\n",
    "                      .reset_index()\n",
    "dfImpTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTraceStats = dfTraces.join(dfImpTraces[['ID liste', 'lon', 'lat']].set_index('ID liste'), on='ID liste', rsuffix='_imp')\n",
    "dfTraceStats = dfTraceStats[['ID liste', 'lon', 'lon_imp', 'lat', 'lat_imp']]\n",
    "dfTraceStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTraceStats['ID liste'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTraceStats[dfTraceStats['ID liste'] == 1028708]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Carte avec limites zone d'étude\n",
    "mp = buildMap(vnds.dfData, sightTitle='Données', clusterSights=True,\n",
    "              dfTraces=dfTraces, tracesTitle='Traces',\n",
    "              dfPoints1=dfImpTraces, points1Title='Points moyens',\n",
    "              dfPoints2=dfPoints, points2Title='Points prévus',\n",
    "              geoBounds=gjZone, geoBoundsTitle='Zone d\\'étude',\n",
    "              mapLayers=[mdOTM, mdSatArcGis, mdIGNOPhoto, mdIGNMaps], mapTitle=titreCarte,\n",
    "              sightFmt='{date} {heure}<br>{espece}{nombre} (code {atlas})<br>{comment}')\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save map as shareable / web-publishable interactive one.\n",
    "mp.save(f'tmp/{nomEtude}.html')\n",
    "\n",
    "# Note: For auto selection of 1 map layer, remove / comment-out its \"tile_layer_<uuid>.remove()\" line\n",
    "# after searching for its uuid by name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pb 1035425 : pas assez d'ouliers virés ? (trace étirée en lat)\n",
    "Pb 1039772 : pas assez d'ouliers virés ? (trace étirée en lat)\n",
    "Pb 1091665 : formulaire pas fermé assez tôt ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Mise au point : Distances en mode \"point transect\"\n",
    "\n",
    "(vérification paranoïaque fonction geometry.Point().distance() ... suite échelle carte imprécise ...\n",
    " ouf, elle fonctionne :-O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListTraces = vnds.listTraces()\n",
    "dfListTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs = vnds.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idListe = 1028708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs1Trans = dfObs[dfObs['ID liste'] == idListe].copy()[['ID liste', 'UTM X [m]', 'UTM Y [m]', 'Distance']]\n",
    "dfObs1Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sListCoords = dfListTraces[dfListTraces['ID liste'] == idListe].iloc[0]\n",
    "dfObs1Trans['lonUtm'] = sListCoords['lonUtm']\n",
    "dfObs1Trans['latUtm'] = sListCoords['latUtm']\n",
    "dfObs1Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs1Trans['Distance2'] = dfObs1Trans.apply(lambda s: np.sqrt((s['UTM X [m]'] - s.lonUtm)*(s['UTM X [m]'] - s.lonUtm)\n",
    "                                                               + (s['UTM Y [m]'] - s.latUtm)*(s['UTM Y [m]'] - s.latUtm)),\n",
    "                                            axis='columns')\n",
    "dfObs1Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ((dfObs1Trans.Distance - dfObs1Trans.Distance2) < 1.e-5).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Astuce : Calcul surface multi-polygones source geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbed from https://www.programcreek.com/python?code=Wireless-Innovation-Forum%2FSpectrum-Access-System%2FSpectrum-Access-System-master%2Fsrc%2Fharness%2Freference_models%2Fgeo%2Futils.py\n",
    "def geoJson2ShapelyGeometry(gjGeo):\n",
    "    \n",
    "    \"\"\"Returns a |shapely| geometry from a GeoJSON geometry.\n",
    "  \n",
    "    Args:\n",
    "      gjGeo: A dict or string representing a GeoJSON geometry.\n",
    "  \n",
    "    Raises:\n",
    "      ValueError: If invalid GeoJSON geometry is passed.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(gjGeo, dict) or 'type' not in gjGeo:\n",
    "        raise ValueError('Invalid GeoJSON geometry.')\n",
    "  \n",
    "    if 'geometries' in gjGeo:\n",
    "        return sgeo.GeometryCollection([geoJson2ShapelyGeometry(g) for g in gjGeo['geometries']])\n",
    "    gjGeo = geometry.shape(gjGeo)\n",
    "    if isinstance(gjGeo, geometry.Polygon) or isinstance(gjGeo, geometry.MultiPolygon):\n",
    "        gjGeo = gjGeo.buffer(0)\n",
    "        \n",
    "    return gjGeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shgeoZone = geoJson2ShapelyGeometry(gjZone)\n",
    "shgeoZone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface en degrés**2 ! (puisque coordonnées de la zone en degrés WGS84)\n",
    "shgeoZone.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAUX: Surface en km**2 (à la louche, terre = sphère parfaite de rayon 6370 km)\n",
    "shgeoZone.area * (6370 * math.pi / 180)\n",
    "\n",
    "# => Mais c'est complètement faux : 6416 ha ! (Cf. KML, c'est écrit dedans)\n",
    "\n",
    "# => il faudrait d'abord projeter le multipolygone en UTM31, avant de redemander .area\n",
    "# => ce qui est expliqué ici : https://stackoverflow.com/a/21420950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Auto table of contents -->\n",
    "<h1 class='tocIgnore'>Validation tests</h1>\n",
    "\n",
    "**pyaudisam**: Automation of Distance Sampling analyses with [Distance software](http://distancesampling.org/)\n",
    "\n",
    "Copyright (C) 2021 Jean-Philippe Meuret\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify it under the terms\n",
    "of the GNU General Public License as published by the Free Software Foundation,\n",
    "either version 3 of the License, or (at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n",
    "without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
    "See the GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License along with this program.\n",
    "If not, see https://www.gnu.org/licenses/.\n",
    "\n",
    "<div style=\"overflow-y: auto\">\n",
    "  <h2 class='tocIgnore'>Table of contents</h2>\n",
    "  <div id=\"toc\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib as pl\n",
    "import importlib as implib\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict as odict, namedtuple as ntuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudisam as ads\n",
    "\n",
    "ads.runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory if not yet done.\n",
    "tmpDir = pl.Path('tmp')\n",
    "tmpDir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration.\n",
    "ads.log.configure(handlers=[sys.stdout, tmpDir / 'valtst.log'], reset=True,\n",
    "                  loggers=[dict(name='matplotlib', level=ads.WARNING),\n",
    "                           dict(name='ads', level=ads.INFO),\n",
    "                           #dict(name='ads.dat', level=ads.INFO2),\n",
    "                           #dict(name='ads.eng', level=ads.INFO2),\n",
    "                           dict(name='ads.anr', level=ads.INFO1),\n",
    "                           dict(name='ads.onr', level=ads.INFO1),\n",
    "                           dict(name='ads.rep', level=ads.INFO1),\n",
    "                           dict(name='valtst', level=ads.DEBUG)])\n",
    "\n",
    "logger = ads.logger('valtst', level=ads.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate Warnings as Exceptions\n",
    "if False:\n",
    "    \n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(action='error')\n",
    "\n",
    "    # pd.read_excel\n",
    "    warnings.filterwarnings(action='default', module='etree')\n",
    "    warnings.filterwarnings(action='default', module='xlrd')\n",
    "    warnings.filterwarnings(action='default', module='defusedxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to :\n",
    "* [II. Run pre-analyses / 0. Data Description](#II.-Run-pre-analyses)\n",
    "* [III. Run analyses with same real life field data / 0. Data Description](#III.-Run-analyses-with-same-real-life-field-data)\n",
    "* [IV. Run truncation opt-analyses with same real life field data](#IV.-Run-truncation-opt-analyses-with-same-real-life-field-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Generate input files for manual analyses in Distance interactive software\n",
    "\n",
    "* through an Excel input field data file,\n",
    "* and a reference output file set, prooved as OK by using it in Distance software ;\n",
    "* automated comparison to reference is achied at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistCases = pd.DataFrame([dict(inFileName='ACDC2019-Papyrus-ALAARV-saisie-ttes-cols.xlsx',\n",
    "                                 decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'],\n",
    "                                 refOutFileName='ACDC2019-Papyrus-ALAARV-saisie-5-cols.txt', withExtraFields=False),\n",
    "                            dict(inFileName='ACDC2019-Papyrus-ALAARV-saisie-ttes-cols.xlsx',\n",
    "                                 decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'],\n",
    "                                 refOutFileName='ACDC2019-Papyrus-ALAARV-saisie-ttes-cols.txt', withExtraFields=True)])\n",
    "dfDistCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = ads.MCDSEngine(workDir=tmpDir / 'mcds-out')\n",
    "\n",
    "pl.Path(eng.workDir, 'distance-in').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails = 0\n",
    "for ind, sCase in dfDistCases.iterrows():\n",
    "    \n",
    "    print('#', ind, ':', sCase.inFileName)\n",
    "\n",
    "    # Create data set\n",
    "    sds = ads.SampleDataSet(source=pl.Path('refin', sCase.inFileName),\n",
    "                           decimalFields=sCase.decimalFields)\n",
    "    \n",
    "    # Build distance import data file\n",
    "    ofn = pl.Path(eng.workDir, 'distance-in', sCase.refOutFileName)\n",
    "    ofn = eng.buildDistanceDataFile(sds, tgtFilePathName=ofn, withExtraFields=sCase.withExtraFields)\n",
    "    \n",
    "    # Compare generated file to reference\n",
    "    rfn = pl.Path('refout', sCase.refOutFileName)\n",
    "    with open(ofn, 'r') as fOut, open(rfn, 'r') as fRef:\n",
    "        if fOut.read() == fRef.read():\n",
    "            print('Success : Conform to reference.')\n",
    "        else:\n",
    "            print('Error: Generated file differs from reference', rfn)\n",
    "            fails += 1\n",
    "            \n",
    "    print()\n",
    "    \n",
    "print('All test cases succeeded !' if fails == 0 else 'Error: {} test case(s) failed.'.format(fails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Run pre-analyses\n",
    "\n",
    "Thanks to MCDSPreAnalyser.\n",
    "\n",
    "Short code, fast (parallel) run.\n",
    "\n",
    "Note: 2 modes here, with explicit or implicit sample specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short string for sample \"identification\"\n",
    "def sampleAbbrev(sSample):\n",
    "    \n",
    "    abrvSpe = ''.join(word[:4].title() for word in sSample['Espèce'].split(' ')[:2])\n",
    "    \n",
    "    sampAbbrev = '{}-{}-{}-{}'.format(abrvSpe, sSample.Passage.replace('+', ''),\n",
    "                                      sSample.Adulte.replace('+', ''), sSample['Durée'])\n",
    "    \n",
    "    return sampAbbrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transectPlaceCols = ['Point']\n",
    "passIdCol = 'Passage'\n",
    "effortCol = 'Effort'\n",
    "\n",
    "sampleDecCols = [effortCol, 'Distance']\n",
    "\n",
    "sampleNumCol = 'NumEchant'\n",
    "sampleSelCols = ['Espèce', passIdCol, 'Adulte', 'Durée']\n",
    "\n",
    "sampleAbbrevCol = 'AbrevEchant'\n",
    "\n",
    "speciesAbbrevCol = 'AbrevEsp'\n",
    "\n",
    "dSurveyArea = dict(Zone='ACDC', Surface='2400')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to [III. Run analyses with same real life field data / 0. Data Description](#III.-Run-analyses-with-same-real-life-field-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Individuals data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsIndiv = ads.DataSet('refin/ACDC2019-Naturalist-ExtraitObsIndiv.ods', sheet='DonnéesIndiv').dfData\n",
    "dfObsIndiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{ col: dfObsIndiv[col].unique() for col in ['Observateur', 'Point', 'Passage', 'Adulte', 'Durée', 'Espèce'] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Actual transects\n",
    "\n",
    "(can't deduce them from data, some points are missing because of data selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects = ads.DataSet('refin/ACDC2019-Naturalist-ExtraitObsIndiv.ods', sheet='Inventaires').dfData\n",
    "dfTransects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Samples to pre-analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implicit variants\n",
    "varEspeces = ['Sylvia atricapilla', 'Turdus merula', 'Luscinia megarhynchos'] # 1 variante espèce ... par espèce <8-]\n",
    "\n",
    "varPassages = ['b', 'a+b'] # Passage b ou a+b => 2 variantes\n",
    "varAdultes = ['m'] # Les mâles, et ensuite les mâles et autres adultes (=> 2 variantes)\n",
    "varDurees = ['5mn', '10mn'] # 5 1ères mn, ou toutes les 10 => 2 variantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitation of variants or not\n",
    "# a. Implicites specs\n",
    "dImplSampleSpecs = { 'Espèce': varEspeces, 'Passage': varPassages, 'Adulte': varAdultes, 'Durée':   varDurees }\n",
    "\n",
    "specsAreExplicit = True\n",
    "if specsAreExplicit:\n",
    "    \n",
    "    # b. Explicit combinations\n",
    "    dfExplSampleSpecs = ads.Analyser.explicitVariantSpecs(dict(_impl=dImplSampleSpecs))\n",
    "    #dfExplSampleSpecs = ads.Analyser.explicitPartialVariantSpecs(dImplSampleSpecs) # Just the same, but less generic.\n",
    "\n",
    "    # c. Add sample order columns (usefull for reports, as pre-analyses are run parallely !).\n",
    "    #dfExplSampleSpecs.reset_index(drop=False, inplace=True)\n",
    "    #dfExplSampleSpecs.rename(columns=dict(index=sampleNumCol), inplace=True)\n",
    "\n",
    "    # d. Add sample abbreviation column (mainly for analysis traces)\n",
    "    #dfExplSampleSpecs[sampleAbbrevCol] = dfExplSampleSpecs.apply(sampleAbbrev, axis='columns')\n",
    "\n",
    "    # e. Add neutral and pass-through column (from sample specs to results)\n",
    "    dfExplSampleSpecs[speciesAbbrevCol] = dfExplSampleSpecs['Espèce'].apply(lambda s: ''.join(m[:4] for m in s.split()))\n",
    "    \n",
    "    print(dfExplSampleSpecs)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # b. Keep unexplicited : run will do automatically\n",
    "    implSampleSpecs = dict(_impl=dImplSampleSpecs)\n",
    "    \n",
    "    print(implSampleSpecs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir = tmpDir / 'mcds-preanlr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4A. Or : Really run pre-analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. MCDSPreAnalyser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preAnlysr = \\\n",
    "    ads.MCDSPreAnalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea,\n",
    "                        transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                        sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleSpecCustCols=[speciesAbbrevCol],\n",
    "                        abbrevCol=sampleAbbrevCol, abbrevBuilder=sampleAbbrev, sampleIndCol=sampleNumCol,\n",
    "                        distanceUnit='Meter', areaUnit='Hectare',\n",
    "                        surveyType='Point', distanceType='Radial', clustering=False,\n",
    "                        resultsHeadCols=dict(before=[sampleNumCol], sample=sampleSelCols,\n",
    "                                             after=([speciesAbbrevCol] if specsAreExplicit else []) + [sampleAbbrevCol]),\n",
    "                        workDir=workDir, logProgressEvery=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(preAnlysr.specs) == 17\n",
    "\n",
    "preAnlysr.specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Check pre-analyses specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExplSampleSpecs, userParamSpecCols, intParamSpecCols, unmUserParamSpecCols, verdict, reasons = \\\n",
    "    preAnlysr.explicitParamSpecs(dfExplParamSpecs=dfExplSampleSpecs if specsAreExplicit else None,\n",
    "                                 implParamSpecs=implSampleSpecs if not specsAreExplicit else None,\n",
    "                                 dropDupes=True, check=True)\n",
    "\n",
    "print(verdict, reasons, len(dfExplSampleSpecs), userParamSpecCols, intParamSpecCols, unmUserParamSpecCols)\n",
    "\n",
    "assert len(dfExplSampleSpecs) == 12\n",
    "assert userParamSpecCols == [] # No analysis params here (auto. generated by PreAnalyser)\n",
    "assert intParamSpecCols == [] # Idem\n",
    "assert unmUserParamSpecCols == []\n",
    "assert verdict\n",
    "assert not reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Run pre-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fall-down strategy\n",
    "modelStrategy = [dict(keyFn=kf, adjSr=js, estCrit='AIC', cvInt=95) \\\n",
    "                 for js in['COSINE', 'POLY', 'HERMITE']\n",
    "                 for kf in['HNORMAL', 'HAZARD', 'UNIFORM', 'NEXPON']]\n",
    "\n",
    "# Note: For real bird study analyses, you'll probably avoid NEXPON key function (model with no shoulder : g'(0) << 1).\n",
    "#       And also HERMITE adjustment series (overkill fitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "preResults = preAnlysr.run(dfExplSampleSpecs if specsAreExplicit else None,\n",
    "                           implSampleSpecs=implSampleSpecs if not specsAreExplicit else None, \n",
    "                           dModelStrategy=modelStrategy, threads=12)\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances figures on a 4-core i5-8350U Ruindows 10 laptop with PCI-e SSD, \"optimal performance power scheme\", 12 threads, Python 3.8 :\n",
    "* 2021 (precise date ?): 50s to ~1mn10s elapsed for 12 samples, 6-12 threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preAnlysr.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preResults.specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not specsAreExplicit or speciesAbbrevCol in preResults.dfTransData('fr').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preResults.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preResults.dfData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Save results for later reload or examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preResults.toExcel(workDir / 'valtests-mcds-preanlyser-results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preResults.toExcel(workDir / 'valtests-mcds-preanlyser-results-fr.xlsx', lang='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4B. Or : Load pre-analyses from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    # An analyser object knowns how to build an empty results object ...\n",
    "    preAnlysr = \\\n",
    "        ads.MCDSPreAnalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea,\n",
    "                            transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                            sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleSpecCustCols=[speciesAbbrevCol],\n",
    "                            abbrevCol=sampleAbbrevCol, abbrevBuilder=sampleAbbrev, sampleIndCol=sampleNumCol,\n",
    "                            distanceUnit='Meter', areaUnit='Hectare',\n",
    "                            surveyType='Point', distanceType='Radial', clustering=False,\n",
    "                            resultsHeadCols=dict(before=[sampleNumCol], sample=sampleSelCols,\n",
    "                                                 after=([speciesAbbrevCol] if specsAreExplicit else []) + [sampleAbbrevCol]))\n",
    "    \n",
    "    preResults = preAnlysr.setupResults()\n",
    "    \n",
    "    # Load resultas from file\n",
    "    resFileName = workDir / 'valtests-mcds-preanlyser-results.xlsx'\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    preResults.fromExcel(resFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} analyses to compare'.format(len(preResults)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare results to reference\n",
    "\n",
    "(reference generated with same kind of \"long\" code like in III above, but on another data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference\n",
    "# 1. Clone results _without_ data.\n",
    "rsRef = preResults.copy(withData=False)\n",
    "\n",
    "# 2. Load it with reference data (prevent re-postComputation as this ref. file is old, with now missing computed cols)\n",
    "rsRef.fromOpenDoc('refout/ACDC2019-Naturalist-ExtraitPreResultats.ods', postComputed=True)  \n",
    "\n",
    "rsRef.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare (ignore sample and analysis indexes, no use here).\n",
    "indexPreCols = [col for col in preResults.miCustomCols.to_list() if '(sample)' in col[0]] \\\n",
    "                + [('parameters', 'estimator key function', 'Value'),\n",
    "                   ('parameters', 'estimator adjustment series', 'Value')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetPreCols = [col for col in preResults.dfData.columns.to_list() \\\n",
    "                 if col in rsRef.columns\n",
    "                    and col not in indexPreCols + [col for col in preResults.miCustomCols.to_list()\n",
    "                                                   if '(sample)' not in col[0]]\n",
    "                                   + [('parameters', 'estimator selection criterion', 'Value'),\n",
    "                                      ('parameters', 'CV interval', 'Value'),\n",
    "                                      ('run output', 'start time', 'Value'),\n",
    "                                      ('run output', 'elapsed time', 'Value'),\n",
    "                                      ('run output', 'run folder', 'Value'),\n",
    "                                      ('detection probability', 'key function type', 'Value'),\n",
    "                                      ('detection probability', 'adjustment series type', 'Value'),\n",
    "                                      ('detection probability', 'Delta AIC', 'Value'),\n",
    "                                      ('density/abundance', 'density of animals', 'Delta Cv')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiff = rsRef.compare(preResults, indexCols=indexPreCols, subsetCols=subsetPreCols, dropCloser=13, dropNans=True)\n",
    "\n",
    "assert dfDiff.empty, 'Oh oh ... some differences !'\n",
    "\n",
    "print('Yessssss !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be perfectly honest ... there may be some 10**-14/-16 glitches (due to worksheet I/O ?)\n",
    "dfComp = rsRef.compare(preResults, indexCols=indexPreCols, subsetCols=subsetPreCols, dropNans=True)\n",
    "dfComp = dfComp[(dfComp != np.inf).all(axis='columns')]\n",
    "dfComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate HTML and Excel pre-analyses reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = preResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-synthesis sub-report : Selected analysis results columns for the 3 textual columns of the table\n",
    "samplePreRepCols = [\n",
    "    ('header (head)', 'NumEchant', 'Value'),\n",
    "    ('header (sample)', 'Espèce', 'Value'),\n",
    "    ('header (sample)', 'Passage', 'Value'),\n",
    "    ('header (sample)', 'Adulte', 'Value'),\n",
    "    ('header (sample)', 'Durée', 'Value'),\n",
    "    ('sample stats', 'total number of observations', 'Value'),\n",
    "    ('sample stats', 'maximal observation distance', 'Value'),\n",
    "]\n",
    "\n",
    "paramPreRepCols = [\n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    #('parameters', 'estimator selection criterion', 'Value'),\n",
    "    #('parameters', 'CV interval', 'Value'),\n",
    "]\n",
    "    \n",
    "resultPreRepCols = [\n",
    "    ('run output', 'run status', 'Value'),\n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    ('encounter rate', 'effort (L or K or T)', 'Value'),\n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    \n",
    "    ('combined quality', 'balanced 1', 'Value'),\n",
    "    ('combined quality', 'balanced 2', 'Value'),\n",
    "    ('combined quality', 'balanced 3', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesis sub-report : Selected analysis results columns for the \n",
    "synthPreRepCols = [\n",
    "    ('header (head)', 'NumEchant', 'Value'),\n",
    "    ('header (sample)', 'Espèce', 'Value'),\n",
    "    ('header (sample)', 'Passage', 'Value'),\n",
    "    ('header (sample)', 'Adulte', 'Value'),\n",
    "    ('header (sample)', 'Durée', 'Value'),\n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    #('parameters', 'estimator selection criterion', 'Value'),\n",
    "    #('parameters', 'CV interval', 'Value'),\n",
    "    ('parameters', 'left truncation distance', 'Value'),\n",
    "    ('parameters', 'right truncation distance', 'Value'),\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'),\n",
    " \n",
    "    R.CLNTotObs, R.CLNObs, R.CLNTotPars, R.CLEffort, R.CLDeltaAic, R.CLChi2, R.CLKS, R.CLCvMUw, R.CLCvMCw, R.CLDCv, \n",
    "\n",
    "    R.CLSightRate,\n",
    "    R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3,\n",
    "    R.CLCmbQuaChi2, R.CLCmbQuaKS, R.CLCmbQuaDCv,\n",
    "\n",
    "    R.CLPDetec, R.CLPDetecMin, R.CLPDetecMax, R.CLDensity, R.CLDensityMin, R.CLDensityMax\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting columns for all the sub-reports\n",
    "sortPreRepCols = [('header (head)', 'NumEchant', 'Value')]\n",
    "sortPreRepAscend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preReport = ads.MCDSResultsPreReport(resultsSet=preResults,\n",
    "                                     title='PyAuDiSam Validation: Pre-analyses', subTitle='Pre-analysis results report',\n",
    "                                     anlysSubTitle='Pre-analysis results details',\n",
    "                                     description='Easy and parallel run through MCDSPreAnalyser',\n",
    "                                     keywords='pyaudisam, validation, pre-analysis',\n",
    "                                     lang='en', superSynthPlotsHeight=288,\n",
    "                                     #plotImgSize=(640, 400), plotLineWidth=1, plotDotWidth=4,\n",
    "                                     #plotFontSizes=dict(title=11, axes=10, ticks=9, legend=10),\n",
    "                                     sampleCols=samplePreRepCols, paramCols=paramPreRepCols,\n",
    "                                     resultCols=resultPreRepCols, synthCols=synthPreRepCols,\n",
    "                                     sortCols=sortPreRepCols, sortAscend=sortPreRepAscend,\n",
    "                                     tgtFolder=workDir, tgtPrefix='valtests-preanalyser-report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsxPreRep = preReport.toExcel()\n",
    "\n",
    "HTML(f'Excel pre-report: <a href=\"{xlsxPreRep}\" target=\"blank\">{xlsxPreRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.startfile(xlsxPreRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "htmlPreRep = preReport.toHtml() #generators=5)\n",
    "\n",
    "print('Pre-report: ' + pl.Path(htmlPreRep).resolve().as_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Run analyses with same real life field data\n",
    "\n",
    "Thanks to MCDSAnalyser class.\n",
    "\n",
    "Short code, fast (parallel) run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run first [II. Run pre-analyses / 0. Data Description](#II.-Run-pre-analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short string for analysis \"identification\"\n",
    "def analysisAbbrev(sAnlys):\n",
    "    \n",
    "    # Sample abbreviation\n",
    "    abbrevs = [sampleAbbrev(sAnlys)]\n",
    "\n",
    "    # Model + Parameters abbreviation\n",
    "    abbrevs += [sAnlys['FonctionClé'][:3].lower(), sAnlys['SérieAjust'][:3].lower()]\n",
    "    dTroncAbrv = { 'l': 'TrGche' if 'TrGche' in sAnlys.index else 'TroncGche',\n",
    "                   'r': 'TrDrte' if 'TrDrte' in sAnlys.index else 'TroncDrte',\n",
    "                   'm': 'NbTrches' if 'NbTrches' in sAnlys.index else 'NbTrModel'\n",
    "                                   if 'NbTrModel' in sAnlys.index else  'NbTrchMod',\n",
    "                   'd': 'NbTrDiscr' }\n",
    "    for abrv, name in dTroncAbrv.items():\n",
    "        if name in sAnlys.index and not pd.isnull(sAnlys[name]):\n",
    "            abbrevs.append('{}{}'.format(abrv, sAnlys[name][0].lower() if isinstance(sAnlys[name], str)\n",
    "                                               else int(sAnlys[name])))\n",
    "   \n",
    "    return '-'.join(abbrevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transectPlaceCols = ['Point']\n",
    "passIdCol = 'Passage'\n",
    "effortCol = 'Effort'\n",
    "\n",
    "sampleDecCols = [effortCol, 'Distance']\n",
    "\n",
    "sampleNumCol = 'NumEchant'\n",
    "sampleSelCols = ['Espèce', passIdCol, 'Adulte', 'Durée']\n",
    "\n",
    "varIndCol = 'NumAnlys'\n",
    "anlysAbbrevCol = 'AbrevAnlys'\n",
    "\n",
    "dSurveyArea = dict(Zone='ACDC', Surface='2400')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to [IV. Run truncation opt-analyses with same real life field data](#IV.-Run-truncation-opt-analyses-with-same-real-life-field-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Individuals data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsIndiv = ads.DataSet('refin/ACDC2019-Naturalist-ExtraitObsIndiv.ods', sheet='DonnéesIndiv').dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsIndiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{ col: dfObsIndiv[col].unique() for col in ['Observateur', 'Point', 'Passage', 'Adulte', 'Durée', 'Espèce'] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Actual transects\n",
    "\n",
    "(can't deduce them from data, some points are missing because of data selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects = ads.DataSet('refin/ACDC2019-Naturalist-ExtraitObsIndiv.ods', sheet='Inventaires').dfData\n",
    "len(dfTransects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyses specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnlysSpecs = ads.Analyser.explicitVariantSpecs('refin/ACDC2019-Naturalist-ExtraitSpecsAnalyses.xlsx', \n",
    "                                                 keep=['Echant1_impl', 'Echant2_impl', 'Modl_impl',\n",
    "                                                       'Params1_expl', 'Params2_expl'],\n",
    "                                                 varIndCol=varIndCol,\n",
    "                                                 #convertCols={ 'Durée': int }, # float 'cause of Excel\n",
    "                                                 computedCols={ anlysAbbrevCol: analysisAbbrev })\n",
    "\n",
    "len(dfAnlysSpecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For faster debugging : reduce work.\n",
    "#dfAnlysSpecs = dfAnlysSpecs[(dfAnlysSpecs.Passage == 'a+b') & (dfAnlysSpecs.Adulte == 'm') \\\n",
    "#                            & (dfAnlysSpecs['Durée'] == '10mn') \\\n",
    "#                            & ((dfAnlysSpecs.TrGche.isnull()) | (dfAnlysSpecs.TrGche < 20)) \\\n",
    "#                            & ((dfAnlysSpecs.TrDrte.isnull()) | (dfAnlysSpecs.TrDrte <= 500))]\n",
    "#len(dfAnlysSpecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnlysSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall analysis set without truncation params\n",
    "dfAnlysSpecs[['Espèce', 'Passage', 'Adulte', 'Durée', 'FonctionClé', 'SérieAjust']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir = tmpDir / 'mcds-anlr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4A. Or : Really run analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. MCDS Analyser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anlysr = ads.MCDSAnalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea,\n",
    "                          transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                          sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols,\n",
    "                          abbrevCol=anlysAbbrevCol, anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                          distanceUnit='Meter', areaUnit='Hectare',\n",
    "                          surveyType='Point', distanceType='Radial', clustering=False,\n",
    "                          resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                               after=[anlysAbbrevCol]),\n",
    "                          workDir=workDir, logProgressEvery=5,\n",
    "                          defEstimCriterion='AIC', defCVInterval=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Check analysis explicit specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnlysSpecs, userParamSpecCols, intParamSpecCols, unmUserParamSpecCols, verdict, reasons = \\\n",
    "    anlysr.explicitParamSpecs(dfExplParamSpecs=dfAnlysSpecs, dropDupes=True, check=True)\n",
    "\n",
    "assert len(dfAnlysSpecs) == 48\n",
    "assert userParamSpecCols == ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod']\n",
    "assert intParamSpecCols == ['EstimKeyFn', 'EstimAdjustFn', 'MinDist', 'MaxDist', 'FitDistCuts']\n",
    "assert unmUserParamSpecCols == []\n",
    "assert verdict\n",
    "assert not reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnlysSpecs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Run analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = anlysr.run(dfAnlysSpecs, threads=6)\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance figures on a Ruindows 10 laptop, 6-core i7-8850H, PCI-e SSD, \"optimal performances\" power scheme\n",
    "* 2019 or 2020 before 06: min=5, max=11s elapsed for 64 analyses\n",
    "\n",
    "Performance figures on a Ruindows 10 laptop, 4-core i5-8350U, PCI-e SSD, \"optimal performances\" power scheme\n",
    "* 2021-01: min=5.3, max=5.7s elapsed for 48 analyses\n",
    "* 2021-10-02: min=4.2s, max=5.7s (n=3) elapsed for 48 analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anlysr.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dfData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Save results for later reload or examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.toExcel(workDir / 'valtests-mcds-anlyser-results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.toExcel(workDir / 'valtests-mcds-anlyser-results-fr.xlsx', lang='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4B. Or : Load analyses from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    # An analyser object knowns how to build an empty results object ...\n",
    "    anlysr = ads.MCDSAnalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea,\n",
    "                              resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                                   after=[anlysAbbrevCol]),\n",
    "                              transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                              sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols,\n",
    "                              abbrevCol=anlysAbbrevCol, anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                              distanceUnit='Meter', areaUnit='Hectare',\n",
    "                              surveyType='Point', distanceType='Radial', clustering=False)\n",
    "    \n",
    "    results = anlysr.setupResults()\n",
    "    \n",
    "    # Load results from file.\n",
    "    resFileName = workDir / 'valtests-mcds-anlyser-results.xlsx'\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    results.fromExcel(resFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} analyses to compare'.format(len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare results to reference\n",
    "\n",
    "(reference generated with same kind of \"long\" code like in III above, but on another data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference\n",
    "# 1. Clone results _without_ data.\n",
    "rsRef = results.copy(withData=False)\n",
    "\n",
    "# 2. Load it with reference data (prevent re-postComputation as this ref. file is old, with now missing computed cols)\n",
    "rsRef.fromFile('refout/ACDC2019-Naturalist-ExtraitResultats.ods', postComputed=True)\n",
    "\n",
    "rsRef.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare (ignore sample and analysis indexes, no use here).\n",
    "indexCols = [col for col in results.miCustomCols.to_list() if '(sample)' in col[0]] \\\n",
    "            + [('parameters', 'estimator key function', 'Value'),\n",
    "               ('parameters', 'estimator adjustment series', 'Value'),\n",
    "               ('parameters', 'left truncation distance', 'Value'),\n",
    "               ('parameters', 'right truncation distance', 'Value'),\n",
    "               ('parameters', 'model fitting distance cut points', 'Value')]\n",
    "\n",
    "# Ignore also string params (comparison not implemented) and computed values.\n",
    "subsetCols = [col for col in results.dfData.columns.to_list() \\\n",
    "              if col in rsRef.columns\n",
    "                 and col not in (indexCols + [col for col in results.miCustomCols.to_list()\n",
    "                                              if '(sample)' not in col[0]]\n",
    "                                 + [('parameters', 'estimator selection criterion', 'Value'),\n",
    "                                    ('parameters', 'CV interval', 'Value'),\n",
    "                                    ('run output', 'start time', 'Value'),\n",
    "                                    ('run output', 'elapsed time', 'Value'),\n",
    "                                    ('run output', 'run folder', 'Value'),\n",
    "                                    ('detection probability', 'key function type', 'Value'),\n",
    "                                    ('detection probability', 'adjustment series type', 'Value'),\n",
    "                                    ('detection probability', 'Delta AIC', 'Value'),\n",
    "                                    ('density/abundance', 'density of animals', 'Delta Cv')])]\n",
    "\n",
    "dfDiff = rsRef.compare(results, indexCols=indexCols, subsetCols=subsetCols, dropCloser=12, dropNans=True)\n",
    "\n",
    "assert dfDiff.empty, 'No, no, no : not the same ...'\n",
    "\n",
    "print('Yessssss !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be perfectly honnest ... may be some 10**-12/15 glitches (due to worksheet I/O ?)\n",
    "rsRef.compare(results, indexCols=indexCols, subsetCols=subsetCols, dropCloser=14, dropNans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate HTML and Excel analyses reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-synthesis sub-report : Selected analysis results columns for the 3 textual columns of the table\n",
    "sampleRepCols = [\n",
    "    ('header (head)', 'NumEchant', 'Value'),\n",
    "    ('header (sample)', 'Espèce', 'Value'),\n",
    "    ('header (sample)', 'Passage', 'Value'),\n",
    "    ('header (sample)', 'Adulte', 'Value'),\n",
    "    ('header (sample)', 'Durée', 'Value'),\n",
    "    ('sample stats', 'total number of observations', 'Value'),\n",
    "    ('sample stats', 'maximal observation distance', 'Value'),\n",
    "]\n",
    "\n",
    "paramRepCols = [\n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    #('parameters', 'estimator selection criterion', 'Value'),\n",
    "    #('parameters', 'CV interval', 'Value'),\n",
    "    ('parameters', 'left truncation distance', 'Value'),\n",
    "    ('parameters', 'right truncation distance', 'Value'),\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'),\n",
    "]\n",
    "    \n",
    "resultRepCols = [\n",
    "    ('header (head)', 'NumAnlys', 'Value'),\n",
    "    ('run output', 'run status', 'Value'),\n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    ('encounter rate', 'effort (L or K or T)', 'Value'),\n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    \n",
    "    ('combined quality', 'balanced 1', 'Value'),\n",
    "    ('combined quality', 'balanced 2', 'Value'),\n",
    "    ('combined quality', 'balanced 3', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesis sub-report: Selected analysis results columns for the table\n",
    "synthRepCols = [\n",
    "    ('header (head)', 'NumEchant', 'Value'),\n",
    "    ('header (sample)', 'Espèce', 'Value'),\n",
    "    ('header (sample)', 'Passage', 'Value'),\n",
    "    ('header (sample)', 'Adulte', 'Value'),\n",
    "    ('header (sample)', 'Durée', 'Value'),\n",
    "    ('header (head)', 'NumAnlys', 'Value'),\n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    #('parameters', 'estimator selection criterion', 'Value'),\n",
    "    #('parameters', 'CV interval', 'Value'),\n",
    "    ('parameters', 'left truncation distance', 'Value'),\n",
    "    ('parameters', 'right truncation distance', 'Value'),\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'),\n",
    " \n",
    "    R.CLNTotObs, R.CLNObs, R.CLNTotPars, R.CLEffort, R.CLDeltaAic, R.CLChi2, R.CLKS, R.CLCvMUw, R.CLCvMCw, R.CLDCv, \n",
    "    R.CLPDetec, R.CLPDetecMin, R.CLPDetecMax, R.CLDensity, R.CLDensityMin, R.CLDensityMax,\n",
    "\n",
    "    R.CLSightRate,\n",
    "    R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3,\n",
    "    R.CLCmbQuaChi2, R.CLCmbQuaKS, R.CLCmbQuaDCv,\n",
    "\n",
    "    R.CLGrpOrdSmTrAic,\n",
    "    R.CLGrpOrdClTrChi2KSDCv, #R.CLGrpOrdClTrChi2,\n",
    "    R.CLGrpOrdClTrDCv,\n",
    "    R.CLGrpOrdClTrQuaBal1, R.CLGrpOrdClTrQuaBal2, R.CLGrpOrdClTrQuaBal3, R.CLGrpOrdClTrQuaChi2,\n",
    "    R.CLGrpOrdClTrQuaKS, R.CLGrpOrdClTrQuaDCv,\n",
    "    R.CLGblOrdChi2KSDCv, R.CLGblOrdQuaBal1, R.CLGblOrdQuaBal2, R.CLGblOrdQuaBal3,\n",
    "    R.CLGblOrdQuaChi2, R.CLGblOrdQuaKS, R.CLGblOrdQuaDCv,\n",
    "    R.CLGblOrdDAicChi2KSDCv,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting columns for all the sub-reports\n",
    "sortRepCols = \\\n",
    "[('header (head)', 'NumEchant', 'Value')] \\\n",
    "+ [('parameters', 'left truncation distance', 'Value'),\n",
    "   ('parameters', 'right truncation distance', 'Value'),\n",
    "   ('detection probability', 'Delta AIC', 'Value'),\n",
    "   ('combined quality', 'balanced 1', 'Value')]\n",
    "\n",
    "sortRepAscend = [True] * (len(sortRepCols) - 1) + [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ads.MCDSResultsFullReport(resultsSet=results, \n",
    "                                   sampleCols=sampleRepCols, paramCols=paramRepCols,\n",
    "                                   resultCols=resultRepCols, synthCols=synthRepCols,\n",
    "                                   sortCols=sortRepCols, sortAscend=sortRepAscend,\n",
    "                                   title='PyAuDiSam Validation: Analyses', subTitle='Global analyses report',\n",
    "                                   anlysSubTitle='Detailled report',\n",
    "                                   description='Easy and parallel run through MCDSAnalyser',\n",
    "                                   keywords='pyaudisam, validation, analysis', pySources=['valtests.ipynb'],\n",
    "                                   lang='en', superSynthPlotsHeight=288,\n",
    "                                   #plotImgSize=(640, 400), plotLineWidth=1, plotDotWidth=4,\n",
    "                                   #plotFontSizes=dict(title=11, axes=10, ticks=9, legend=10),\n",
    "                                   tgtFolder=workDir, tgtPrefix='valtests-analyser-report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsxAnlrRep = report.toExcel()\n",
    "\n",
    "HTML(f'Excel report: <a href=\"{xlsxAnlrRep}\" target=\"blank\">{xlsxAnlrRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.startfile(xlsxAnlrRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlAnlrRep = report.toHtml()  # Auto-number of parallel generators \n",
    "\n",
    "print('Report: ' + pl.Path(htmlAnlrRep).resolve().as_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Run truncation opt-analyses with same real life field data\n",
    "\n",
    "i.e. analyses with:\n",
    "* ready-to-go (const values) analysis parameters,\n",
    "* sometimes, some distance truncation parameters auto-computed:\n",
    "    * through some kind of optimisation process around MCDS.exe,\n",
    "    * from easily specified optimisation parameters.\n",
    "\n",
    "Thanks to MCDSTruncationOptanalyser class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data description and optanalysis parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run first\n",
    "* [II. Run pre-analyses / 0. Data Description](#II.-Run-pre-analyses)\n",
    "* [III. Run analyses with same real life field data / 0. Data Description](#III.-Run-analyses-with-same-real-life-field-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source / Results data\n",
    "transectPlaceCols = ['Point']\n",
    "passIdCol = 'Passage'\n",
    "effortCol = 'Effort'\n",
    "\n",
    "sampleDistCol = 'Distance'\n",
    "sampleDecCols = [effortCol, sampleDistCol]\n",
    "\n",
    "sampleNumCol = 'NumEchant'\n",
    "sampleSelCols = ['Espèce', passIdCol, 'Adulte', 'Durée']\n",
    "\n",
    "sampleAbbrevCol = 'AbrevEchant'\n",
    "\n",
    "optIndCol = 'IndOptim'\n",
    "optAbbrevCol = 'AbrevOptim'\n",
    "\n",
    "dSurveyArea = dict(Zone='ACDC', Surface='2400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General DS analysis parameters\n",
    "varIndCol = 'NumAnlys'\n",
    "anlysAbbrevCol = 'AbrevAnlys'\n",
    "anlysParamCols = ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod']\n",
    "\n",
    "distanceUnit = 'Meter'\n",
    "areaUnit = 'Hectare'\n",
    "surveyType = 'Point'\n",
    "distanceType = 'Radial'\n",
    "clustering = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default optimisation parameters.\n",
    "defEstimKeyFn = 'HNORMAL'\n",
    "defEstimAdjustFn = 'COSINE'\n",
    "defEstimCriterion = 'AIC'\n",
    "defCVInterval = 95\n",
    "defMinDist = None\n",
    "defMaxDist = None, \n",
    "defFitDistCuts = None\n",
    "defDiscrDistCuts = None\n",
    "\n",
    "defExpr2Optimise = 'chi2'\n",
    "defMinimiseExpr = False\n",
    "defOutliersMethod = 'tucquant'\n",
    "defOutliersQuantCutPct = 7\n",
    "defFitDistCutsFctr = ads.Interval(min=0.6, max=1.4)\n",
    "defDiscrDistCutsFctr = ads.Interval(min=0.5, max=1.2)\n",
    "\n",
    "defSubmitTimes = 1\n",
    "defSubmitOnlyBest = None\n",
    "\n",
    "defCoreEngine = 'zoopt'\n",
    "defCoreMaxIters = 100\n",
    "defCoreTermExprValue = None\n",
    "defCoreAlgorithm = 'racos'\n",
    "defCoreMaxRetries = 0\n",
    "\n",
    "dDefSubmitOtherParams = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results post-computation parameters\n",
    "ldTruncIntrvSpecs = [dict(col='left', minDist=5.0, maxLen=5.0),\n",
    "                     dict(col='right', minDist=25.0, maxLen=25.0)]\n",
    "truncIntrvEpsilon = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les analyses à faire (avec specs d'optimisation dedans si nécessaire)\n",
    "optanlysSpecFile = 'refin/ACDC2019-Naturalist-ExtraitSpecsOptanalyses.xlsx'\n",
    "#optanlysSpecFile = '../donnees/acdc/ACDC2019-Naturalist-ExtraitSpecsOptanalyses-reduit.ods'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimAbbrev(sAnlys):\n",
    "    \n",
    "    # Sample abbreviation\n",
    "    spcAbbrev = ''.join(word[:4].title() for word in sAnlys['Espèce'].split(' ')[:2])\n",
    "    sampAbbrev = [str(x) for x in [spcAbbrev, sAnlys.Passage.replace('+', ''),\n",
    "                                   sAnlys.Adulte.replace('+', ''), sAnlys['Durée']]]\n",
    "\n",
    "    # Model + Parameters abbreviation\n",
    "    modParAbbrev = [sAnlys['FonctionClé'][:3].lower(), sAnlys['SérieAjust'][:3].lower()]\n",
    "    \n",
    "    return '-'.join(sampAbbrev + modParAbbrev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Individuals data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les données individualisées et transects\n",
    "indivObsFile = 'refin/ACDC2019-Naturalist-ExtraitObsIndiv.ods'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsIndiv = ads.DataSet(indivObsFile, sheet='DonnéesIndiv').dfData\n",
    "len(dfObsIndiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsIndiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{ col: dfObsIndiv[col].unique() for col in ['Observateur', 'Point', 'Passage', 'Adulte', 'Durée', 'Espèce'] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Actual transects\n",
    "\n",
    "(can't deduce them from data, some points are missing because of data selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects = ads.DataSet(indivObsFile, sheet='Inventaires').dfData\n",
    "len(dfTransects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir = tmpDir / 'mcds-optanlr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to [3C. Or : Load opt-analyses results from a previous run](#3C.-Or-%3A-Load-opt-analyses-results-from-a-previous-run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A. Or : Really run opt-analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. MCDS Opt-Analyser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optanlr = \\\n",
    "    ads.MCDSTruncationOptanalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea, \n",
    "                                  transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                                  sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleDistCol=sampleDistCol,\n",
    "                                  abbrevCol=anlysAbbrevCol, abbrevBuilder=analysisAbbrev,\n",
    "                                  anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                                  distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                                  surveyType=surveyType, distanceType=distanceType, clustering=clustering,\n",
    "                                  resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                                       after=anlysParamCols + [anlysAbbrevCol]),\n",
    "                                  ldTruncIntrvSpecs=ldTruncIntrvSpecs, truncIntrvEpsilon=truncIntrvEpsilon,\n",
    "                                  workDir=workDir, runMethod='subprocess.run', runTimeOut=120,\n",
    "                                  #runMethod='os.system', runTimeOut=None,  # Uncomment to test os.system run method.\n",
    "                                  logAnlysProgressEvery=5, logOptimProgressEvery=3, backupOptimEvery=5,\n",
    "                                  defEstimKeyFn=defEstimKeyFn, defEstimAdjustFn=defEstimAdjustFn,\n",
    "                                  defEstimCriterion=defEstimCriterion, defCVInterval=defCVInterval,\n",
    "                                  defExpr2Optimise=defExpr2Optimise, defMinimiseExpr=defMinimiseExpr,\n",
    "                                  defOutliersMethod=defOutliersMethod, defOutliersQuantCutPct=defOutliersQuantCutPct,\n",
    "                                  defFitDistCutsFctr=defFitDistCutsFctr, defDiscrDistCutsFctr=defDiscrDistCutsFctr,\n",
    "                                  defSubmitTimes=defSubmitTimes, defSubmitOnlyBest=defSubmitOnlyBest,\n",
    "                                  dDefSubmitOtherParams=dDefSubmitOtherParams,\n",
    "                                  dDefOptimCoreParams=dict(core=defCoreEngine, maxIters=defCoreMaxIters,\n",
    "                                                           termExprValue=defCoreTermExprValue,\n",
    "                                                           algorithm=defCoreAlgorithm, maxRetries=defCoreMaxRetries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(optanlr.specs) == 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Check opt-analyses specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnlysSpecs, userParamSpecCols, intParamSpecCols, unmUserParamSpecCols, verdict, reasons = \\\n",
    "    optanlr.explicitParamSpecs(implParamSpecs=optanlysSpecFile, dropDupes=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dfAnlysSpecs) == 60\n",
    "assert userParamSpecCols == ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod', 'MultiOpt']\n",
    "assert intParamSpecCols == ['EstimKeyFn', 'EstimAdjustFn', 'MinDist', 'MaxDist', 'FitDistCuts', 'SubmitParams']\n",
    "assert unmUserParamSpecCols == []\n",
    "assert verdict\n",
    "assert not reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnlysSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfAnlysSpecs))\n",
    "if not verdict:\n",
    "    print(reasons)\n",
    "    print(userParamSpecCols, intParamSpecCols, unmUserParamSpecCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Run opt-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('* OptAnalyser specs:', ', '.join(f'{k}={v}' for k, v in optanlr.specs.items()))\n",
    "print('* OptAnalyses specs:', len(dfAnlysSpecs), 'optimisations from', optanlysSpecFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = optanlr.run(implParamSpecs=optanlysSpecFile, threads=12)\n",
    "#results = optanlr.run(dfExplParamSpecs=dfAnlysSpecs.loc[51:52], threads=1)  # A small sample, for a quicker check\n",
    "\n",
    "optanlr.shutdown()\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances figures on a 4-core i5-8350U Ruindows 10 laptop with PCI-e SSD, \"optimal performance power scheme\", 12 threads, Python 3.8 :\n",
    "* 2021-01-05\n",
    "  * OptAnalyserspecs: Zone=ACDC, Surface=2400, distanceUnit=Meter, areaUnit=Hectare, surveyType=Point, distanceType=Radial, clustering=False, defEstimKeyFn=HNORMAL, defEstimAdjustFn=COSINE, defEstimCriterion=AIC, defCVInterval=95, defMinDist=None, defMaxDist=None, defFitDistCuts=None, defDiscrDistCuts=None, defExpr2Optimise=chi2, defMinimiseExpr=False, dDefOptimCoreParams={'core': 'zoopt', 'maxIters': 100, 'termExprValue': None, 'algorithm': 'racos', 'maxRetries': 0}, defSubmitTimes=1, defSubmitOnlyBest=None, dDefSubmitOtherParams={}, defOutliersMethod=tucquant, defOutliersQuantCutPct=7, defFitDistCutsFctr=[0.6, 1.4], defDiscrDistCutsFctr=[0.5, 1.2]\n",
    "  * OptAnalyses specs: 60 optimisations, from refin/ACDC2019-Naturalist-ExtraitSpecsOptanalyses.xlsx => 70 resultats,\n",
    "  * runMethod: subprocess.run => 4mn40, 4mn52, 4mn38, 4mn23, 4mn40, 5mn00, 4mn41, 4mn35, 4mn47 (mean 4mn42)\n",
    "  * runMethod: os.system      => 4mn35, 4mn24, 4mn20, 4mn30 (mean 4mn27)\n",
    "\n",
    "* 2021-08-22, 2021-10-02\n",
    "  * same OptAnalyserspecs, OptAnalyses specs\n",
    "  * runMethod: subprocess.run => 4mn35 (n >= 2)\n",
    "  \n",
    "* 2021-10-06\n",
    "  * same OptAnalyserspecs, OptAnalyses specs\n",
    "  * runMethod: subprocess.run => 4mn08 (n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array([eval(x) for x in \"4mn35, 4mn24, 4mn20, 4mn30,\".replace('mn', '+').replace(',', '/60,')[:-1].split(',')]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ads.MCDSTruncationOptanalyser.OptimTruncFlagCol in results.dfTransData('fr').columns\n",
    "# Note: This also runs post-computations ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.dfTransData('fr').to_excel('tmp/res-tst.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results._dfData.to_excel('tmp/rawres-tst.xlsx')\n",
    "\n",
    "results._dfData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Save results for later reload or examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.toExcel(workDir / 'valtests-mcds-optanlyser-results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.toOpenDoc(workDir / 'valtests-mcds-optanlyser-results-fr.ods', lang='fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.fromExcel(workDir / 'valtests-mcds-optanlyser-results.xlsx', specs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B. Or : Restart opt-analyses from recovery files\n",
    "\n",
    "(already run above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. MCDS Opt-Analyser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Must be a real clone of the 3A optanalyser (about data, not technical run stuff),\n",
    "# otherwise recovery might not work.\n",
    "optanlr = \\\n",
    "    ads.MCDSTruncationOptanalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea, \n",
    "                                  transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                                  sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleDistCol=sampleDistCol,\n",
    "                                  abbrevCol=anlysAbbrevCol, abbrevBuilder=analysisAbbrev,\n",
    "                                  anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                                  distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                                  surveyType=surveyType, distanceType=distanceType, clustering=clustering,\n",
    "                                  resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                                       after=anlysParamCols + [anlysAbbrevCol]),\n",
    "                                  ldTruncIntrvSpecs=ldTruncIntrvSpecs, truncIntrvEpsilon=truncIntrvEpsilon,\n",
    "                                  workDir=workDir, logAnlysProgressEvery=5, logOptimProgressEvery=3,\n",
    "                                  defEstimKeyFn=defEstimKeyFn, defEstimAdjustFn=defEstimAdjustFn,\n",
    "                                  defEstimCriterion=defEstimCriterion, defCVInterval=defCVInterval,\n",
    "                                  defExpr2Optimise=defExpr2Optimise, defMinimiseExpr=defMinimiseExpr,\n",
    "                                  defOutliersMethod=defOutliersMethod, defOutliersQuantCutPct=defOutliersQuantCutPct,\n",
    "                                  defFitDistCutsFctr=defFitDistCutsFctr, defDiscrDistCutsFctr=defDiscrDistCutsFctr,\n",
    "                                  defSubmitTimes=defSubmitTimes, defSubmitOnlyBest=defSubmitOnlyBest,\n",
    "                                  dDefSubmitOtherParams=dDefSubmitOtherParams,\n",
    "                                  dDefOptimCoreParams=dict(core=defCoreEngine, maxIters=defCoreMaxIters,\n",
    "                                                           termExprValue=defCoreTermExprValue,\n",
    "                                                           algorithm=defCoreAlgorithm, maxRetries=defCoreMaxRetries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(optanlr.specs) == 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Check opt-analyses specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnlysSpecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Run opt-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results2 = optanlr.run(implParamSpecs=optanlysSpecFile, recoverOptims=True, threads=12)\n",
    "\n",
    "# A small sample, for a quicker check\n",
    "#results2 = optanlr.run(dfExplParamSpecs=dfAnlysSpecs.loc[51:52], recoverOptims=True, threads=1)\n",
    "\n",
    "optanlr.shutdown()\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Save results for later reload or examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.toExcel(workDir / 'valtests-mcds-optanlyser-results2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3C. Or : Load opt-analyses results from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'computed' not in dir():\n",
    "    computed = False\n",
    "\n",
    "if not computed:\n",
    "    \n",
    "    # An opt-analyser object knowns how to build an empty results object ...\n",
    "    optanlr = \\\n",
    "        ads.MCDSTruncationOptanalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea, \n",
    "                                      transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                                      sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols,\n",
    "                                      sampleDistCol=sampleDistCol,\n",
    "                                      abbrevCol=anlysAbbrevCol, abbrevBuilder=analysisAbbrev,\n",
    "                                      anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                                      distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                                      surveyType=surveyType, distanceType=distanceType, clustering=clustering,\n",
    "                                      resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                                           after=anlysParamCols + [anlysAbbrevCol]),\n",
    "                                      ldTruncIntrvSpecs=ldTruncIntrvSpecs, truncIntrvEpsilon=truncIntrvEpsilon)\n",
    "\n",
    "    results = optanlr.setupResults()\n",
    "    \n",
    "    # Load results from file.\n",
    "    resFileName = workDir / 'valtests-mcds-optanlyser-results.xlsx'\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    results.fromExcel(resFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} analyses to compare'.format(len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to [5. Generate HTML and Excel opt-analyses reports](#5.-Generate-HTML-and-Excel-opt-analyses-reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D. Generate reference for non-regression tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Clone results _without_ data.\n",
    "#results3 = results.copy(withData=True)\n",
    "#\n",
    "## 2. Remove analyses with non-unique 'NumAnlys' (because of multiple optimisation tries)\n",
    "##    (to make comparison easier, sorry)\n",
    "#numAnlysCols = ('header (head)', 'NumAnlys', 'Value')\n",
    "#numEchantCol = ('header (head)', 'NumEchant', 'Value')\n",
    "#\n",
    "#sb = results3.dfData[[numAnlysCols, numEchantCol]].groupby([numAnlysCols]).transform(len)[numEchantCol] > 1\n",
    "#results3.dropRows(sb)\n",
    "#\n",
    "#results3.toExcel(workDir / 'valtests-mcds-optanlyser-results.ref.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare analyses results to reference\n",
    "\n",
    "(reference analysis results generated with same kind of \"long\" code like in [valarchives.ipynb / I. Run analyses with real life field data (1/2 : long code, long run)](./valarchives.ipynb#I.-Run-analyses-with-real-life-field-data-(1%2F2-%3A-long-code%2C-long-run)), but on another data set)\n",
    "\n",
    "Note: As for now, filter and sort post-computed columns are not checked here ; only DS analyses are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Load reference unoptimised analyses results from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unoptimised reference\n",
    "# 1. Clone results _without_ data.\n",
    "rsUnoptRef = results.copy(withData=False)\n",
    "\n",
    "# 2. Load it with reference data (prevent re-postComputation as this ref. file is old, with now missing computed cols)\n",
    "rsUnoptRef.fromOpenDoc('refout/ACDC2019-Naturalist-ExtraitResultats.ods', postComputed=True)\n",
    "\n",
    "unoptAnlysAbbrevs = list(rsUnoptRef.dfData[('header (tail)', anlysAbbrevCol, 'Value')])\n",
    "\n",
    "len(unoptAnlysAbbrevs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Separate actual optanalysis results in 2 sets : optimised, and unoptimised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unoptimised results.\n",
    "rsUnoptRes = results.copy()\n",
    "#rsUnoptRes = results2.copy() # For recovered run\n",
    "\n",
    "rsUnoptRes.dropRows(~rsUnoptRes.dfData[('header (tail)', anlysAbbrevCol, 'Value')].isin(unoptAnlysAbbrevs))\n",
    "\n",
    "#rsUnoptRes.dfTransData('fr').to_excel('tmp/res.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimised results.\n",
    "rsOptRes = results.copy()\n",
    "\n",
    "rsOptRes.dropRows(rsOptRes.dfData[('header (tail)', anlysAbbrevCol, 'Value')].isin(unoptAnlysAbbrevs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(unoptRef=len(rsUnoptRef), unoptRes=len(rsUnoptRes), optRes=len(rsOptRes), allRes=len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Compare \"unoptimised\" analyses results to reference ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare (ignore sample and analysis indexes, no use here).\n",
    "indexCols = [col for col in rsUnoptRes.miCustomCols.to_list() if '(sample)' in col[0]] \\\n",
    "            + [('parameters', 'estimator key function', 'Value'),\n",
    "               ('parameters', 'estimator adjustment series', 'Value'),\n",
    "               ('parameters', 'left truncation distance', 'Value'),\n",
    "               ('parameters', 'right truncation distance', 'Value'),\n",
    "               ('parameters', 'model fitting distance cut points', 'Value'),\n",
    "               ('header (tail)', 'AbrevAnlys', 'Value')]\n",
    "subsetCols = [col for col in rsUnoptRes.columns.to_list() \\\n",
    "              if col in rsUnoptRef.columns\n",
    "                 and col not in (indexCols + [col for col in rsUnoptRes.miCustomCols.to_list()\n",
    "                                              if '(sample)' not in col[0]]\n",
    "                                 + [('parameters', 'estimator selection criterion', 'Value'),\n",
    "                                    ('parameters', 'CV interval', 'Value'),\n",
    "                                    ('run output', 'start time', 'Value'),\n",
    "                                    ('run output', 'elapsed time', 'Value'),\n",
    "                                    ('run output', 'run folder', 'Value'),\n",
    "                                    ('detection probability', 'Delta AIC', 'Value'),\n",
    "                                    ('detection probability', 'key function type', 'Value'),\n",
    "                                    ('detection probability', 'adjustment series type', 'Value')])]\n",
    "\n",
    "dfDiff = rsUnoptRef.compare(rsUnoptRes, indexCols=indexCols, subsetCols=subsetCols, dropCloser=14, dropNans=True)\n",
    "\n",
    "assert dfDiff.empty, 'No, no, no : not the same ...'\n",
    "\n",
    "print('Yessssss !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be perfectly honest, may be some 10^-15 differences (when some results loaded from Excel, some other not).\n",
    "rsUnoptRef.compare(rsUnoptRes, indexCols=indexCols, subsetCols=subsetCols, dropCloser=15, dropNans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Compare \"with optimisation\" analysis results to \"reference\" ones\n",
    "\n",
    "**Warning** :\n",
    "* reference = analyses results computed through [valarchives.ipynb / VII. Truncation optimisation (short code and fast run) / 6A. Or : Really run analyses](./valarchives.ipynb#VII.-Truncation-optimisation-(short-code-and-fast-run))\n",
    "* with [IV. 0. Optanalyser parameters]((#0.-Optanalyser-parameters) exactly the same\n",
    "* using variant 'main' for [3. Samples and analyses to optimise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimised reference (analysis results with truncation params computed through optimisation)\n",
    "# 1. Clone results _without_ data.\n",
    "rsOptRef = results.copy(withData=False)\n",
    "\n",
    "# 2. Load it with reference data (need to enforce presence of OptimTrunc column, as the source file may have been\n",
    "#    built with an MCDSAnalisysResultsSet, not an MCDSOptanalisysResultsSet, the actual class of results ;\n",
    "#    otherwise, postCompute will fail ... => dDefMissingCols arg)\n",
    "rsOptRef.fromExcel(f'tmp/mcds-anaftopt/valarc-mcds-analyser-afteropt-main-results.xlsx', \n",
    "                   dDefMissingCols={('header (tail)', 'OptimTrunc', 'Value'): np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort rows for each analysis optim param specs ... by left truncation distance first\n",
    "miSortCols = [('header (tail)', 'AbrevAnlys', 'Value'),\n",
    "              ('parameters', 'left truncation distance', 'Value'),\n",
    "              ('parameters', 'right truncation distance', 'Value'),\n",
    "              ('parameters', 'model fitting distance cut points', 'Value')]\n",
    "\n",
    "rsOptRes.sortRows(by=miSortCols)\n",
    "rsOptRef.sortRows(by=miSortCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple columns index (fr) + setup sorted analyses index\n",
    "miAnlysNumCol = 'NumAnlys'\n",
    "dfOptRes = rsOptRes.dfTransData('fr')\n",
    "dfOptRes[miAnlysNumCol] = [i for i in range(len(dfOptRes))]\n",
    "dfOptRef = rsOptRef.dfTransData('fr')\n",
    "dfOptRef[miAnlysNumCol] = [i for i in range(len(dfOptRef))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that order is \"compatible\" between reference and actual results\n",
    "miAnlysAbrevCol = 'AbrevAnlys'\n",
    "\n",
    "assert dfOptRes[miAnlysAbrevCol].to_list() == dfOptRef[miAnlysAbrevCol].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk for visual checks / comparison\n",
    "#dfOptRes.to_excel('tmp/opt-res-fr.xlsx')\n",
    "#dfOptRef.to_excel('tmp/opt-ref-fr.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare a simple subset of analyses results ...\n",
    "indexCols = [miAnlysNumCol, miAnlysAbrevCol]\n",
    "subsetCols = ['AIC', 'PDetec', 'EDR/ESW', 'Densité']\n",
    "\n",
    "dfDiff = ads.DataSet.compareDataFrames(dfOptRes, dfOptRef, indexCols=indexCols, subsetCols=subsetCols, dropNans=True)\n",
    "\n",
    "dfDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some diff. stats\n",
    "dfDiffStats = pd.DataFrame(data=[dfDiff.min(), dfDiff.max(), dfDiff.replace(np.inf, 16).mean()],\n",
    "                           index=['min', 'max', 'mean'])\n",
    "dfDiffStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not too bad if less that 10% mean difference (100 / 10**1 = 10%) !\n",
    "assert dfDiffStats.loc['mean'].min() >= 1.0\n",
    "\n",
    "# And actually at most P % difference : let's compute P ...\n",
    "p = 100 / 10**dfDiffStats.loc['mean'].min()\n",
    "\n",
    "assert p < 10, f'Oh oh ... {p=} >= 10 %'\n",
    "\n",
    "print(f'Good: {p=:.2f} < 10 %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk after \"merging\" ref and actual results, again for visual checks\n",
    "dfOptRef.insert(0, 'x', 'ref')\n",
    "dfOptRes.insert(0, 'x', 'res')\n",
    "\n",
    "dfOptComp = dfOptRef.append(dfOptRes, sort=False)\n",
    "\n",
    "dfOptComp.sort_values(by=['NumAnlys', 'x'], inplace=True)\n",
    "\n",
    "dfOptComp.to_excel('tmp/opt-comp.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Some history of computations difference stats with various 'maxIters' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep stats for history ... copy/paste results below ...\n",
    "print('**maxIters={} (N=?): max delta = {:.2f} %**'.format(defCoreMaxIters, 100 / 10**dfDiffStats.loc['mean'].min()))\n",
    "print()\n",
    "print(dfDiffStats.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**maxIter=100 (N=6, last on 2021-10-16) : max delta = 3.6 %, 3.7 %, 6.44 %, 5.01 %, 5.12 %, 3.55 %**\n",
    "\n",
    "|      |     AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|--------:|---------:|----------:|----------:|\n",
    "| min  | 1.1     |  0.2     |   0.4     |   0.2     |\n",
    "| max  | 6.3     |  4.6     |   4.9     |   4.6     |\n",
    "| mean | 2.06818 |  1.29091 |   1.85455 |   1.54545 |\n",
    "    \n",
    "|      |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1       |  0.2     |       0.6 |   0.4     |\n",
    "| max  | inf       |  4.9     |     inf   | inf       |\n",
    "| mean |   2.82273 |  1.44545 |       2.7 |   2.40455 |\n",
    "\n",
    "|      |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.1     |  0.3     |   0.5     |   0.3     |\n",
    "| max  | inf       |  4.5     |   5.4     |   4.5     |\n",
    "| mean |   2.63182 |  1.49091 |   2.03182 |   1.43182 |\n",
    "\n",
    "|      |     AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|--------:|---------:|----------:|----------:|\n",
    "| min  | 1       |  0.2     |   0.5     |   0.3     |\n",
    "| max  | 5.7     |  4.3     |   4.6     |   4.3     |\n",
    "| mean | 1.92273 |  1.19091 |   1.80455 |   1.50455 |\n",
    "\n",
    "|      |     AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|--------:|---------:|----------:|----------:|\n",
    "| min  | 1       |      0.2 |   0.8     |   0.6     |\n",
    "| max  | 4.6     |      3.4 |   3.7     |   3.4     |\n",
    "| mean | 1.80909 |      1.3 |   1.73636 |   1.53182 |\n",
    "\n",
    "|      |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.2     |     0.2  |   0.9     |   0.6     |\n",
    "| max  | inf       |     4.1  | inf       | inf       |\n",
    "| mean |   2.64091 |     1.45 |   2.55455 |   2.28182 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**maxIter=120 (N=3) : max delta = 6.1 %, 1.6 %, 1.7 %**\n",
    "\n",
    "|Exec1 |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.1     |  0.2     |   0.9     |   0.6     |\n",
    "| max  | inf       |  5.1     | inf       |   6.5     |\n",
    "| mean |   2.37273 |  1.21364 |   2.15909 |   1.47273 |\n",
    "\n",
    "|Exec2 |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.1     |  0.2     |   0.8     |   0.6     |\n",
    "| max  | inf       |  5       | inf       | inf       |\n",
    "| mean |   3.15455 |  1.79545 |   2.82273 |   2.47273 |\n",
    "\n",
    "|Exec3 |     AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|--------:|---------:|----------:|----------:|\n",
    "| min  | 1.1     |  0.3     |   0.6     |   0.4     |\n",
    "| max  | 6.6     |  4.9     |   5.2     |   4.9     |\n",
    "| mean | 2.57727 |  1.76818 |   2.21364 |   1.92273 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**maxIter=250 (N=3) : max delta = 0.83 %, 3.4 %, 0.53 %**\n",
    "\n",
    "|Exec1 |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.1     |  0.4     |   0.8     |   0.6     |\n",
    "| max  | inf       |  5.9     | inf       | inf       |\n",
    "| mean |   4.39545 |  2.08182 |   2.95455 |   2.68636 |\n",
    "\n",
    "|Exec2 |     AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|--------:|---------:|----------:|----------:|\n",
    "| min  | 1       |  0.4     |   0.5     |      0.3  |\n",
    "| max  | 6.7     |  5.4     |   5.7     |      5.5  |\n",
    "| mean | 2.18636 |  1.46818 |   1.82273 |      1.55 |\n",
    "\n",
    "|Exec3 |       AIC |    PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|----------:|----------:|----------:|\n",
    "| min  |   1       |   0.3     |   0.9     |   0.6     |\n",
    "| max  | inf       | inf       | inf       | inf       |\n",
    "| mean |   3.76818 |   2.27727 |   3.50909 |   3.24091 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**maxIters=400 (N=4): max delta = 2.6 %, 2.9%, 1.9%, 1.8%**\n",
    "\n",
    "|Exec1 |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.1     |  0.1     |   0.5     |   0.3     |\n",
    "| max  | inf       |  6.7     | inf       |   6.4     |\n",
    "| mean |   3.03182 |  1.57727 |   2.65455 |   1.89091 |\n",
    "\n",
    "|Exec2 |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.1     |  0.3     |   0.9     |   0.6     |\n",
    "| max  | inf       |  4.3     |   5       |   4.7     |\n",
    "| mean |   2.79091 |  1.54091 |   2.08182 |   1.80909 |\n",
    "\n",
    "|Exec3 |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.1     |  0.2     |   0.5     |   0.3     |\n",
    "| max  | inf       |  6.7     | inf       |  15.9     |\n",
    "| mean |   3.40455 |  1.71818 |   2.46364 |   2.24545 |\n",
    "\n",
    "|Exec4 |       AIC |   PDetec |   EDR/ESW |   Densité |\n",
    "|:-----|----------:|---------:|----------:|----------:|\n",
    "| min  |   1.1     |  0.2     |      0.8  |   0.6     |\n",
    "| max  |   6.7     |  4.9     |      5.2  |   4.9     |\n",
    "| mean |   2.66818 |  1.74091 |      2.45 |   2.18636 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate HTML and Excel opt-analyses reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-synthesis sub-report : Selected analysis results columns for the 3 textual columns of the table\n",
    "sampleCols = [\n",
    "    ('header (head)', 'NumEchant', 'Value'),\n",
    "    ('header (sample)', 'Espèce', 'Value'),\n",
    "    ('header (sample)', 'Passage', 'Value'),\n",
    "    ('header (sample)', 'Adulte', 'Value'),\n",
    "    ('header (sample)', 'Durée', 'Value'),\n",
    "    \n",
    "    R.CLNTotObs, R.CLMaxObsDist]\n",
    "\n",
    "paramCols = [\n",
    "    ('header (head)', 'NumAnlys', 'Value'),\n",
    "    R.CLParEstKeyFn, R.CLParEstAdjSer]\n",
    "    \n",
    "resultCols = [\n",
    "    R.CLRunStatus,\n",
    "    R.CLNObs, R.CLEffort,\n",
    "    R.CLAic, R.CLChi2, R.CLKS, R.CLDCv,\n",
    "    R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3,\n",
    "    \n",
    "    R.CLEswEdr, R.CLPDetec, R.CLDensity, R.CLDensityMin, R.CLDensityMax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesis sub-report : Selected analysis results columns for the table\n",
    "synthCols = [\n",
    "    ('header (head)', 'NumEchant', 'Value'),\n",
    "    ('header (sample)', 'Espèce', 'Value'),\n",
    "    ('header (sample)', 'Passage', 'Value'),\n",
    "    ('header (sample)', 'Adulte', 'Value'),\n",
    "    ('header (sample)', 'Durée', 'Value'),\n",
    "\n",
    "    ('header (head)', 'NumAnlys', 'Value'),\n",
    "    R.CLParEstKeyFn, R.CLParEstAdjSer,\n",
    "    #R.CLParEstSelCrit, R.CLParEstCVInt,\n",
    "    R.CLParTruncLeft, R.CLParTruncRight, R.CLParModFitDistCuts,\n",
    " \n",
    "    R.CLNTotObs, R.CLNObs, R.CLNTotPars, R.CLEffort,\n",
    "    R.CLDeltaAic, R.CLChi2, R.CLKS, R.CLCvMUw, R.CLCvMCw, R.CLDCv, \n",
    "    R.CLSightRate,\n",
    "    R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3,\n",
    "    R.CLCmbQuaChi2, R.CLCmbQuaKS, R.CLCmbQuaDCv,\n",
    "\n",
    "    R.CLPDetec, R.CLPDetecMin, R.CLPDetecMax, R.CLDensity, R.CLDensityMin, R.CLDensityMax,\n",
    "\n",
    "    R.CLGrpOrdSmTrAic,\n",
    "    R.CLGrpOrdClTrChi2KSDCv, #R.CLGrpOrdClTrChi2,\n",
    "    R.CLGrpOrdClTrDCv,\n",
    "    R.CLGrpOrdClTrQuaBal1, R.CLGrpOrdClTrQuaBal2, R.CLGrpOrdClTrQuaBal3, R.CLGrpOrdClTrQuaChi2,\n",
    "    R.CLGrpOrdClTrQuaKS, R.CLGrpOrdClTrQuaDCv,\n",
    "    R.CLGblOrdChi2KSDCv, R.CLGblOrdQuaBal1, R.CLGblOrdQuaBal2, R.CLGblOrdQuaBal3,\n",
    "    R.CLGblOrdQuaChi2, R.CLGblOrdQuaKS, R.CLGblOrdQuaDCv,\n",
    "    R.CLGblOrdDAicChi2KSDCv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and sort sub-reports : schemes to apply\n",
    "whichFinalQua = R.CLCmbQuaBal3\n",
    "ascFinalQua = False\n",
    "\n",
    "whichBestQua = [R.CLGrpOrdClTrChi2KSDCv, R.CLGrpOrdClTrDCv, whichFinalQua,\n",
    "               R.CLGrpOrdClTrQuaChi2, R.CLGrpOrdClTrQuaKS, R.CLGrpOrdClTrQuaDCv]\n",
    "\n",
    "dupSubset = [R.CLNObs, R.CLEffort, R.CLDeltaAic, R.CLChi2, R.CLKS, R.CLCvMUw, R.CLCvMCw, R.CLDCv, \n",
    "             R.CLPDetec, R.CLPDetecMin, R.CLPDetecMax, R.CLDensity, R.CLDensityMin, R.CLDensityMax]\n",
    "dDupRounds = {R.CLDeltaAic: 1, R.CLChi2: 2, R.CLKS: 2, R.CLCvMUw: 2, R.CLCvMCw: 2, R.CLDCv: 2, \n",
    "              R.CLPDetec: 3, R.CLPDetecMin: 3, R.CLPDetecMax: 3, R.CLDensity: 2, R.CLDensityMin: 2, R.CLDensityMax: 2}\n",
    "\n",
    "filSorSchemes = [dict(method=ads.MCDSTruncOptanalysisResultsSet.filterSortOnExecCode,\n",
    "                      deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                      filterSort=dict(whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                      preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                      preselAscs=False, preselThrhs=0.2, preselNum=4),\n",
    "                 dict(method=ads.MCDSTruncOptanalysisResultsSet.filterSortOnExCAicMulQua,\n",
    "                      deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                      filterSort=dict(sightRate=90, nBestAIC=4, nBestQua=2, whichBestQua=whichBestQua,\n",
    "                                      nFinalRes=15, whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                      preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                      preselAscs=False, preselThrhs=0.2, preselNum=3),\n",
    "                 dict(method=ads.MCDSTruncOptanalysisResultsSet.filterSortOnExCAicMulQua,\n",
    "                      deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                      filterSort=dict(sightRate=92, nBestAIC=3, nBestQua=2, whichBestQua=whichBestQua,\n",
    "                                      nFinalRes=12, whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                      preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                      preselAscs=False, preselThrhs=0.2, preselNum=3),\n",
    "                 dict(method=ads.MCDSTruncOptanalysisResultsSet.filterSortOnExCAicMulQua,\n",
    "                      deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                      filterSort=dict(sightRate=94, nBestAIC=2, nBestQua=1, whichBestQua=whichBestQua,\n",
    "                                      nFinalRes=10, whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                      preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                      preselAscs=False, preselThrhs=0.2, preselNum=3),\n",
    "                 dict(method=ads.MCDSTruncOptanalysisResultsSet.filterSortOnExCAicMulQua,\n",
    "                      deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                      filterSort=dict(sightRate=96, nBestAIC=2, nBestQua=1, whichBestQua=whichBestQua,\n",
    "                                      nFinalRes=8, whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                      preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                      preselAscs=False, preselThrhs=0.2, preselNum=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afsReport = ads.MCDSResultsFilterSortReport(resultsSet=results,\n",
    "                                            title=\"PyAuDiSam Validation : Analyses with optimised truncations\",\n",
    "                                            subTitle=\"Auto-selection of best results\",\n",
    "                                            description='Automated filtering et sorting : method \"{fsId}\" ; after '\n",
    "                                                        'easy and parallel run through MCDSTruncationOptAnalyser',\n",
    "                                            anlysSubTitle='Analyses details',\n",
    "                                            lang='en', keywords='pyaudisam, validation, optimisation',\n",
    "                                            superSynthPlotsHeight=280, plotImgSize=(512, 280),\n",
    "                                            sampleCols=sampleCols, paramCols=paramCols,\n",
    "                                            resultCols=resultCols, synthCols=synthCols,\n",
    "                                            filSorSchemes=filSorSchemes, \n",
    "                                            tgtFolder=workDir, tgtPrefix='valtests-autofilsor-report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLSX report\n",
    "xlsxAFXRep = afsReport.toExcel()\n",
    "\n",
    "HTML(f'Auto-filtered Excel report: <a href=\"{xlsxAFXRep}\" target=\"blank\">{xlsxAFXRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.startfile(xlsxAFXRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select scheme to apply for HTML report.\n",
    "scheme = next(sch for sch in filSorSchemes \n",
    "              if sch['method'] is ads.MCDSTruncOptanalysisResultsSet.filterSortOnExCAicMulQua\n",
    "                 and sch['filterSort']['sightRate'] == 92)\n",
    "print(results.dFilSorSchemes.keys(), '\\n=>', results.filSorSchemeId(scheme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HTML report\n",
    "htmlAFSRep = afsReport.toHtml(filSorScheme=scheme, rebuild=False)\n",
    "\n",
    "afsId = results.filSorSchemeId(scheme)\n",
    "print(f'Auto-filtered HTML report({afsId} scheme): ' + pl.Path(htmlAFSRep).resolve().as_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Simple checks on opt-analyses reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xlsxAFXRep = 'tmp/mcds-optanlr/valtests-autofilsor-report.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel report\n",
    "ddfAfsXlsxReport = pd.read_excel(xlsxAFXRep, sheet_name=None)\n",
    "\n",
    "snPrfx = 'AFSM-'\n",
    "{sn[len(snPrfx):]: len(ddfAfsXlsxReport[sn]) for sn in ddfAfsXlsxReport if sn.startswith(snPrfx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check expected number of results for each filter and sort method.\n",
    "KExpectedNbOfResults = {'ExCode': 70, 'ExAicMQua-r900m6q3d15': 51, 'ExAicMQua-r920m6q3d12': 47,\n",
    "                        'ExAicMQua-r940m6q3d10': 36, 'ExAicMQua-r960m6q3d8': 28}  # OK on 2021-11-05 & 06\n",
    "\n",
    "assert all(len(ddfAfsXlsxReport[sn]) == KExpectedNbOfResults[sn[len(snPrfx):]]\n",
    "           for sn in ddfAfsXlsxReport if sn.startswith(snPrfx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some results\n",
    "dfAfsXlsxRes = pd.read_excel(xlsxAFXRep, sheet_name='Details')\n",
    "len(dfAfsXlsxRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAfsXlsxRes[['NumEchant', 'NumAnlys', 'Group Left Trunc', 'Group Right Trunc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference Excel report\n",
    "xlsxAFXRefRep = 'tmp/mcds-optanlr/valtests-autofilsor-report.211105.xlsx'\n",
    "ddfAfsXlsxRefReport = pd.read_excel(xlsxAFXRefRep, sheet_name=None)\n",
    "\n",
    "snPrfx = 'AFSM-'\n",
    "{sn[len(snPrfx):]: len(ddfAfsXlsxRefReport[sn]) for sn in ddfAfsXlsxRefReport if sn.startswith(snPrfx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check expected number of results for each filter and sort method.\n",
    "KExpectedNbOfResults = {'ExCode': 70, 'ExAicMQua-r900m6q3d15': 51, 'ExAicMQua-r920m6q3d12': 47,\n",
    "                        'ExAicMQua-r940m6q3d10': 36, 'ExAicMQua-r960m6q3d8': 28}  # OK on 2021-11-05 & 06\n",
    "\n",
    "assert all(len(ddfAfsXlsxRefReport[sn]) == KExpectedNbOfResults[sn[len(snPrfx):]]\n",
    "           for sn in ddfAfsXlsxRefReport if sn.startswith(snPrfx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check some results\n",
    "dfAfsXlsxRefRes = pd.read_excel(xlsxAFXRefRep, sheet_name='Details')\n",
    "len(dfAfsXlsxRefRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAfsXlsxRefRes[['NumEchant', 'NumAnlys', 'Group Left Trunc', 'Group Right Trunc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dfAfsXlsxRefRes[['NumEchant', 'NumAnlys', 'Group Left Trunc', 'Group Right Trunc']] \\\n",
    "         .compare(dfAfsXlsxRes[['NumEchant', 'NumAnlys', 'Group Left Trunc', 'Group Right Trunc']]).empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MiniConda3-py38]",
   "language": "python",
   "name": "conda-env-MiniConda3-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

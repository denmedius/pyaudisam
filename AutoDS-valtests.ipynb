{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Auto table of contents -->\n",
    "<h1 class='tocIgnore'>AutoDS : Validation tests</h1>\n",
    "<p>(for the <b>autods</b> module, a python interface to MCDS.exe, http://distancesampling.org/)</p>\n",
    "<div style=\"overflow-y: auto\">\n",
    "  <h2 class='tocIgnore'>Table of contents</h2>\n",
    "  <div id=\"toc\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib as implib\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict as odict, namedtuple as ntuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly as ply\n",
    "import plotly.graph_objs as plygo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autods as ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate Warnings as Exception\n",
    "import warnings\n",
    "\n",
    "if False:\n",
    "    \n",
    "    warnings.filterwarnings(action='error')\n",
    "\n",
    "    # pd.read_excel\n",
    "    warnings.filterwarnings(action='default', module='etree')\n",
    "    warnings.filterwarnings(action='default', module='xlrd')\n",
    "    warnings.filterwarnings(action='default', module='defusedxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses with real life field data\n",
    "\n",
    "(for comparison to manually issued analyses with Distance 7.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load analyses set specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load refout results table\n",
    "refFileName = 'ACDC2019-Papyrus-ALAARV-TURMER-resultats-distance-73.xlsx'\n",
    "dfRefRes = pd.read_excel(os.path.join('AutoDS', 'refout', refFileName))\n",
    "dfRefRes.rename(columns=dict(Name='Model'), inplace=True)\n",
    "\n",
    "dfRefRes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate test cases definition code from refout results file (don't cheat : only input columns :-)\n",
    "modelIdCols = ['Model'] #, 'LTrunc', 'RTrunc', 'FitDistCuts', 'DiscrDistCuts']\n",
    "modelParamCols = ['LTrunc', 'RTrunc', 'FitDistCuts', 'DiscrDistCuts']\n",
    "sampleIdCols = ['Species', 'Periods', 'Prec.', 'Duration']\n",
    "caseIdCols = sampleIdCols + modelIdCols\n",
    "dfAnlysCases = dfRefRes[caseIdCols + modelParamCols].copy()\n",
    "\n",
    "dfAnlysCases['KeyFn'] = \\\n",
    "    dfAnlysCases.Model.apply(lambda s: 'UNIFORM' if s.startswith('Unif') \\\n",
    "                                                 else 'HNORMAL' if s.startswith('Half') else 'HAZARD')\n",
    "dfAnlysCases['AdjSer'] = \\\n",
    "    dfAnlysCases.Model.apply(lambda s: 'COSINE' if s.find(' Cos') > 0 \\\n",
    "                                                else 'POLY' if s.find(' SimPoly') > 0 else 'HERMITE')\n",
    "dfAnlysCases['InFileName'] = \\\n",
    "    dfAnlysCases.apply(lambda sRow: 'ACDC2019-Papyrus-{}-{}-{}mn-{}dec-dist.txt' \\\n",
    "                                    .format(sRow.Species,\n",
    "                                            'AB' if 'A+B' in sRow.Periods else 'A' if 'A' in sRow.Periods else 'B',\n",
    "                                            sRow.Duration.split(' ')[0], sRow['Prec.'].split(' ')[0]),\n",
    "                       axis='columns')\n",
    "dfAnlysCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimalFields = ['Point transect*Survey effort', 'Observation*Radial distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis engine\n",
    "mcds = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'),\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frozen analysis parameters (a choice here)\n",
    "KEstimCriterion = 'AIC'\n",
    "KCVInterval = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results object construction\n",
    "sampCols = [('sample', col, 'Value') for col in sampleIdCols]\n",
    "miSampCols = pd.MultiIndex.from_tuples(sampCols)\n",
    "\n",
    "custCols = sampCols + [('model', 'Model', 'Value')] # + [('model', col, 'Value') for col in modelIdCols]\n",
    "miCustCols = pd.MultiIndex.from_tuples(custCols)\n",
    "\n",
    "dfCustColTrans = \\\n",
    "    pd.DataFrame(index=miCustCols,\n",
    "                 data=dict(en=caseIdCols, \n",
    "                           fr=['Espèce', 'Périodes', 'Préc.', 'Durée', # 'Echant.', \n",
    "                               'Modèle'])) #, 'TroncGche', 'TroncDrte', 'TranchDistMod', 'TranchDistDiscr']))\n",
    "\n",
    "results = ads.MCDSResultsSet(miCustomCols=miCustCols, miSampleCols=miSampCols, dfCustomColTrans=dfCustColTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Or : Really run analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réduire éventuellement la liste des cas test et des résultats de référence, pour aller plus vite\n",
    "# Attention: Si on ne prend pas des échantillons entiers, les comparaisons référence / calcul échoueront sur Delta AIC.\n",
    "#selCaseInds = [0, 5, 7, 22, 31] # Some random cases, with uncomplete samples.\n",
    "#selCaseInds = dfAnlysCases[dfAnlysCases.Sample.isin([3, 4])].index # A shorter selection, with complete samples.\n",
    "selCaseInds = range(len(dfAnlysCases)) # All of them.\n",
    "\n",
    "nOrigAnlysCases = len(dfAnlysCases)\n",
    "dfAnlysCases = dfAnlysCases.loc[selCaseInds]\n",
    "dfRefRes = dfRefRes.loc[selCaseInds]\n",
    "\n",
    "print('Retained {} out of {}.'.format(len(selCaseInds), nOrigAnlysCases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsStart = pd.Timestamp.now()\n",
    "print('Started at', tsStart)\n",
    "print()\n",
    "\n",
    "# Run all analyses\n",
    "lastInFileName = None\n",
    "for nCase, sCase in dfAnlysCases.iterrows():\n",
    "    \n",
    "    name = sCase.InFileName[len('ACDC2019-Papyrus')+1:-len('-dist.txt')]\n",
    "    name += '-' + sCase.Model.lower().translate(str.maketrans({c:'-' for c in ' ,.:;()/'}))\n",
    "    print('#{:3d}'.format(nCase+1), name, sCase.KeyFn, sCase.AdjSer, end='\\n'*2)\n",
    "    \n",
    "    # Create data set if not already done.\n",
    "    if lastInFileName != sCase.InFileName:\n",
    "        ds = ads.DataSet(os.path.join('AutoDS', 'refin', sCase.InFileName), decimalFields=decimalFields)\n",
    "        lastInFileName = sCase.InFileName\n",
    "        \n",
    "    # Run analysis\n",
    "    def nan2None(v):\n",
    "        return None if pd.isnull(v) else v\n",
    "    def distCutsFromSpecs(v):\n",
    "        if pd.isnull(v):\n",
    "            return None\n",
    "        if isinstance(v, int):\n",
    "            return v\n",
    "        return [float(x) for x in v.split(',')]\n",
    "\n",
    "    analysis = ads.MCDSAnalysis(engine=mcds, dataSet=ds, name=name,\n",
    "                                estimKeyFn=sCase.KeyFn, estimAdjustFn=sCase.AdjSer,\n",
    "                                estimCriterion=KEstimCriterion, cvInterval=KCVInterval,\n",
    "                                minDist=nan2None(sCase.LTrunc), maxDist=nan2None(sCase.RTrunc),\n",
    "                                fitDistCuts=distCutsFromSpecs(sCase.FitDistCuts),\n",
    "                                discrDistCuts=distCutsFromSpecs(sCase.DiscrDistCuts))\n",
    "    sResult = analysis.run()\n",
    "\n",
    "    # Save results\n",
    "    sHead = pd.Series(data=[sCase[col] for col in sCase.index[:len(caseIdCols)]], index=miCustCols)\n",
    "\n",
    "    results.append(sResult, sCustomHead=sHead)\n",
    "    \n",
    "tsEnd = pd.Timestamp.now()\n",
    "print('Finished at', tsEnd, ': duration', str(tsEnd - tsStart).replace('0 days ', ''))\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save results in case need for not recomputing them\n",
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "\n",
    "results.toExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check translation\n",
    "dfActTrRes = results.dfTransData('fr')\n",
    "\n",
    "dfActTrRes.head().T.iloc[:30] #.at['TroncGche', 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Or : Load analyses from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    results.fromExcel(resFileName, sheetName='AutoDSVal')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} analyses to compare'.format(len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare actual results to reference\n",
    "\n",
    "(reference = manually run analyses with Distance software)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract actual results to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis results\n",
    "dfActRes = results.dfData\n",
    "\n",
    "dfActRes.head().T[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes des résultats autos et association aux disponibles dans la référence, pour comparaison.\n",
    "dCompCols = \\\n",
    "{\n",
    "    ('sample', 'Species', 'Value'):   'Species',\n",
    "    ('sample', 'Periods', 'Value'):   'Periods',\n",
    "    ('sample', 'Prec.', 'Value'):     'Prec.',\n",
    "    ('sample', 'Duration', 'Value'):  'Duration',\n",
    "    \n",
    "    ('model',  'Model', 'Value'):         'Model',\n",
    "    ('parameters', 'left truncation distance', 'Value'):           'LTrunc',\n",
    "    ('parameters', 'right truncation distance', 'Value'):          'RTrunc',\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'):  'FitDistCuts',\n",
    "    ('parameters', 'distance discretisation cut points', 'Value'): 'DiscrDistCuts',\n",
    "    \n",
    "    ('run output', 'run status', 'Value') : 'Status',\n",
    "    \n",
    "    ('detection probability', 'total number of parameters (m)', 'Value'): '# params',\n",
    "    ('encounter rate', 'number of observations (n)', 'Value'): '# obs',\n",
    "    \n",
    "    ('detection probability', 'Delta AIC', 'Value'): 'Delta AIC',\n",
    "    ('detection probability', 'AIC value', 'Value'): 'AIC',\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value')               : 'GOF Chi-p',\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value')                  : 'GOF K-S p',\n",
    "    ('detection probability', 'Cramér-von Mises (uniform weighting) test probability', 'Value'): 'GOF CvM (unif) p',\n",
    "    ('detection probability', 'Cramér-von Mises (cosine weighting) test probability', 'Value') : 'GOF CvM (cos) p',\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'): 'ESW/EDR',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl')  : 'ESW/EDR LCL',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl')  : 'ESW/EDR UCL',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Cv')   : 'ESW/EDR CV',\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'): 'D',\n",
    "    ('density/abundance', 'density of animals', 'Lcl')  : 'D LCL',\n",
    "    ('density/abundance', 'density of animals', 'Ucl')  : 'D UCL',\n",
    "    ('density/abundance', 'density of animals', 'Cv')   : 'D CV',\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'): 'P',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl')  : 'P LCL',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl')  : 'P UCL',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Cv')   : 'P CV',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df')   : 'P DF',\n",
    "}\n",
    "len(dCompCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Unused columns (full of NaNs) have been atomatically removed\n",
    "# (see last line of ResultsSet.dfData getter)\n",
    "dCompCols = { k: v for k, v in dCompCols.items() if k in dfActRes.columns }\n",
    "len(dCompCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(modelParamCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we need to cleanup modelParamCols too\n",
    "modelParamCols = [id_ for id_ in modelParamCols if id_ in dCompCols.values()]\n",
    "len(modelParamCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe stringification of model params\n",
    "# * needed for use in indexes (hashability)\n",
    "# * needed to cope with to_excel/read_excel unconsistent None management\n",
    "def modelParam2Str(par):\n",
    "    #print(par)\n",
    "    if isinstance(par, list):\n",
    "        spar = str([float(v) for v in par])\n",
    "    elif pd.isnull(par):\n",
    "        spar = 'None'\n",
    "    elif isinstance(par, str):\n",
    "        if ',' in par: # Assumed already somewhat stringified list\n",
    "            spar = str([float(v) for v in par.strip('[]').split(',')])\n",
    "    else:\n",
    "        spar = str(par)\n",
    "    return spar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select results columns and rename them as reference, for easier comparison\n",
    "dfActRes4c = dfActRes[list(dCompCols.keys())].copy()\n",
    "dfActRes4c.columns = [dCompCols[col] for col in dCompCols]\n",
    "dfActRes4c[modelParamCols] = dfActRes4c[modelParamCols].applymap(modelParam2Str) # Hashable mandatory for indexing\n",
    "dfActRes4c.set_index(caseIdCols + modelParamCols, inplace=True)\n",
    "\n",
    "dfActRes4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select usefull reference columns for comarison\n",
    "dfRefRes4c = dfRefRes.copy()\n",
    "dfRefRes4c[modelParamCols] = dfRefRes4c[modelParamCols].applymap(modelParam2Str) # Hashable mandatory for indexing\n",
    "dfRefRes4c.set_index(caseIdCols + modelParamCols, inplace=True)\n",
    "dfRefRes4c = dfRefRes4c.reindex(columns=dfActRes4c.columns)\n",
    "\n",
    "dfRefRes4c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diagnostic automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First checks : equality of test case lists (index) and of column names (columns)\n",
    "assert sorted(dfActRes4c.index)   == sorted(dfRefRes4c.index)\n",
    "assert sorted(dfActRes4c.columns) == sorted(dfRefRes4c.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual / reference closeness measure : -round(log10((actual - reference) / max(abs(actual), abs(reference))), 1)\n",
    "# = Compute the order of magnitude that separate the difference from the absolute max. of the two values\n",
    "# The greater it is, the lower the relative difference\n",
    "#    Ex: 3 = 10**3 ratio between difference absolue max. of the two,\n",
    "#        +inf = NO difference at all,\n",
    "#        0 = bad, one of the two is 0, and the other not,\n",
    "# See unitary test below.\n",
    "def closeness(sRefAct):\n",
    "    \n",
    "    x, y = sRefAct.to_list()\n",
    "    \n",
    "    # Special cases with 1 NaN, or 1 or more inf => all different\n",
    "    if np.isnan(x):\n",
    "        if not np.isnan(y):\n",
    "            return 0 # All different\n",
    "    elif np.isnan(y):\n",
    "        return 0 # All different\n",
    "    \n",
    "    if np.isinf(x) or np.isinf(y):\n",
    "        return 0 # All different\n",
    "    \n",
    "    # Normal case\n",
    "    c = abs(x - y)\n",
    "    if not np.isnan(c) and c != 0:\n",
    "        c = c / max(abs(x), abs(y))\n",
    "    \n",
    "    return np.inf if c == 0 else round(-np.log10(c), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Actual / reference comparison : compute closeness indicator\n",
    "dfRelDif = dfRefRes4c.copy()\n",
    "for col in dfRelDif.columns:\n",
    "    dfRelDif['act'] = dfActRes4c[col]\n",
    "    dfRelDif[col] = dfRelDif[[col, 'act']].apply(closeness, axis='columns')\n",
    "    dfRelDif.drop(columns='act', inplace=True)\n",
    "    \n",
    "dfRelDif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis : we only keep lines and columns with some relevant differences.\n",
    "dfBadRelDif = dfRelDif.copy()\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Suppression lignes : Status identique et reste NaN (cas des status = 0/3/4 : erreur d'exécution, ou pas d'exécution)\n",
    "valCols = [col for col in dfRelDif.columns if col != 'Status']\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif.Status.abs() == np.inf) & dfBadRelDif[valCols].isnull().all(axis='columns')].index,\n",
    "                 axis='index', inplace=True)\n",
    "assert len(dfBadRelDif) == 29, len(dfBadRelDif)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Suppression lignes : Status et toutes autres colonnes à inf (stricte égalité)\n",
    "#    NB. Somme very small differences observed when results have just been computed or when they have been\n",
    "#        loaded from a previously saved Excel file (above 10**15 closeness value)\n",
    "dfBadRelDif.drop(dfBadRelDif[dfBadRelDif.apply(np.isinf, axis='columns').all(axis='columns')].index,\n",
    "                 axis='index', inplace=True)\n",
    "assert (computed and len(dfBadRelDif) == 26) or (not computed and len(dfBadRelDif) == 19), len(dfBadRelDif)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Suppression lignes : Status et toutes autres colonnes supérieures à 15 (quasi stricte égalité)\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif >= 15).all(axis='columns')].index, axis='index', inplace=True)\n",
    "assert len(dfBadRelDif) == 9, len(dfBadRelDif)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Suppression lignes : Status identique et toutes autres colonnes supérieures à 4 (quasi égalité)\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif >= 4).all(axis='columns')].index, axis='index', inplace=True)\n",
    "assert len(dfBadRelDif) == 4, len(dfBadRelDif)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Suppression lignes : Status identique et toutes autres colonnes supérieures à 4 (quasi égalité)\n",
    "#                         sauf colonnes GOF KS et CvM à NaN, non calculées quand on discrétise les distances.\n",
    "if 'DiscrDistCuts' in dfBadRelDif.index.names:\n",
    "    discrCols = [col for col in dfRelDif.columns if not col.startswith('GOF') or col.find('Chi') > 0]\n",
    "    df2Drop = (dfBadRelDif.index.get_level_values('DiscrDistCuts') != -1) & (dfBadRelDif[discrCols] >= 4).all(axis='columns')\n",
    "    dfBadRelDif.drop(dfBadRelDif[df2Drop].index, axis='index', inplace=True)\n",
    "assert len(dfBadRelDif) == 2, len(dfBadRelDif)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le verdict (Cf. fichier Excel refFileName, feuille \"DiffAuto\" pour explications des 2 différences Act/Ref)\n",
    "dfBadRelDif.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRefRes4c.loc[dfBadRelDif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActRes4c.loc[dfBadRelDif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFails = len(dfBadRelDif.index)\n",
    "if nFails > 0:\n",
    "    print('Warning: {} test case(s) failed ;'.format(nFails))\n",
    "    print(' ... see sheet \"DiffAuto\" of {} for possible explanations.'.format(refFileName))\n",
    "else:\n",
    "    print('All test cases succeeded !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sauvegarde des résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resCompFileName = os.path.join(mcds.workDir, 'autods-validation-rescomp.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(resCompFileName) as xlsxWriter:\n",
    "\n",
    "    dfRefRes.to_excel(xlsxWriter, sheet_name='RefResults', index=True)\n",
    "    dfActRes4c.reset_index().to_excel(xlsxWriter, sheet_name='ActResults', index=False)\n",
    "    dfRelDif.reset_index().to_excel(xlsxWriter, sheet_name='Diff2Ref', index=False)\n",
    "    dfBadRelDif.reset_index().to_excel(xlsxWriter, sheet_name='BadDiff2Ref', index=False)\n",
    "    dfRefRes4c.loc[dfBadRelDif.index].reset_index().to_excel(xlsxWriter, sheet_name='RefResWithDiff', index=False)\n",
    "    dfActRes4c.loc[dfBadRelDif.index].reset_index().to_excel(xlsxWriter, sheet_name='ActResWithDiff', index=False)\n",
    "    dfActRes.to_excel(xlsxWriter, sheet_name='RawActResults', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActRes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapports d'analyses Excel et HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes pour les tableaux de synthèse du rapport\n",
    "synthCols = \\\n",
    "[\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Periods', 'Value'),\n",
    "    ('sample', 'Prec.', 'Value'),\n",
    "    ('sample', 'Duration', 'Value'),\n",
    "    \n",
    "    ('model', 'Model', 'Value'),\n",
    "    ('parameters', 'left truncation distance', 'Value'),\n",
    "    ('parameters', 'right truncation distance', 'Value'),\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'),\n",
    "    ('parameters', 'distance discretisation cut points', 'Value'),\n",
    "    \n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'Delta AIC', 'Value'),\n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl'),\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df'),\n",
    "\n",
    "    ('run output', 'run folder', 'Value'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ads.MCDSResultsFullReport(resultsSet=results, synthCols=synthCols, title='Validation du module autods',\n",
    "                                   subTitle='Rapport d\\'analyse global', anlysSubTitle='Rapport détaillé',\n",
    "                                   description='Qu\\'ajouter de plus ?', keywords='autods, validation',\n",
    "                                   lang='fr', attachedDir='.', tgtFolder=mcds.workDir, tgtPrefix='autods-validation-report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "htmlRep = report.toHtml()\n",
    "\n",
    "HTML(f'Rapport HTML : <a href=\"{htmlRep}\" target=\"blank\">{htmlRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlsxRep = report.toExcel()\n",
    "\n",
    "HTML(f'Rapport Excel : <a href=\"{xlsxRep}\" target=\"blank\">{xlsxRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-run and report pre-analyses\n",
    "\n",
    "(to help users to setup the full analyses plan : run first try simple analyses and show PDF and few results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Determine samples from input data\n",
    "\n",
    "* in real life, we'd simply load field collected data, and deduce individual \"samples\" from it ;\n",
    "* but there, for testing, it's easier to deduce samples from manual analysis specification file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create sample table from refout results table\n",
    "refFileName = 'ACDC2019-Papyrus-ALAARV-TURMER-resultats-distance-73.xlsx'\n",
    "\n",
    "sampleIdCols = ['Species', 'Periods', 'Prec.', 'Duration']\n",
    "\n",
    "dfSamples = pd.read_excel(os.path.join('AutoDS', 'refout', refFileName), usecols=sampleIdCols)\n",
    "dfSamples.rename(columns=dict(Name='Model'), inplace=True)\n",
    "dfSamples.drop_duplicates(inplace=True)\n",
    "dfSamples.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimalFields = ['Point transect*Survey effort', 'Observation*Radial distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis engine\n",
    "mcds = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-pout'),\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results object construction\n",
    "custCols = [('sample', col, 'Value') for col in sampleIdCols]\n",
    "miCustCols = pd.MultiIndex.from_tuples(custCols)\n",
    "dfCustColTrans = \\\n",
    "    pd.DataFrame(index=miCustCols,\n",
    "                 data=dict(en=sampleIdCols, \n",
    "                           fr=['Espèce', 'Périodes', 'Préc.', 'Durée']))\n",
    "\n",
    "results = ads.MCDSResultsSet(miCustomCols=miCustCols, dfCustomColTrans=dfCustColTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Or : Really run pre-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tsStart = pd.Timestamp.now()\n",
    "print('Started at', tsStart)\n",
    "print()\n",
    "\n",
    "# Run all analyses\n",
    "lastInFileName = None\n",
    "for nSamp, sSamp in dfSamples.iterrows():\n",
    "    \n",
    "    sampId = '{}-{}-{}mn-{}dec' \\\n",
    "             .format(sSamp.Species,\n",
    "                     'AB' if 'A+B' in sSamp.Periods else 'A' if 'A' in sSamp.Periods else 'B',\n",
    "                     sSamp.Duration.split(' ')[0], sSamp['Prec.'].split(' ')[0])\n",
    "    print('#{:3d}'.format(nSamp+1), sampId, end='\\n'*2)\n",
    "    \n",
    "    # Create data set if not already done.\n",
    "    inFileName = 'ACDC2019-Papyrus-{}-dist.txt'.format(sampId)\n",
    "    if lastInFileName != inFileName:\n",
    "        ds = ads.DataSet(os.path.join('AutoDS', 'refin', inFileName), decimalFields=decimalFields)\n",
    "        lastInFileName = inFileName\n",
    "        \n",
    "    # Run analysis\n",
    "    analysis = ads.MCDSAnalysis(engine=mcds, dataSet=ds, name=sampId + '-' + 'hnor-cos',\n",
    "                                estimKeyFn='HNORMAL', estimAdjustFn='COSINE',\n",
    "                                estimCriterion='AIC', cvInterval=95)\n",
    "    sResult = analysis.run()\n",
    "\n",
    "    # Save results\n",
    "    sHead = sSamp.copy()\n",
    "    sHead.index = miCustCols\n",
    "\n",
    "    results.append(sResult, sCustomHead=sHead)\n",
    "    \n",
    "tsEnd = pd.Timestamp.now()\n",
    "print('Finished at', tsEnd, ': duration', str(tsEnd - tsStart).replace('0 days ', ''))\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at results\n",
    "results.dfTransData('fr')[['Espèce', 'Périodes', 'Préc.', 'Durée', 'Fn Clé',\n",
    "                           'Sér Ajust', 'CodEx', 'NObs', 'AIC', 'Chi2 P', 'KS P', \n",
    "                           'Densité', 'CoefVar Densité', 'Min Densité', 'Max Densité']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save results in case need for not recomputing them\n",
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-preresults.xlsx')\n",
    "\n",
    "results.toExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Or : Load analyses from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    resFileName = os.path.join(mcds.workDir, 'autods-validation-preresults.xlsx')\n",
    "    print('Loading pre-results from {} ...'.format(resFileName))\n",
    "\n",
    "    results.fromExcel(resFileName, sheetName='AutoDSVal')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} pre-analyses loaded'.format(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at results\n",
    "results.dfTransData('fr')[['Espèce', 'Périodes', 'Préc.', 'Durée', 'Fn Clé',\n",
    "                           'Sér Ajust', 'CodEx', 'NObs', 'AIC', 'Chi2 P', 'KS P', \n",
    "                           'Densité', 'CoefVar Densité', 'Min Densité', 'Max Densité']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate HTML and Excel reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes pour les tableaux de synthèse du rapport\n",
    "synthCols = \\\n",
    "[\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Periods', 'Value'),\n",
    "    ('sample', 'Prec.', 'Value'),\n",
    "    ('sample', 'Duration', 'Value'),\n",
    "    \n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    ('parameters', 'CV interval', 'Value'),\n",
    "    ('parameters', 'left truncation distance', 'Value'),\n",
    "    ('parameters', 'right truncation distance', 'Value'),\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'),\n",
    "    ('parameters', 'distance discretisation cut points', 'Value'),\n",
    "    \n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl'),\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df'),\n",
    "\n",
    "    ('run output', 'run folder', 'Value'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select analysis results columns for the 3 textual columns of the synthesis pre-report\n",
    "sampleCols = \\\n",
    "[\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Periods', 'Value'),\n",
    "    ('sample', 'Prec.', 'Value'),\n",
    "    ('sample', 'Duration', 'Value')\n",
    "]\n",
    "\n",
    "paramCols = \\\n",
    "[\n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    ('parameters', 'CV interval', 'Value')\n",
    "]\n",
    "    \n",
    "resultCols = \\\n",
    "[\n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ads.MCDSResultsPreReport(resultsSet=results,\n",
    "                                  title='Validation du module autods', subTitle='Rapport de pré-analyse',\n",
    "                                  anlysSubTitle='Détail des pré-analyses', description='Qu\\'ajouter de plus ?',\n",
    "                                  keywords='autods, validation', pdfPlotHeight=384, lang='fr',\n",
    "                                  sampleCols=sampleCols, paramCols=paramCols, resultCols=resultCols, anlysSynthCols=synthCols,\n",
    "                                  attachedDir='.', tgtFolder=mcds.workDir, tgtPrefix='autods-validation-prereport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "htmlRep = report.toHtml()\n",
    "\n",
    "HTML(f'Pré-rapport HTML : <a href=\"{htmlRep}\" target=\"blank\">{htmlRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlsxRep = report.toExcel()\n",
    "\n",
    "HTML(f'Rapport Excel : <a href=\"{xlsxRep}\" target=\"blank\">{xlsxRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bac à sable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.dfTransData('fr')\n",
    "df['x'] = ['C', 'F', 'B', 'E', 'A']\n",
    "df.index = [3, 2, 4, 1, 5]\n",
    "df[['x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sCurrUrl = df['x']\n",
    "dfUrls = pd.DataFrame(dict(current=sCurrUrl, previous=np.roll(sCurrUrl, 1), next=np.roll(sCurrUrl, -1)))\n",
    "dfUrls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(dict(a=1, b=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRes = results.dfTransData('fr')\n",
    "dfRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dfRes.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = s.to_frame(name='toto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.to_html(header=False, border=0, classes='layout-only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub('\\\\\\n *', '', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dPlots = mcds.decodePlots('AutoDS/mcds-out/ALAARV-AB-10mn-6dec-hazard-simpoly-tgd-fitint-z1rrb_m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(dPlots.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=[dict(x='toto', \n",
    "                             y=\"\"\"<a href=\"./autods-validation-report.xlsx\" target=\"_blank\"><img height=\"72\" style=\"margin-right: 16px\" src=\"./fa-file-excel.svg\"\n",
    "                                       onmouseover=\"this.src='./fa-file-excel-hover.svg';\"\n",
    "                                       onmouseout=\"this.src='./fa-file-excel.svg';\"\n",
    "                                       title=\"Download Excel\" alt=\"Dnld\" /></a>\"\"\", z=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html('AutoDS/mcds-out/test.html', escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDet = results.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[results.dfCustomColTrans['fr'][col] for col in results.miCustomCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dfDet.loc[0, [results.dfCustomColTrans['fr'][col] for col in results.miCustomCols]]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(['{}={}'.format(k, v) for k, v in s.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#{}'.format(0), ' '.join(['{}={}'.format(k, v) for k, v in s.iteritems()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dfCustomColTrans['fr'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSyn = results.dfTransData('fr', subset=synthCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort=True\n",
    "convert=True\n",
    "round=True\n",
    "style=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNull(o):\n",
    "    return not isinstance(o, list) and pd.isnull(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNull(pd.NaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrSynRes = results.dfTransData('fr', subset=synthCols)\n",
    "dfTrSynRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cChrGray = '#869074'\n",
    "cBckGreen, cBckGray = '#e0ef8c', '#dae3cb'\n",
    "cSclGreen, cSclOrange, cSclRed = '#cbef8c', '#f9da56', '#fe835a' #'#f25e2d'\n",
    "scaledColors = [cSclGreen, cSclOrange, cSclRed]\n",
    "scaledColorsRvd = list(reversed(scaledColors))\n",
    "\n",
    "dExCodeColors = dict(zip([1, 2, 3], scaledColors))\n",
    "def colorExecCodes(sCodes):\n",
    "    return ['background-color: ' + dExCodeColors.get(c, dExCodeColors[3]) for c in sCodes]\n",
    "\n",
    "def scaledColorV(v, thresholds, colors): # len(thresholds) == len(colors) - 1\n",
    "    if pd.isnull(v):\n",
    "        return cBckGray\n",
    "    for ind, thresh in enumerate(thresholds):\n",
    "        if v > thresh:\n",
    "            return colors[ind]\n",
    "    return colors[-1]\n",
    "def scaledColorS(sValues, thresholds, colors):\n",
    "    return ['background-color: ' + scaledColorV(v, thresholds, colors) for v in sValues]\n",
    "\n",
    "densCVThresholds = [0.4, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfTrSynRes \\\n",
    "        .sort_values(by=['Espèce', 'Préc.', 'Durée']) \\\n",
    "        .style \\\n",
    "        .set_precision(3) \\\n",
    "        .apply(colorExecCodes, subset=['CodEx'], axis='columns') \\\n",
    "        .apply(scaledColorS, subset=['CoefVar Densité'], axis='columns',\n",
    "               thresholds=densCVThresholds, colors=scaledColors) \\\n",
    "        .set_properties(subset=pd.IndexSlice[dfTrSynRes[~dfTrSynRes.CodEx.isin([1, 2])].index, :],\n",
    "                         **{'color': cChrGray}) \\\n",
    "        .where(pd.isnull, 'color: transparent')\n",
    "\n",
    "        #.set_properties(subset=pd.IndexSlice[dfTrSynRes[dfTrSynRes['Delta AIC'] == 0].index, :],\n",
    "        #                **{'background-color': cBckGreen}) \\\n",
    "\n",
    "    #.format(lambda v: v if not pd.isnull(v) else '') # Détruit une partie des arrondis, auugmente la précision ???\n",
    "\n",
    "    #.set_precision(3) # Not really usable, as only for the whole frame\n",
    "\n",
    "    #.apply(lambda s: ['color: grey']*len(s), subset=pd.IndexSlice[dfTrSynRes[~dfTrSynRes.CodEx.isin([1, 2])].index, :],\n",
    "    #       axis='index') # OK\n",
    "    \n",
    "    #.apply(lambda s: ['color: grey']*len(s), subset=dfTrSynRes[~dfTrSynRes.CodEx.isin([1, 2])].index,\n",
    "    #       axis='index') # KO\n",
    "    \n",
    "dfs.to_excel('tmp/styled-results.xlsx')\n",
    "\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfTrSynRes.iloc[0].to_frame()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc['CodEx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.IndexSlice[df2.loc['CodEx'].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs2 = df2.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs2.apply(colorExecCodes, subset=['CodEx'], axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.style \\\n",
    "        .set_precision(3) \\\n",
    "        .apply(colorExecCodes, subset=['CodEx'], axis='index')\n",
    "\n",
    "#        .apply(scaledColorS, subset=['CoefVar Densité'], axis='index',\n",
    "#               thresholds=densCVThresholds, colors=scaledColors)\n",
    "#\n",
    "#        .set_properties(subset=[] if df2.loc['CodEx'].isin([1, 2]) else df2.index,\n",
    "#                         **{'color': cChrGray})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "#, FormatStrFormatter, AutoMinorLocator)\n",
    "\n",
    "tMax = 600\n",
    "\n",
    "t = np.arange(0.0, tMax, 0.1)\n",
    "s = np.sin(0.1 * np.pi * t) * np.exp(-t * 0.01)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "ax.plot(t, s)\n",
    "ax.grid(True)\n",
    "ax.grid(True, which='minor')\n",
    "\n",
    "# Make a plot with major ticks that are multiples of 20 and minor ticks that\n",
    "# are multiples of 5.  Label major ticks with '%d' formatting but don't label\n",
    "# minor ticks.\n",
    "#ax.xaxis.set_major_locator(MultipleLocator(25))\n",
    "#ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
    "\n",
    "# For the minor ticks, use no labels; default NullFormatter.\n",
    "aTicks = ax.get_xticks()\n",
    "\n",
    "ax.xaxis.set_minor_locator(MultipleLocator((aTicks[1]-aTicks[0])/5))\n",
    "\n",
    "ax.tick_params(which='minor', grid_linestyle='-.', grid_alpha=0.6) #length=4, color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ax.xaxis.get_major_ticks()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_xticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Auto table of contents -->\n",
    "<h1 class='tocIgnore'>AutoDS : Tests de validation</h1>\n",
    "<p>(module <b>autods</b> d'interface python à MCDS.exe)</p>\n",
    "<div style=\"overflow-y: auto\">\n",
    "  <h2 class='tocIgnore'>Table des matières</h2>\n",
    "  <div id=\"toc\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('../ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib as implib\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict as odict, namedtuple as ntuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly as ply\n",
    "import plotly.graph_objs as plygo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autods as ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate Warnings as Exception\n",
    "#import warnings\n",
    "#warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCDS : Analyses avec de vraies données\n",
    "\n",
    "(pour comparaison à des analyses faites à la main avec Distance 7.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construction des cas tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load refout results table\n",
    "refFileName = 'ACDC2019-Papyrus-ALAARV-TURMER-resultats-distance-73.xlsx'\n",
    "dfRefRes = pd.read_excel(os.path.join('AutoDS', 'refout', refFileName))\n",
    "dfRefRes.rename(columns=dict(Name='Model'), inplace=True)\n",
    "sampleIdCols = ['Species', 'Periods', 'Precision', 'Duration']\n",
    "dfRefRes.insert(0, column='Sample', value=dfRefRes.groupby(sampleIdCols, sort=False).ngroup())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRefRes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate test cases definition code from refout results file (don't cheat : only input columns :-)\n",
    "modelIdCols = ['Model', 'LTrunc', 'RTrunc', 'FitDistCuts', 'DiscrDistCuts']\n",
    "caseIdCols = ['Sample'] + sampleIdCols + modelIdCols\n",
    "dfAnlysCases = dfRefRes[caseIdCols].copy()\n",
    "\n",
    "#dfAnlysCases['Status'] = \\\n",
    "#    dfAnlysCases.Status.apply(lambda s: 1 if s == 'OK' else 2 if s == 'Warnings' else 3)\n",
    "dfAnlysCases['KeyFn'] = \\\n",
    "    dfAnlysCases.Model.apply(lambda s: 'UNIFORM' if s.startswith('Unif') \\\n",
    "                                                 else 'HNORMAL' if s.startswith('Half') else 'HAZARD')\n",
    "dfAnlysCases['AdjSer'] = \\\n",
    "    dfAnlysCases.Model.apply(lambda s: 'COSINE' if s.find(' Cos') > 0 \\\n",
    "                                                else 'POLY' if s.find(' SimPoly') > 0 else 'HERMITE')\n",
    "dfAnlysCases['InFileName'] = \\\n",
    "    dfAnlysCases.apply(lambda sRow: 'ACDC2019-Papyrus-{}-{}-{}mn-{}dec-dist.txt' \\\n",
    "                                    .format(sRow.Species,\n",
    "                                            'AB' if 'A+B' in sRow.Periods else 'A' if 'A' in sRow.Periods else 'B',\n",
    "                                            5 if '5' in sRow.Duration == '5 mn' else 10,\n",
    "                                            6 if sRow.Precision.startswith('6 déc') else 1),\n",
    "                       axis='columns')\n",
    "\n",
    "dfAnlysCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Préparation des analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimalFields = ['Point transect*Survey effort', 'Observation*Radial distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis engine\n",
    "mcds = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'),\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frozen analysis parameters (a choice here)\n",
    "KEstimCriterion = 'AIC'\n",
    "KCVInterval = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results object construction\n",
    "custCols = [('sample', col, 'Value') for col in ['Sample'] + sampleIdCols] \\\n",
    "            + [('model', col, 'Value') for col in modelIdCols]\n",
    "miCustCols = pd.MultiIndex.from_tuples(custCols)\n",
    "dfCustColTrans = \\\n",
    "    pd.DataFrame(index=miCustCols,\n",
    "                 data=dict(en=caseIdCols, \n",
    "                           fr=['Echantillon', 'Espèce', 'Périodes', 'Précision', 'Durée',\n",
    "                               'Modèle', 'TroncGche', 'TroncDrte', 'TranchDistMod', 'TranchDistDiscr']))\n",
    "\n",
    "results = ads.MCDSResultsSet(miCustomCols=miCustCols, dfCustomColTrans=dfCustColTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Ou : Exécution des analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsStart = pd.Timestamp.now()\n",
    "print('Started at', tsStart)\n",
    "print()\n",
    "\n",
    "# Run all analyses\n",
    "lastInFileName = None\n",
    "for ind, sCase in dfAnlysCases.iterrows():\n",
    "    \n",
    "    name = sCase.InFileName[len('ACDC2019-Papyrus')+1:-len('-dist.txt')]\n",
    "    name += '-' + sCase.Model.lower().translate(str.maketrans({c:'-' for c in ' ,.:;()/'}))\n",
    "    print('#{:3d}'.format(ind+1), name, sCase.KeyFn, sCase.AdjSer, end='\\n'*2)\n",
    "    \n",
    "    # Create data set if not already done.\n",
    "    if lastInFileName != sCase.InFileName:\n",
    "        ds = ads.DataSet(os.path.join('AutoDS', 'refin', sCase.InFileName), decimalFields=decimalFields)\n",
    "        lastInFileName = sCase.InFileName\n",
    "        \n",
    "    # Run analysis\n",
    "    def nan2None(v):\n",
    "        return None if pd.isnull(v) else v\n",
    "    def distCutsFromSpecs(v):\n",
    "        if pd.isnull(v):\n",
    "            return None\n",
    "        if isinstance(v, int):\n",
    "            return v\n",
    "        return [float(x) for x in v.split(',')]\n",
    "\n",
    "    analysis = ads.MCDSAnalysis(engine=mcds, dataSet=ds, name=name,\n",
    "                                estimKeyFn=sCase.KeyFn, estimAdjustFn=sCase.AdjSer,\n",
    "                                estimCriterion=KEstimCriterion, cvInterval=KCVInterval,\n",
    "                                minDist=nan2None(sCase.LTrunc), maxDist=nan2None(sCase.RTrunc),\n",
    "                                fitDistCuts=distCutsFromSpecs(sCase.FitDistCuts),\n",
    "                                discrDistCuts=distCutsFromSpecs(sCase.DiscrDistCuts))\n",
    "    sResult = analysis.run()\n",
    "\n",
    "    # Save results\n",
    "    sHead = pd.Series(data=[sCase[col] for col in sCase.index[:len(caseIdCols)]], index=miCustCols)\n",
    "\n",
    "    results.append(sResult, sCustomHead=sHead)\n",
    "    \n",
    "tsEnd = pd.Timestamp.now()\n",
    "print('Finished at', tsEnd, ': duration', str(tsEnd - tsStart).replace('0 days ', ''))\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in case need for not recomputing them\n",
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "\n",
    "results.toExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check translation\n",
    "dfActTrRes = results.dfTransData('fr')\n",
    "\n",
    "dfActTrRes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Ou : Rechargement des résultats d'analyses\n",
    "\n",
    "(déjà faites ci-dessus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "\n",
    "    results.fromExcel(resFileName, sheetName='AutoDSVal')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading from backup !')\n",
    "    \n",
    "print('{} analyses to compare'.format(len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison des résultats à la référence\n",
    "\n",
    "(référence = analyses faites \"à la main\" avec distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extraction des données à comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis results\n",
    "dfActRes = results.dfData\n",
    "\n",
    "dfActRes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes des résultats autos et association aux disponibles dans la référence, pour comparaison.\n",
    "dCompCols = \\\n",
    "{\n",
    "    ('sample', 'Sample', 'Value'):    'Sample',\n",
    "    ('sample', 'Species', 'Value'):   'Species',\n",
    "    ('sample', 'Periods', 'Value'):   'Periods',\n",
    "    ('sample', 'Precision', 'Value'): 'Precision',\n",
    "    ('sample', 'Duration', 'Value'):  'Duration',\n",
    "    \n",
    "    ('model',  'Model', 'Value'):         'Model',\n",
    "    ('model',  'LTrunc', 'Value'):        'LTrunc',\n",
    "    ('model',  'RTrunc', 'Value'):        'RTrunc',\n",
    "    ('model',  'FitDistCuts', 'Value'):   'FitDistCuts',\n",
    "    ('model',  'DiscrDistCuts', 'Value'): 'DiscrDistCuts',\n",
    "    \n",
    "    ('run output', 'run status', 'Value') : 'Status',\n",
    "    \n",
    "    ('detection probability', 'total number of parameters (m)', 'Value'): '# params',\n",
    "    ('encounter rate', 'number of observations (n)', 'Value'): '# obs',\n",
    "    \n",
    "    ('detection probability', 'Delta AIC', 'Value'): 'Delta AIC',\n",
    "    ('detection probability', 'AIC value', 'Value'): 'AIC',\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value')               : 'GOF Chi-p',\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value')                  : 'GOF K-S p',\n",
    "    ('detection probability', 'Cramér-von Mises (uniform weighting) test probability', 'Value'): 'GOF CvM (unif) p',\n",
    "    ('detection probability', 'Cramér-von Mises (cosine weighting) test probability', 'Value') : 'GOF CvM (cos) p',\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'): 'ESW/EDR',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl')  : 'ESW/EDR LCL',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl')  : 'ESW/EDR UCL',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Cv')   : 'ESW/EDR CV',\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'): 'D',\n",
    "    ('density/abundance', 'density of animals', 'Lcl')  : 'D LCL',\n",
    "    ('density/abundance', 'density of animals', 'Ucl')  : 'D UCL',\n",
    "    ('density/abundance', 'density of animals', 'Cv')   : 'D CV',\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'): 'P',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl')  : 'P LCL',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl')  : 'P UCL',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Cv')   : 'P CV',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df')   : 'P DF',\n",
    "}\n",
    "len(dCompCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sélection des colonnes de résultats, et renommage comme la référence, pour comparaison\n",
    "dfActRes4c = dfActRes[list(dCompCols.keys())].copy()\n",
    "dfActRes4c.columns = [dCompCols[col] for col in dCompCols]\n",
    "dfActRes4c[caseIdCols] = dfActRes4c[caseIdCols].fillna(-1) # For easier comparison\n",
    "dfActRes4c.set_index(caseIdCols, inplace=True)\n",
    "\n",
    "dfActRes4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sélection des colonnes utiles de la référence pour comparaison\n",
    "dfRefRes4c = dfRefRes.copy()\n",
    "dfRefRes4c[caseIdCols] = dfRefRes4c[caseIdCols].fillna(-1) # For easier comparison\n",
    "dfRefRes4c.set_index(caseIdCols, inplace=True)\n",
    "dfRefRes4c.drop(columns=['Run'], inplace=True)\n",
    "\n",
    "dfRefRes4c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diagnostic automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premières vérifications : égalité des listes de cas tests (index) et des listes de noms de colonnes (columns)\n",
    "assert sorted(dfActRes4c.index)   == sorted(dfRefRes4c.index)\n",
    "assert sorted(dfActRes4c.columns) == sorted(dfRefRes4c.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual / reference closeness measure : -round(log10((actual - reference) / max(abs(actual), abs(reference))), 1)\n",
    "# = Compute the orders of magnitude that separate the difference from the max. of the two values\n",
    "def closeness(sRefAct):\n",
    "    \n",
    "    x, y = sRefAct.to_list()\n",
    "    \n",
    "    # Special cases with 1 NaN, or 1 or more inf => all different\n",
    "    if np.isnan(x):\n",
    "        if not np.isnan(y):\n",
    "            return 0 # All different\n",
    "    elif np.isnan(y):\n",
    "        return 0 # All different\n",
    "    \n",
    "    if np.isinf(x) or np.isinf(y):\n",
    "        return 0 # All different\n",
    "    \n",
    "    # Normal case\n",
    "    c = abs(x - y)\n",
    "    if not np.isnan(c) and c != 0:\n",
    "        c = c / max(abs(x), abs(y))\n",
    "    \n",
    "    return round(-np.log10(c), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Comparaison actual / reference : mesure de proximité\n",
    "# => Plus c'est grand, plus petite est la différence relative entre les 2\n",
    "#    Ex: 3 = facteur 10**3 entre différence et valeurs absolues ; +inf = AUCUNE différence\n",
    "#        0 = pas bon, l'un des 2 est nul n'autre pas du tout\n",
    "#        inf = égalité parfaite ref/act\n",
    "# Cf. tests unitaires plus bas.\n",
    "dfRelDif = dfRefRes4c.copy()\n",
    "for col in dfRelDif.columns:\n",
    "    dfRelDif['act'] = dfActRes4c[col]\n",
    "    dfRelDif[col] = dfRelDif[[col, 'act']].apply(closeness, axis='columns')\n",
    "    dfRelDif.drop(columns='act', inplace=True)\n",
    "    \n",
    "dfRelDif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic : on ne garde que ce qui n'est pas rigoureusement égal (lignes et colonnes).\n",
    "dfBadRelDif = dfRelDif.copy()\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Suppression lignes : Status identique et reste NaN (cas des status = 0/3/4 : erreur d'exécution, ou pas d'exécution)\n",
    "valCols = [col for col in dfRelDif.columns if col != 'Status']\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif.Status.abs() == np.inf) & dfBadRelDif[valCols].isnull().all(axis='columns')].index,\n",
    "            axis='index', inplace=True)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Suppression lignes : Status et toutes autres colonnes à inf (stricte égalité)\n",
    "dfBadRelDif.drop(dfBadRelDif[dfBadRelDif.apply(np.isinf, axis='columns').all(axis='columns')].index,\n",
    "            axis='index', inplace=True)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Suppression lignes : Status identique et toutes autres colonnes supérieures à 4 (quasi égalité)\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif >= 4).all(axis='columns')].index, axis='index', inplace=True)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Suppression lignes : Status identique et toutes autres colonnes supérieures à 4 (quasi égalité)\n",
    "#                         sauf colonnes GOF KS et CvM à NaN, non calculées quand on discrétise les distances.\n",
    "discrCols = [col for col in dfRelDif.columns if not col.startswith('GOF') or col.find('Chi') > 0]\n",
    "df2Drop = (dfBadRelDif.index.get_level_values('DiscrDistCuts') != -1) & (dfBadRelDif[discrCols] >= 4).all(axis='columns')\n",
    "dfBadRelDif.drop(dfBadRelDif[df2Drop].index, axis='index', inplace=True)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le verdict (Cf. fichier Excel refFileName, feuille \"DiffAuto\" pour explications des différences Act/Ref)\n",
    "dfBadRelDif.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRefRes4c.loc[dfBadRelDif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActRes4c.loc[dfBadRelDif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFails = len(dfBadRelDif.index)\n",
    "if nFails > 0:\n",
    "    print('Warning: {} test case(s) failed ;'.format(nFails))\n",
    "    print(' ... see sheet \"DiffAuto\" of {} for possible explanations.'.format(refFileName))\n",
    "else:\n",
    "    print('All test cases succeeded !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sauvegarde des résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resCompFileName = os.path.join(mcds.workDir, 'autods-validation-rescomp.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(resCompFileName) as xlsxWriter:\n",
    "\n",
    "    dfRefRes.to_excel(xlsxWriter, sheet_name='RefResults', index=True)\n",
    "    dfActRes4c.reset_index().to_excel(xlsxWriter, sheet_name='ActResults', index=False)\n",
    "    dfRelDif.reset_index().to_excel(xlsxWriter, sheet_name='Diff2Ref', index=False)\n",
    "    dfBadRelDif.reset_index().to_excel(xlsxWriter, sheet_name='BadDiff2Ref', index=False)\n",
    "    dfRefRes4c.loc[dfBadRelDif.index].reset_index().to_excel(xlsxWriter, sheet_name='RefResWithDiff', index=False)\n",
    "    dfActRes4c.loc[dfBadRelDif.index].reset_index().to_excel(xlsxWriter, sheet_name='ActResWithDiff', index=False)\n",
    "    dfActRes.to_excel(xlsxWriter, sheet_name='RawActResults', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCDS : Rapports d'analyses Excel et HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes pour les tableaux de synthèse du rapport\n",
    "synthCols = \\\n",
    "[\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Periods', 'Value'),\n",
    "    ('sample', 'Precision', 'Value'),\n",
    "    ('sample', 'Duration', 'Value'),\n",
    "    \n",
    "    ('model', 'Model', 'Value'),\n",
    "    \n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'Delta AIC', 'Value'),\n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl'),\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df'),\n",
    "\n",
    "    ('sample', 'Sample', 'Value'),\n",
    "    ('run output', 'run folder', 'Value'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized results reports class\n",
    "class SpeMCDSResultsReport(ads.ResultsReport):\n",
    "\n",
    "    DCustTrans = \\\n",
    "        dict(en={ 'Note: Some figures rounded or converted': \n",
    "                     \"<strong>Note</strong>: Densities are expressed per square km,\"\n",
    "                     \" and most figures have been rounded for readability\",\n",
    "                  'Note: All figures untouched, as output by MCDS': \n",
    "                     \"<strong>Note</strong>: All values have been left untouched,\"\n",
    "                     \" as outuput by MCDS (no rounding, no conversion)\" },\n",
    "             fr={ 'Note: Some figures rounded or converted':\n",
    "                      \"<strong>N.B.</strong> Les densités sont exprimées par km carré, et presque toutes les valeurs\"\n",
    "                      \" ont été arrondies pour la lisibilité\",\n",
    "                  'Note: All figures untouched, as output by MCDS':\n",
    "                      \"<strong>N.B.</strong> Aucune valeur n'a été convertie ou arrondie,\"\n",
    "                      \" elles sont toutes telles que produites par MCDS\" })\n",
    "    \n",
    "    def __init__(self, resultsSet, title, subTitle, anlysSubTitle, description, keywords,\n",
    "                       synthCols=None, lang='en', attachedDir='.', tgtFolder='.', tgtPrefix='results'):\n",
    "    \n",
    "        super().__init__(resultsSet, title, subTitle, anlysSubTitle, description, keywords,\n",
    "                         self.DCustTrans, synthCols, lang, attachedDir, tgtFolder, tgtPrefix)\n",
    "        \n",
    "    # Styling colors\n",
    "    cChrGray = '#869074'\n",
    "    cBckGreen, cBckGray = '#e0ef8c', '#dae3cb'\n",
    "    cSclGreen, cSclOrange, cSclRed = '#cbef8c', '#f9da56', '#fe835a'\n",
    "    cChrInvis = '#e8efd1' # body background\n",
    "    scaledColors = [cSclGreen, cSclOrange, cSclRed]\n",
    "    scaledColorsRvd = list(reversed(scaledColors))\n",
    "    \n",
    "    dExCodeColors = dict(zip([1, 2, 3], scaledColors))\n",
    "    \n",
    "    @classmethod\n",
    "    def colorExecCodes(cls, sCodes):\n",
    "        return ['background-color: ' + cls.dExCodeColors.get(c, cls.dExCodeColors[3]) for c in sCodes]\n",
    "    \n",
    "    @classmethod\n",
    "    def scaledColorV(cls, v, thresholds, colors): # len(thresholds) == len(colors) - 1\n",
    "        if pd.isnull(v):\n",
    "            return cls.cBckGray\n",
    "        for ind, thresh in enumerate(thresholds):\n",
    "            if v > thresh:\n",
    "                return colors[ind]\n",
    "        return colors[-1]\n",
    "    \n",
    "    def scaledColorS(cls, sValues, thresholds, colors):\n",
    "        return ['background-color: ' + cls.scaledColorV(v, thresholds, colors) for v in sValues]\n",
    "    \n",
    "    # Final formatting of translated data tables, for HTML or SpreadSheet rendering\n",
    "    # (sort, convert units, round values, and style).\n",
    "    # Note: Use trEnColNames method to pass from EN-translated columns names to self.lang-ones\n",
    "    # Return a pd.DataFrame.Styler\n",
    "    def finalFormatData(self, dfTrData, sort=True, convert=True, round=True, style=True):\n",
    "        \n",
    "        # Sorting\n",
    "        df = dfTrData\n",
    "        if sort:\n",
    "            df.sort_values(by=self.trEnColNames(['Sample', 'Delta AIC']), \n",
    "                           ascending=[True, True], inplace=True)\n",
    "        \n",
    "        # Converting to other units\n",
    "        kVarDens = 1.0\n",
    "        if convert:\n",
    "            for col in self.trEnColNames(['Density', 'Min Density', 'Max Density']): # 'CoefVar Density', \n",
    "                df[col] *= 1000000 / 10000 # ha => km2\n",
    "            kVarDens = 100.0\n",
    "            df[self.trEnColNames('CoefVar Density')] *= kVarDens # [0, 1] => %\n",
    "            \n",
    "        # Reducing float precision\n",
    "        if round:\n",
    "            dColDecimals = { **{ col: 2 for col in ['Delta AIC', 'Chi2 P 3', 'KS P', # TODO: which Chi2 ????\n",
    "                                                    'PDetec', 'Min PDetec', 'Max PDetec'] },\n",
    "                             **{ col: 1 for col in ['AIC', 'EDR/ESW', 'Min EDR/ESW', 'Max EDR/ESW',\n",
    "                                                    'Density', 'Min Density', 'Max Density', 'CoefVar Density'] } }\n",
    "            df = df.round(decimals=self.trEnColNames(dColDecimals))\n",
    "        \n",
    "        # Styling\n",
    "        dfs = df.style\n",
    "        if style:\n",
    "            dfs.set_properties(subset=pd.IndexSlice[df[df[self.trEnColNames('Delta AIC')] == 0].index, :],\n",
    "                               **{'background-color': self.cBckGreen}) \\\n",
    "               .apply(self.colorExecCodes, subset=[self.trEnColNames('ExCod')], axis='columns') \\\n",
    "               .apply(self.scaledColorS, subset=[self.trEnColNames('CoefVar Density')], axis='columns',\n",
    "                      thresholds=[v * kVarDens for v in [0.3, 0.2]], colors=self.scaledColorsRvd) \\\n",
    "               .apply(self.scaledColorS, subset=[self.trEnColNames('KS P')], axis='columns',\n",
    "                      thresholds=[0.7, 0.2], colors=self.scaledColors) \\\n",
    "               .apply(self.scaledColorS, subset=[self.trEnColNames('Chi2 P 3')], axis='columns', # TODO: which Chi2 ????\n",
    "                      thresholds=[0.7, 0.2], colors=self.scaledColors) \\\n",
    "               .set_properties(subset=pd.IndexSlice[df[~df[self.trEnColNames('ExCod')].isin([1, 2])].index, :],\n",
    "                               **{'color': self.cChrGray}) \\\n",
    "               .where(pd.isnull, 'color: transparent').where(pd.isnull, 'text-shadow: none')\n",
    "        \n",
    "        return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = SpeMCDSResultsReport(resultsSet=results, synthCols=synthCols, title='Validation du module autods',\n",
    "                              subTitle='Rapport d\\'analyse global', anlysSubTitle='Rapport détaillé',\n",
    "                              description='Qu\\'ajouter de plus ?', keywords='autods, validation',\n",
    "                              lang='fr', attachedDir='.', tgtFolder=mcds.workDir, tgtPrefix='autods-validation-report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "htmlRep = report.toHtml()\n",
    "\n",
    "HTML(f'Rapport HTML : <a href=\"{htmlRep}\" target=\"blank\">{htmlRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlsxRep = report.toExcel()\n",
    "\n",
    "HTML(f'Rapport Excel : <a href=\"{xlsxRep}\" target=\"blank\">{xlsxRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bac à sable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecimalFields = ['SMP_EFFORT', 'DISTANCE']\n",
    "\n",
    "ImportFieldAliasREs = \\\n",
    "    odict([('STR_LABEL', ['region', 'zone', 'strate', 'stratum']),\n",
    "           ('STR_AREA', ['surface', 'area', 'ha', 'km2']),\n",
    "           ('SMP_LABEL', ['point', 'lieu', 'location']),\n",
    "           ('SMP_EFFORT', ['effort', 'passages', 'surveys', 'samplings']),\n",
    "           ('DISTANCE', ['distance'])])\n",
    "\n",
    "def matchDataFields(srcFields):\n",
    "\n",
    "    print('Matching required data columns:', end=' ')\n",
    "\n",
    "    # Try and match required data columns.\n",
    "    matFields = list()\n",
    "    matDecFields = list()\n",
    "    for tgtField in ImportFieldAliasREs:\n",
    "        print(tgtField, end='=')\n",
    "        foundTgtField = False\n",
    "        for srcField in srcFields:\n",
    "            print(srcField, end=':')\n",
    "            for pat in ImportFieldAliasREs[tgtField]:\n",
    "                print(pat, end=';')\n",
    "                if re.search(pat, srcField, flags=re.IGNORECASE):\n",
    "                    print(srcField, end=', ')\n",
    "                    matFields.append(srcField)\n",
    "                    if tgtField in DecimalFields:\n",
    "                        matDecFields.append(srcField)\n",
    "                    foundTgtField = True\n",
    "                    break\n",
    "            if foundTgtField:\n",
    "                break\n",
    "        if not foundTgtField:\n",
    "            raise Exception('Error: Failed to find a match for expected {} in dataset columns {}' \\\n",
    "                            .format(tgtField, srcFields))\n",
    "\n",
    "    # Extra fields.\n",
    "    extFields = [field for field in srcFields if field not in matFields]\n",
    "\n",
    "    print('... success.')\n",
    "\n",
    "    return matFields, matDecFields, extFields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchDataFields(['Region*Label', 'Region*Area', 'Point transect*Label',\n",
    "       'Point transect*Survey effort', 'Observation*Radial distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = re.search('area', 'Region*Area', flags=re.IGNORECASE)\n",
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safeFloat2Str(val, prec=None, decPt='.'):\n",
    "    strVal = '' if pd.isnull(val) else str(val) if prec is None \\\n",
    "                else '{:.{prec}f}'.format(val, prec=prec)\n",
    "    if decPt != '.':\n",
    "        strVal = strVal.replace('.', decPt)\n",
    "    return strVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeFloat2Str(12.53, prec=None, decPt='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeFloat2Str(12.53, prec=1, decPt='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeFloat2Str(12.53, prec=4, decPt='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeFloat2Str(12.53, prec=None, decPt=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Auto table of contents -->\n",
    "<h1 class='tocIgnore'>AutoDS : Validation tests archives</h1>\n",
    "<p>(for the <b>autods</b> module, a python interface to MCDS.exe, http://distancesampling.org/)</p>\n",
    "<p>For up-to-date validation tests, see <a href=\"./valtests.ipynb\" target=\"_blank\">valtests.ipynb</a></p>\n",
    "<div style=\"overflow-y: auto\">\n",
    "  <h2 class='tocIgnore'>Table of contents</h2>\n",
    "  <div id=\"toc\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('ipython_notebook_toc.js')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib as pl\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML, Markdown\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import plotly as ply\n",
    "#import plotly.graph_objs as plygo\n",
    "#import plotly.express as plyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:31:39,135 ads.eng INFO0\tFound MCDS.exe here: C:\\git\\perso\\autods\\Distance 7\\MCDS.exe.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'platform': 'win32',\n",
       " 'cpython': '3.8.2 | packaged by conda-forge | (default, Apr 24 2020, 07:34:03) [MSC v.1916 64 bit (AMD64)]',\n",
       " 'numpy': '1.19.4',\n",
       " 'pandas': '1.2.5',\n",
       " 'pickle': '4.0',\n",
       " 'zoopt': '0.4.0',\n",
       " 'matplotlib': '3.4.2'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autods as ads\n",
    "\n",
    "ads.runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:31:39,578 root INFO0\tWill log to Stream(stdout), File(tmp/valarc.log)\n"
     ]
    }
   ],
   "source": [
    "# Logging configuration.\n",
    "ads.log.configure(handlers=[sys.stdout, 'tmp/valarc.log'], verbose=True, reset=True)\n",
    "\n",
    "ads.logger('matplotlib', level=ads.WARNING, reset=True)\n",
    "\n",
    "ads.logger('ads', level=ads.INFO, reset=True)\n",
    "#ads.logger('ads.eng', level=ads.INFO, reset=True)\n",
    "#ads.logger('ads.exr', level=ads.DEBUG, reset=True)\n",
    "#ads.logger('ads.dat', level=ads.DEBUG, reset=True)\n",
    "ads.logger('ads.rep', level=ads.INFO1, reset=True)\n",
    "#ads.logger('ads.opn', level=ads.DEBUG, reset=True)\n",
    "#ads.logger('ads.opr', level=ads.DEBUG, reset=True)\n",
    "#ads.logger('ads.anr', level=ads.DEBUG, reset=True)\n",
    "ads.logger('ads.onr', level=ads.DEBUG1, reset=True)\n",
    "\n",
    "logger = ads.logger('valarc', level=ads.DEBUG, reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Run analyses with real life field data (1/2 : long code, long run)\n",
    "\n",
    "Note: Don't use this low level method : MCDSAnalyser is here for than now.\n",
    "\n",
    "Here we use directly MCDSAnalysis class.\n",
    "\n",
    "(for comparison to manually issued analyses with Distance 7.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load analyses set specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load refout results table\n",
    "refFileName = 'ACDC2019-Papyrus-ALAARV-TURMER-resultats-distance-73.xlsx'\n",
    "dfRefRes = pd.read_excel(pl.Path('refout', refFileName))\n",
    "dfRefRes.reset_index(inplace=True) # Generate analysis # (later need for original cases order)\n",
    "dfRefRes.rename(columns=dict(index='AnlysNum', Name='Model'), inplace=True)\n",
    "\n",
    "dfRefRes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate test cases definition code from refout results file (don't cheat : only input columns :-)\n",
    "modelIdCols = ['Model']\n",
    "modelParamCols = ['LTrunc', 'RTrunc', 'FitDistCuts', 'DiscrDistCuts']\n",
    "sampleSelCols = ['Species', 'Periods', 'Prec.', 'Duration']\n",
    "caseIdCols = ['AnlysNum', 'SampNum'] + sampleSelCols + modelIdCols\n",
    "\n",
    "dfRefRes['SampNum'] = dfRefRes.groupby(sampleSelCols, sort=False).ngroup()\n",
    "\n",
    "dfAnlysCases = dfRefRes[caseIdCols + modelParamCols].copy()\n",
    "\n",
    "dfAnlysCases['KeyFn'] = \\\n",
    "    dfAnlysCases.Model.apply(lambda s: 'UNIFORM' if s.startswith('Unif') \\\n",
    "                                                 else 'HNORMAL' if s.startswith('Half') else 'HAZARD')\n",
    "dfAnlysCases['AdjSer'] = \\\n",
    "    dfAnlysCases.Model.apply(lambda s: 'COSINE' if s.find(' Cos') > 0 \\\n",
    "                                                else 'POLY' if s.find(' SimPoly') > 0 else 'HERMITE')\n",
    "dfAnlysCases['InFileName'] = \\\n",
    "    dfAnlysCases.apply(lambda sRow: 'ACDC2019-Papyrus-{}-{}-{}mn-{}dec-dist.txt' \\\n",
    "                                    .format(sRow.Species,\n",
    "                                            'AB' if 'A+B' in sRow.Periods else 'A' if 'A' in sRow.Periods else 'B',\n",
    "                                            sRow.Duration.split(' ')[0], sRow['Prec.'].split(' ')[0]),\n",
    "                       axis='columns')\n",
    "dfAnlysCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def nan2None(v):\n",
    "#    return None if pd.isnull(v) else v\n",
    "def distCutsFromSpecs(v):\n",
    "    if pd.isnull(v):\n",
    "        return None\n",
    "    if isinstance(v, int):\n",
    "        return v\n",
    "    return [float(x) for x in v.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimalFields = ['Point transect*Survey effort', 'Observation*Radial distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis engine (sequential)\n",
    "mcds = ads.MCDSEngine(workDir=pl.Path('tmp', 'mcds-out'),\n",
    "                      executor=None, # Non-parallel: ~7.5s elapsed on a Lenovo P52 (6-core i7-8850H with PCI-e SSD)\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial', clustering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frozen analysis parameters (a choice here)\n",
    "KEstimCriterion = 'AIC'\n",
    "KCVInterval = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results object construction\n",
    "sampCols = [('sample', col, 'Value') for col in sampleSelCols]\n",
    "miSampCols = pd.MultiIndex.from_tuples(sampCols)\n",
    "\n",
    "sampIndCol = ('sample', 'SampNum', 'Value')\n",
    "custCols = [('sample', 'AnlysNum', 'Value'), sampIndCol] + sampCols + [('model', 'Model', 'Value')]\n",
    "miCustCols = pd.MultiIndex.from_tuples(custCols)\n",
    "\n",
    "dfCustColTrans = \\\n",
    "    pd.DataFrame(index=miCustCols,\n",
    "                 data=dict(en=caseIdCols, fr=['NumAnlys', 'NumEchant', 'Espèce', 'Périodes', 'Préc.', 'Durée', 'Modèle']))\n",
    "\n",
    "results = ads.MCDSAnalysisResultsSet(miCustomCols=miCustCols, dfCustomColTrans=dfCustColTrans,\n",
    "                                     miSampleCols=miSampCols, sampleIndCol=sampIndCol,\n",
    "                                     distanceUnit='Meter', areaUnit='Hectare',\n",
    "                                     surveyType='Point', distanceType='Radial', clustering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Or : Really run analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten test cases and reference results lists, to go faster\n",
    "# Warning: If you don't retain entire samples, later comparison will fail on Delta AIC values.\n",
    "#selCaseInds = [0, 5, 7, 22, 31] # Some random cases, with uncomplete samples.\n",
    "#selCaseInds = dfAnlysCases[dfAnlysCases.Sample.isin([3, 4])].index # A shorter selection, with complete samples.\n",
    "selCaseInds = range(len(dfAnlysCases)) # All of them.\n",
    "\n",
    "nOrigAnlysCases = len(dfAnlysCases)\n",
    "dfAnlysCases = dfAnlysCases.loc[selCaseInds]\n",
    "dfRefRes = dfRefRes.loc[selCaseInds]\n",
    "\n",
    "logger.info(f'Retained {len(selCaseInds)} out of {nOrigAnlysCases}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run all analyses\n",
    "lastInFileName = None\n",
    "for _, sCase in dfAnlysCases.iterrows():\n",
    "    \n",
    "    nCase = sCase.AnlysNum\n",
    "    name = sCase.InFileName[len('ACDC2019-Papyrus')+1:-len('-dist.txt')]\n",
    "    name += '-' + sCase.Model.lower().translate(str.maketrans({c:'-' for c in ' ,.:;()/'}))\n",
    "    logger.info(f'#{nCase+1:3d} {name} {sCase.KeyFn} {sCase.AdjSer}')\n",
    "    \n",
    "    # Create data set if not already done.\n",
    "    if lastInFileName != sCase.InFileName:\n",
    "        sds = ads.SampleDataSet(pl.Path('refin', sCase.InFileName), decimalFields=decimalFields)\n",
    "        lastInFileName = sCase.InFileName\n",
    "        \n",
    "    # Run analysis and get results\n",
    "    anlys = ads.MCDSAnalysis(engine=mcds, sampleDataSet=sds, name=name, logData=True,\n",
    "                             estimKeyFn=sCase.KeyFn, estimAdjustFn=sCase.AdjSer,\n",
    "                             estimCriterion=KEstimCriterion, cvInterval=KCVInterval,\n",
    "                             minDist=sCase.LTrunc, maxDist=sCase.RTrunc,\n",
    "                             fitDistCuts=distCutsFromSpecs(sCase.FitDistCuts),\n",
    "                             discrDistCuts=distCutsFromSpecs(sCase.DiscrDistCuts))\n",
    "\n",
    "    anlys.submit()\n",
    "    sResult = anlys.getResults()\n",
    "\n",
    "    # Save results\n",
    "    sHead = pd.Series(data=[sCase[col] for col in sCase.index[:len(caseIdCols)]], index=miCustCols)\n",
    "\n",
    "    results.append(sResult, sCustomHead=sHead)\n",
    "    \n",
    "# shutdown analysis engine\n",
    "mcds.shutdown()\n",
    "\n",
    "# Done.\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save results in case need for not recomputing them\n",
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "\n",
    "results.toExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-results-en.xlsx')\n",
    "\n",
    "results.toExcel(resFileName, sheetName='Auto', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check translation\n",
    "dfActTrRes = results.dfTransData('fr')\n",
    "\n",
    "dfActTrRes.head().T.iloc[:30] #.at['TroncGche', 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Or : Load analyses from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    results.fromExcel(resFileName, sheetName='AutoDSVal')\n",
    "    \n",
    "    # shutdown analysis engine\n",
    "    mcds.shutdown()\n",
    "\n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} analyses to compare'.format(len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Compare actual results to reference\n",
    "\n",
    "(reference = manually run analyses with Distance software)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract actual results to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis results\n",
    "dfActRes = results.dfData\n",
    "\n",
    "dfActRes.head().T[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of auto-results and match them with reference ones, for comparison.\n",
    "dCompCols = \\\n",
    "{\n",
    "    ('sample', 'AnlysNum', 'Value'):  'AnlysNum',\n",
    "    ('sample', 'SampNum', 'Value'):   'SampNum',\n",
    "    ('sample', 'Species', 'Value'):   'Species',\n",
    "    ('sample', 'Periods', 'Value'):   'Periods',\n",
    "    ('sample', 'Prec.', 'Value'):     'Prec.',\n",
    "    ('sample', 'Duration', 'Value'):  'Duration',\n",
    "    \n",
    "    ('model',  'Model', 'Value'):         'Model',\n",
    "    ('parameters', 'left truncation distance', 'Value'):           'LTrunc',\n",
    "    ('parameters', 'right truncation distance', 'Value'):          'RTrunc',\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'):  'FitDistCuts',\n",
    "    ('parameters', 'distance discretisation cut points', 'Value'): 'DiscrDistCuts',\n",
    "    \n",
    "    ('run output', 'run status', 'Value'): 'Status',\n",
    "    #('run output', 'run time', 'Value'): 'Run', # Only for unintests ref. generation just below\n",
    "    \n",
    "    ('detection probability', 'total number of parameters (m)', 'Value'): '# params',\n",
    "    ('encounter rate', 'number of observations (n)', 'Value'): '# obs',\n",
    "    \n",
    "    #('detection probability', 'Delta AIC', 'Value'): 'Delta AIC',\n",
    "    ('detection probability', 'AIC value', 'Value'): 'AIC',\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value')               : 'GOF Chi-p',\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value')                  : 'GOF K-S p',\n",
    "    ('detection probability', 'Cramér-von Mises (uniform weighting) test probability', 'Value'): 'GOF CvM (unif) p',\n",
    "    ('detection probability', 'Cramér-von Mises (cosine weighting) test probability', 'Value') : 'GOF CvM (cos) p',\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'): 'ESW/EDR',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl')  : 'ESW/EDR LCL',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl')  : 'ESW/EDR UCL',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Cv')   : 'ESW/EDR CV',\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'): 'D',\n",
    "    ('density/abundance', 'density of animals', 'Lcl')  : 'D LCL',\n",
    "    ('density/abundance', 'density of animals', 'Ucl')  : 'D UCL',\n",
    "    ('density/abundance', 'density of animals', 'Cv')   : 'D CV',\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'): 'P',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl')  : 'P LCL',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl')  : 'P UCL',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Cv')   : 'P CV',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df')   : 'P DF',\n",
    "}\n",
    "len(dCompCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Unused columns (full of NaNs) have been automatically removed\n",
    "# (see last line of AnalysisResultsSet.dfData getter)\n",
    "dCompCols = { k: v for k, v in dCompCols.items() if k in dfActRes.columns }\n",
    "len(dCompCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we need to cleanup modelParamCols too\n",
    "modelParamCols = [id_ for id_ in modelParamCols if id_ in dCompCols.values()]\n",
    "len(modelParamCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe stringification of model params\n",
    "# * needed for use in indexes (hashability)\n",
    "# * needed to cope with to_excel/read_excel unconsistent None management\n",
    "def modelParam2Str(par):\n",
    "    #print(par)\n",
    "    if isinstance(par, list):\n",
    "        spar = str([float(v) for v in par])\n",
    "    elif pd.isnull(par):\n",
    "        spar = 'None'\n",
    "    elif isinstance(par, str):\n",
    "        if ',' in par: # Assumed already somewhat stringified list\n",
    "            spar = str([float(v) for v in par.strip('[]').split(',')])\n",
    "    else:\n",
    "        spar = str(par)\n",
    "    return spar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select results columns and rename them as the reference is, for easier comparison\n",
    "dfActRes4c = dfActRes[list(dCompCols.keys())].copy()\n",
    "dfActRes4c.columns = [dCompCols[col] for col in dCompCols]\n",
    "dfActRes4c[modelParamCols] = dfActRes4c[modelParamCols].applymap(modelParam2Str) # Hashable mandatory for indexing\n",
    "dfActRes4c.set_index(caseIdCols + modelParamCols, inplace=True)\n",
    "\n",
    "dfActRes4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select usefull reference columns for comparison\n",
    "dfRefRes4c = dfRefRes.copy()\n",
    "dfRefRes4c[modelParamCols] = dfRefRes4c[modelParamCols].applymap(modelParam2Str) # Hashable mandatory for indexing\n",
    "dfRefRes4c.set_index(caseIdCols + modelParamCols, inplace=True)\n",
    "dfRefRes4c = dfRefRes4c.reindex(columns=dfActRes4c.columns)\n",
    "\n",
    "dfRefRes4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfActRes4c.to_excel('tmp/act-res.xlsx')\n",
    "#dfRefRes4c.to_excel('tmp/ref-res.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Automated diagnosis\n",
    "\n",
    "Note: Since then, ads.DataSet.compare has been developed based on this prototype ... use it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First checks : equality of test case lists (index) and of column names (columns)\n",
    "assert sorted(dfActRes4c.index)   == sorted(dfRefRes4c.index)\n",
    "assert sorted(dfActRes4c.columns) == sorted(dfRefRes4c.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual / reference closeness measure : -round(log10((actual - reference) / max(abs(actual), abs(reference))), 1)\n",
    "# = Compute the order of magnitude that separate the difference from the absolute max. of the two values\n",
    "# The greater it is, the lower the relative difference\n",
    "#    Ex: 3 = 10**3 ratio between difference absolue max. of the two,\n",
    "#        +inf = NO difference at all,\n",
    "#        0 = bad, one of the two is 0, and the other not,\n",
    "# See unitary test below.\n",
    "def closeness(sRefAct):\n",
    "    \n",
    "    x, y = sRefAct.to_list()\n",
    "    \n",
    "    # Special cases with 1 NaN, or 1 or more inf => all different\n",
    "    if np.isnan(x):\n",
    "        if not np.isnan(y):\n",
    "            return 0 # All different\n",
    "    elif np.isnan(y):\n",
    "        return 0 # All different\n",
    "    \n",
    "    if np.isinf(x) or np.isinf(y):\n",
    "        return 0 # All different\n",
    "    \n",
    "    # Normal case\n",
    "    c = abs(x - y)\n",
    "    if not np.isnan(c) and c != 0:\n",
    "        c = c / max(abs(x), abs(y))\n",
    "    \n",
    "    return np.inf if c == 0 else round(-np.log10(c), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Actual / reference comparison : compute closeness indicator\n",
    "dfRelDif = dfRefRes4c.copy()\n",
    "for col in dfRelDif.columns:\n",
    "    dfRelDif['act'] = dfActRes4c[col]\n",
    "    dfRelDif[col] = dfRelDif[[col, 'act']].apply(closeness, axis='columns')\n",
    "    dfRelDif.drop(columns='act', inplace=True)\n",
    "    \n",
    "dfRelDif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis : we only keep lines and columns with some relevant differences.\n",
    "dfBadRelDif = dfRelDif.copy()\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Suppress rows : Same status and NaNs in the remainder (if status == 0/3/4, execution error or no execution)\n",
    "valCols = [col for col in dfRelDif.columns if col != 'Status']\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif.Status.abs() == np.inf) & dfBadRelDif[valCols].isnull().all(axis='columns')].index,\n",
    "                 axis='index', inplace=True)\n",
    "assert len(dfBadRelDif) == 29, len(dfBadRelDif)\n",
    "anlysNums = dfBadRelDif.index.get_level_values('AnlysNum').to_list()\n",
    "assert anlysNums == [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17,\n",
    "                     18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], anlysNums\n",
    "print(len(dfBadRelDif), 'analyses:', ', '.join(map(str, anlysNums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Suppress rows : Status and all other columns == inf (<=> strict equality)\n",
    "#    NB. Some very small differences observed when results have just been computed or when they have been\n",
    "#        loaded from a previously saved Excel file (above 10**15 closeness value)\n",
    "dfBadRelDif.drop(dfBadRelDif[dfBadRelDif.apply(np.isinf, axis='columns').all(axis='columns')].index,\n",
    "                 axis='index', inplace=True)\n",
    "assert (computed and len(dfBadRelDif) <= 26) or (not computed and len(dfBadRelDif) <= 17), len(dfBadRelDif)\n",
    "anlysNums = dfBadRelDif.index.get_level_values('AnlysNum').to_list()\n",
    "assert (computed and all(anlysNum in [0, 1, 2, 5, 6, 7, 8, 9, 13, 14, 15, 17, 18,\n",
    "                                       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "                         for anlysNum in anlysNums)) \\\n",
    "       or (not computed and all(anlysNum in [0, 1, 2, 7, 8, 9, 13, 14, 15, 19, 20, 23, 25, 27, 28, 29, 30]\n",
    "                                for anlysNum in anlysNums)), \\\n",
    "       anlysNums\n",
    "print(len(dfBadRelDif), 'analyses:', ', '.join(map(str, anlysNums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Suppress rows : Status and all other columns >= à 15 (<=> nearly strict equality)\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif >= 15).all(axis='columns')].index, axis='index', inplace=True)\n",
    "assert len(dfBadRelDif) == 5, len(dfBadRelDif)\n",
    "anlysNums = dfBadRelDif.index.get_level_values('AnlysNum').to_list()\n",
    "assert all(anlysNum in [9, 20, 28, 29, 30] for anlysNum in anlysNums), anlysNums\n",
    "print(len(dfBadRelDif), 'analyses:', ', '.join(map(str, anlysNums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Suppress rows : Same status and all other columns >= 4 (<=> close to equality)\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif >= 4).all(axis='columns')].index, axis='index', inplace=True)\n",
    "assert len(dfBadRelDif) == 4, len(dfBadRelDif)\n",
    "anlysNums = dfBadRelDif.index.get_level_values('AnlysNum').to_list()\n",
    "assert all(anlysNum in [9, 20, 28, 30] for anlysNum in anlysNums), anlysNums\n",
    "print(len(dfBadRelDif), 'analyses:', ', '.join(map(str, anlysNums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Suppress rows : Same status and all other columns >= 4 (<=> close to equality)\n",
    "#                    except for GOF KS and CvM, equal to NaN, because not computed when distances are discretised.\n",
    "if 'DiscrDistCuts' in dfBadRelDif.index.names:\n",
    "    discrCols = [col for col in dfRelDif.columns if not col.startswith('GOF') or col.find('Chi') > 0]\n",
    "    df2Drop = (dfBadRelDif.index.get_level_values('DiscrDistCuts') != -1) & (dfBadRelDif[discrCols] >= 4).all(axis='columns')\n",
    "    dfBadRelDif.drop(dfBadRelDif[df2Drop].index, axis='index', inplace=True)\n",
    "assert len(dfBadRelDif) == 2, len(dfBadRelDif)\n",
    "anlysNums = dfBadRelDif.index.get_level_values('AnlysNum').to_list()\n",
    "assert all(anlysNum in [9, 30] for anlysNum in anlysNums), anlysNums\n",
    "print(len(dfBadRelDif), 'analyses:', ', '.join(map(str, anlysNums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verdict (Cf. refFileName Excel file, sheet \"DiffAuto\" for explanations about the 2 different rows between Act/Ref)\n",
    "dfBadRelDif.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRefRes4c.loc[dfBadRelDif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFails = len(dfBadRelDif.index)\n",
    "if nFails > 0:\n",
    "    print(f'Warning: {nFails} test case(s) failed ;')\n",
    "    print(f' ... see sheet \"DiffAuto\" of {refFileName} for possible explanations.')\n",
    "else:\n",
    "    print('All test cases succeeded !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save results to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resCompFileName = os.path.join(mcds.workDir, 'autods-validation-rescomp.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(resCompFileName) as xlsxWriter:\n",
    "\n",
    "    dfRefRes.to_excel(xlsxWriter, sheet_name='RefResults', index=True)\n",
    "    dfActRes4c.reset_index().to_excel(xlsxWriter, sheet_name='ActResults', index=False)\n",
    "    dfRelDif.reset_index().to_excel(xlsxWriter, sheet_name='Diff2Ref', index=False)\n",
    "    dfBadRelDif.reset_index().to_excel(xlsxWriter, sheet_name='BadDiff2Ref', index=False)\n",
    "    dfRefRes4c.loc[dfBadRelDif.index].reset_index().to_excel(xlsxWriter, sheet_name='RefResWithDiff', index=False)\n",
    "    dfActRes4c.loc[dfBadRelDif.index].reset_index().to_excel(xlsxWriter, sheet_name='ActResWithDiff', index=False)\n",
    "    dfActRes.to_excel(xlsxWriter, sheet_name='RawActResults', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build HTML and Excel reports\n",
    "\n",
    "See [IV. Excel and HTML reports](#IV.-Excel-and-HTML-reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Parallel run of same analyses\n",
    "\n",
    "Note: Don't use this low level method : MCDSAnalyser is here for than now.\n",
    "\n",
    "Here, we directly call MCDSAnalysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare analyses\n",
    "\n",
    "(same test cases and input data as previously, for easy comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis executor : 6, 8, None threads => min elapsed = ~2s on a Lenovo P52 (6-core i7-8850H with PCI-e SSD)\n",
    "parallelExecutor = ads.Executor(threads=6)\n",
    "\n",
    "# Analysis engine\n",
    "mcds = ads.MCDSEngine(workDir=pl.Path('tmp') / 'mcds-pout', executor=parallelExecutor, \n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial', clustering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results object construction\n",
    "parResults = ads.MCDSAnalysisResultsSet(miCustomCols=miCustCols, miSampleCols=miSampCols, dfCustomColTrans=dfCustColTrans, \n",
    "                                        distanceUnit='Meter', areaUnit='Hectare', sampleIndCol=sampIndCol,\n",
    "                                        surveyType='Point', distanceType='Radial', clustering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Or : Really run analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten test cases and reference results lists, to go faster\n",
    "# Warning: If you don't retain entire samples, later comparison will fail on Delta AIC values.\n",
    "#selCaseInds = [0, 5, 7, 22, 31] # Some random cases, with uncomplete samples.\n",
    "#selCaseInds = dfAnlysCases[dfAnlysCases.Sample.isin([3, 4])].index # A shorter selection, with complete samples.\n",
    "selCaseInds = range(len(dfAnlysCases)) # All of them.\n",
    "\n",
    "nOrigAnlysCases = len(dfAnlysCases)\n",
    "dfAnlysCases = dfAnlysCases.loc[selCaseInds]\n",
    "dfRefRes = dfRefRes.loc[selCaseInds]\n",
    "\n",
    "logger.info(f'Retained {len(selCaseInds)} out of {nOrigAnlysCases}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Start running all analyses\n",
    "lastInFileName = None\n",
    "analyses = dict()\n",
    "for _, sCase in dfAnlysCases.iterrows():\n",
    "    \n",
    "    nCase = sCase.AnlysNum\n",
    "    name = sCase.InFileName[len('ACDC2019-Papyrus')+1:-len('-dist.txt')]\n",
    "    name += '-' + sCase.Model.lower().translate(str.maketrans({c:'-' for c in ' ,.:;()/'}))\n",
    "    logger.info(f'#{nCase+1:3d} {name} {sCase.KeyFn} {sCase.AdjSer}')\n",
    "    \n",
    "    # Create data set if not already done.\n",
    "    if lastInFileName != sCase.InFileName:\n",
    "        sds = ads.SampleDataSet(pl.Path('refin', sCase.InFileName), decimalFields=decimalFields)\n",
    "        lastInFileName = sCase.InFileName\n",
    "        \n",
    "    # Start running analysis in parallel (don't wait for it's finished, go on)\n",
    "    sResHead = pd.Series(data=[sCase[col] for col in sCase.index[:len(caseIdCols)]], index=miCustCols)\n",
    "\n",
    "    anlys = ads.MCDSAnalysis(engine=mcds, sampleDataSet=sds, name=name, customData=sResHead, logData=True,\n",
    "                             estimKeyFn=sCase.KeyFn, estimAdjustFn=sCase.AdjSer,\n",
    "                             estimCriterion=KEstimCriterion, cvInterval=KCVInterval,\n",
    "                             minDist=sCase.LTrunc, maxDist=sCase.RTrunc,\n",
    "                             #minDist=nan2None(sCase.LTrunc), maxDist=nan2None(sCase.RTrunc),\n",
    "                             fitDistCuts=distCutsFromSpecs(sCase.FitDistCuts), # TODO: do this when building dfAnlysCases\n",
    "                             discrDistCuts=distCutsFromSpecs(sCase.DiscrDistCuts))\n",
    "    anlysFut = anlys.submit()\n",
    "    \n",
    "    # Store analysis object and associated \"future\" for later use (should be running soon or later).\n",
    "    analyses[anlysFut] = anlys\n",
    "    \n",
    "logger.info('All analyses started ; now waiting for their end, and results ...')\n",
    "\n",
    "# For each analysis as it gets completed (first completed => first yielded)\n",
    "for anlysFut in parallelExecutor.asCompleted(analyses):\n",
    "\n",
    "    # Retrieve analysis object from its associated future object\n",
    "    anlys = analyses[anlysFut]\n",
    "    \n",
    "    # Get analysis results\n",
    "    sResult = anlys.getResults()\n",
    "\n",
    "    # Save results with header\n",
    "    parResults.append(sResult, sCustomHead=anlys.customData)\n",
    "    \n",
    "# shutdown analysis engine\n",
    "mcds.shutdown()\n",
    "\n",
    "# Done.\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save results in case need for not recomputing them\n",
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "\n",
    "parResults.toExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Or : Load analyses from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    parResults.fromExcel(resFileName, sheetName='AutoDSVal')\n",
    "    \n",
    "    # shutdown analysis engine\n",
    "    mcds.shutdown()\n",
    "\n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print(f'... {len(parResults)} analyses to compare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare parallel results to sequential ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare sequential results for comparison\n",
    "dfSeqCmpRes = results.dfTransData('en')\n",
    "\n",
    "dfSeqCmpRes.fillna(-9999, inplace=True) # Get rid of the Nan pb (because NaN != NaN :-)\n",
    "\n",
    "# Start date-time and elapsed time and folder can never be the same\n",
    "dfSeqCmpRes.drop(columns=['StartTime', 'ElapsedTime', 'RunFolder'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare parallel results for comparison\n",
    "dfParCmpRes = parResults.dfTransData('en')\n",
    "\n",
    "dfParCmpRes.sort_values(by='AnlysNum', inplace=True) # Back to original test case order = sequential run order\n",
    "\n",
    "dfParCmpRes.reset_index(inplace=True, drop=True) # Enforce same index as a consequence\n",
    "\n",
    "dfParCmpRes.fillna(-9999, inplace=True) # And get rid of the Nan pb (because NaN != Nan :-)\n",
    "\n",
    "# Start date-time and elapsed time and folder can never be the same\n",
    "dfParCmpRes.drop(columns=['StartTime', 'ElapsedTime', 'RunFolder'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Doesn't work if 1 of the 2 sets (not both) was loaded from disk (Excel numerical rounding stuff)\n",
    "assert (dfSeqCmpRes == dfParCmpRes).all().all(), \\\n",
    "       'Oh, oh, something went differently when run parallely ... but due to one results set loaded from disk ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSeqCmpRes.compare(dfParCmpRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Excel and HTML reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want to report parallel results.\n",
    "# Or NOT if you want to report sequential sequential\n",
    "seqResults = results\n",
    "results = parResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes pour les tableaux de synthèse du rapport\n",
    "synthRepCols = \\\n",
    "[\n",
    "    ('sample', 'AnlysNum', 'Value'),\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Periods', 'Value'),\n",
    "    ('sample', 'Prec.', 'Value'),\n",
    "    ('sample', 'Duration', 'Value'),\n",
    "    ('sample', 'SampNum', 'Value'),\n",
    "    ('sample stats', 'total number of observations', 'Value'),\n",
    "    ('sample stats', 'maximal observation distance', 'Value'),\n",
    "    \n",
    "    ('model', 'Model', 'Value'),\n",
    "    ('parameters', 'left truncation distance', 'Value'),\n",
    "    ('parameters', 'right truncation distance', 'Value'),\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'),\n",
    "    ('parameters', 'distance discretisation cut points', 'Value'),\n",
    "    \n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    ('encounter rate', 'effort (L or K or T)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'Delta AIC', 'Value'),\n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Delta Cv'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    \n",
    "    ('encounter rate', 'observation rate', 'Value'),\n",
    "    ('combined quality', 'balanced 1', 'Value'),\n",
    "    ('combined quality', 'balanced 2', 'Value'),\n",
    "    ('combined quality', 'balanced 3', 'Value'),\n",
    "    ('combined quality', 'more Chi2', 'Value'),\n",
    "    ('combined quality', 'more KS', 'Value'),\n",
    "    ('combined quality', 'more DCv', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl'),\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df'),\n",
    "\n",
    "    ('run output', 'run folder', 'Value'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select analysis results columns for the 3 textual columns of the synthesis pre-report\n",
    "sampleRepCols = \\\n",
    "[\n",
    "    ('sample', 'SampNum', 'Value'),\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Periods', 'Value'),\n",
    "    ('sample', 'Prec.', 'Value'),\n",
    "    ('sample', 'Duration', 'Value'),\n",
    "    ('sample', 'AnlysNum', 'Value'),\n",
    "    ('sample stats', 'total number of observations', 'Value'),\n",
    "    ('sample stats', 'maximal observation distance', 'Value'),\n",
    "]\n",
    "\n",
    "paramRepCols = \\\n",
    "[\n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    ('parameters', 'left truncation distance', 'Value'),\n",
    "    ('parameters', 'right truncation distance', 'Value'),\n",
    "]\n",
    "    \n",
    "resultRepCols = \\\n",
    "[\n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    ('encounter rate', 'left truncation distance', 'Value'),\n",
    "    ('encounter rate', 'right truncation distance (w)', 'Value'),\n",
    "    ('encounter rate', 'effort (L or K or T)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('combined quality', 'balanced 1', 'Value'),\n",
    "    ('combined quality', 'balanced 2', 'Value'),\n",
    "    ('combined quality', 'balanced 3', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortRepCols = \\\n",
    "[('sample', 'SampNum', 'Value'), ('sample', 'AnlysNum', 'Value')] \\\n",
    "+ [('sample', col, 'Value') for col in sampleSelCols] \\\n",
    "+ [('parameters', 'left truncation distance', 'Value'),\n",
    "   ('parameters', 'right truncation distance', 'Value'),\n",
    "   ('detection probability', 'Delta AIC', 'Value')]\n",
    "#   ('density/abundance', 'density of animals', 'Delta Cv')]\n",
    "\n",
    "sortRepAscend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ads.MCDSResultsFullReport(resultsSet=results, \n",
    "                                   sampleCols=sampleRepCols, paramCols=paramRepCols,\n",
    "                                   resultCols=resultRepCols, synthCols=synthRepCols,\n",
    "                                   sortCols=sortRepCols, sortAscend=sortRepAscend,\n",
    "                                   title='Validation AutoDS : Analyses automatiques', subTitle='Rapport d\\'analyse global',\n",
    "                                   anlysSubTitle='Rapport détaillé',\n",
    "                                   description=(\"Résultats d'analyses exécutées \"\n",
    "                                                + ('en parallèle' if mcds.workDir.name.endswith('pout')\n",
    "                                                   else 'séquentiellement')),\n",
    "                                   keywords='autods, validation', pySources=['valtests.ipynb'],\n",
    "                                   lang='fr', superSynthPlotsHeight=288,\n",
    "                                   #plotImgSize=(640, 400), plotLineWidth=1, plotDotWidth=4,\n",
    "                                   #plotFontSizes=dict(title=11, axes=10, ticks=9, legend=10),\n",
    "                                   tgtFolder=mcds.workDir, tgtPrefix='autods-validation-report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlsxRep = report.toExcel()\n",
    "\n",
    "HTML(f'Rapport Excel : <a href=\"{xlsxRep}\" target=\"blank\">{xlsxRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Lenovo T490  (4-core i5-8350U with PCI-e SSD) 6 generators (2021-02-13) : 38s (n=3)\n",
    "htmlRep = report.toHtml(generators=6)\n",
    "\n",
    "HTML(f'Rapport HTML : <a href=\"{htmlRep}\" target=\"blank\">{htmlRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Run and report pre-analyses (1/2 : long code, long duration)\n",
    "\n",
    "(to help users to setup the full analyses plan : run first try simple analyses and show PDF and few results)\n",
    "\n",
    "On same input data as for I, II, III.\n",
    "\n",
    "Note: Don't use this low level method : MCDSPreAnalyser is here for than now.\n",
    "\n",
    "Here we directly call MCDSPreAnalysis class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Determine samples from input data\n",
    "\n",
    "* in real life, we'd simply load field collected data, and deduce individual \"samples\" from it ;\n",
    "* but there, for testing, it's easier to deduce samples from manual analysis specification file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create sample table from refout results table\n",
    "refFileName = 'ACDC2019-Papyrus-ALAARV-TURMER-resultats-distance-73.xlsx'\n",
    "\n",
    "sampleSelCols = ['Species', 'Periods', 'Prec.', 'Duration']\n",
    "\n",
    "dfSamples = pd.read_excel(pl.Path('refout', refFileName), usecols=sampleSelCols)\n",
    "dfSamples.rename(columns=dict(Name='Model'), inplace=True)\n",
    "dfSamples.drop_duplicates(inplace=True)\n",
    "dfSamples.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dfSamples.reset_index(inplace=True) # Generate sample # (later need for original sample order)\n",
    "sampleIndCol = 'SampleNum'\n",
    "dfSamples.rename(columns=dict(index=sampleIndCol), inplace=True)\n",
    "\n",
    "sampleSelCols = [sampleIndCol] + sampleSelCols\n",
    "\n",
    "dfSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare pre-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimalFields = ['Point transect*Survey effort', 'Observation*Radial distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis engine: Non-parallel executor here, 'cause MCDSPreAnalysis takes care of this !\n",
    "mcds = ads.MCDSEngine(workDir=pl.Path('tmp') / 'mcds-preout', \n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial', clustering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results object construction\n",
    "custCols = [('sample', col, 'Value') for col in sampleSelCols]\n",
    "sampMIndCol = next(iter(mCol for mCol in custCols if mCol[1] == sampleIndCol))\n",
    "miCustCols = pd.MultiIndex.from_tuples(custCols)\n",
    "dfCustColTrans = \\\n",
    "    pd.DataFrame(index=miCustCols,\n",
    "                 data=dict(en=sampleSelCols, fr=['NumEchant', 'Espèce', 'Périodes', 'Préc.', 'Durée']))\n",
    "\n",
    "preResults = ads.MCDSPreAnalysisResultsSet(miCustomCols=miCustCols, dfCustomColTrans=dfCustColTrans, sampleIndCol=sampMIndCol,\n",
    "                                           distanceUnit='Meter', areaUnit='Hectare',\n",
    "                                           surveyType='Point', distanceType='Radial', clustering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPreEstimCrit = 'AIC'\n",
    "KPreCVInterval = 95\n",
    "KPreEstimModStrat = [dict(keyFn=kf, adjSr='COSINE', estCrit=KPreEstimCrit, cvInt=KPreCVInterval) \\\n",
    "                     for kf in['HNORMAL', 'HAZARD', 'UNIFORM', 'NEXPON']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Or : Really run pre-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run all analyses\n",
    "lastInFileName = None\n",
    "for _, sSamp in dfSamples.iterrows():\n",
    "    \n",
    "    nSamp = sSamp.SampleNum\n",
    "    sampId = '{}-{}-{}mn-{}dec' \\\n",
    "             .format(sSamp.Species,\n",
    "                     'AB' if 'A+B' in sSamp.Periods else 'A' if 'A' in sSamp.Periods else 'B',\n",
    "                     sSamp.Duration.split(' ')[0], sSamp['Prec.'].split(' ')[0])\n",
    "    logger.info(f'#{nSamp+1:3d} {sampId}')\n",
    "    \n",
    "    # Create data set if not already done.\n",
    "    inFileName = 'ACDC2019-Papyrus-{}-dist.txt'.format(sampId)\n",
    "    if lastInFileName != inFileName:\n",
    "        sds = ads.SampleDataSet(pl.Path('refin', inFileName), decimalFields=decimalFields)\n",
    "        lastInFileName = inFileName\n",
    "        \n",
    "    # Run analysis: Not parallel runs for now ... see below.\n",
    "    preAnlys = ads.MCDSPreAnalysis(engine=mcds, sampleDataSet=sds, name=sampId, executor=None,\n",
    "                                   logData=False, modelStrategy=KPreEstimModStrat)\n",
    "    preAnlys.submit()\n",
    "    \n",
    "    # Get results (wait for it's finished)\n",
    "    sResult = preAnlys.getResults()\n",
    "\n",
    "    # Save results\n",
    "    sResHead = sSamp.copy()\n",
    "    sResHead.index = miCustCols\n",
    "    preResults.append(sResult, sCustomHead=sResHead)\n",
    "    \n",
    "# shutdown analysis engine\n",
    "mcds.shutdown()\n",
    "\n",
    "# Done.\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at results\n",
    "preResults.dfTransData('fr')[['NumEchant', 'Espèce', 'Périodes', 'Préc.', 'Durée', 'Fn Clé',\n",
    "                              'Sér Ajust', 'CodEx', 'NObs', 'AIC', 'Chi2 P', 'KS P', \n",
    "                              'Densité', 'CoefVar Densité', 'Min Densité', 'Max Densité']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save results in case need for not recomputing them\n",
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-preresults.xlsx')\n",
    "\n",
    "preResults.toExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Or : Load pre-analyses results from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    resFileName = os.path.join(mcds.workDir, 'autods-validation-preresults.xlsx')\n",
    "    print(f'Loading pre-results from {resFileName} ...')\n",
    "\n",
    "    preResults.fromExcel(resFileName, sheetName='AutoDSVal')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print(f'... {len(preResults)} pre-analyses loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at results\n",
    "preResults.dfTransData('fr')[['NumEchant', 'Espèce', 'Périodes', 'Préc.', 'Durée', 'Fn Clé',\n",
    "                              'Sér Ajust', 'CodEx', 'NObs', 'AIC', 'Chi2 P', 'KS P', \n",
    "                              'Densité', 'CoefVar Densité', 'Min Densité', 'Max Densité']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HTML and Excel pre-analyses reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want to report parallel results.\n",
    "# Or NOT if you want to report sequential sequential\n",
    "seqPreResults = preResults\n",
    "preResults = parPreResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes pour les tableaux de synthèse du rapport\n",
    "synthPreRepCols = \\\n",
    "[\n",
    "    ('sample', 'SampleNum', 'Value'),\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Periods', 'Value'),\n",
    "    ('sample', 'Prec.', 'Value'),\n",
    "    ('sample', 'Duration', 'Value'),\n",
    "    ('sample stats', 'total number of observations', 'Value'),\n",
    "    ('sample stats', 'maximal observation distance', 'Value'),\n",
    "    \n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    ('parameters', 'model fitting distance cut points', 'Value'),\n",
    "    ('parameters', 'distance discretisation cut points', 'Value'),\n",
    "    \n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    ('encounter rate', 'right truncation distance (w)', 'Value'),\n",
    "    ('encounter rate', 'effort (L or K or T)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    ('encounter rate', 'observation rate', 'Value'),\n",
    "    ('combined quality', 'balanced 1', 'Value'),\n",
    "    ('combined quality', 'balanced 2', 'Value'),\n",
    "    ('combined quality', 'balanced 3', 'Value'),\n",
    "    ('combined quality', 'more Chi2', 'Value'),\n",
    "    ('combined quality', 'more KS', 'Value'),\n",
    "    ('combined quality', 'more DCv', 'Value'),\n",
    "    \n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl'),\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df'),\n",
    "\n",
    "    ('run output', 'run folder', 'Value'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select analysis results columns for the 3 textual columns of the synthesis pre-report\n",
    "samplePreRepCols = \\\n",
    "[\n",
    "    ('sample', 'SampleNum', 'Value'),\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Periods', 'Value'),\n",
    "    ('sample', 'Prec.', 'Value'),\n",
    "    ('sample', 'Duration', 'Value'),\n",
    "    ('sample stats', 'total number of observations', 'Value'),\n",
    "    ('sample stats', 'maximal observation distance', 'Value'),\n",
    "]\n",
    "\n",
    "paramPreRepCols = \\\n",
    "[\n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    ('parameters', 'CV interval', 'Value')\n",
    "]\n",
    "    \n",
    "resultPreRepCols = \\\n",
    "[\n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    ('encounter rate', 'effort (L or K or T)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "\n",
    "    ('encounter rate', 'observation rate', 'Value'),\n",
    "    ('combined quality', 'balanced 1', 'Value'),\n",
    "    ('combined quality', 'balanced 2', 'Value'),\n",
    "    ('combined quality', 'balanced 3', 'Value'),\n",
    "    ('combined quality', 'more Chi2', 'Value'),\n",
    "    ('combined quality', 'more KS', 'Value'),\n",
    "    ('combined quality', 'more DCv', 'Value'),\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortPreRepCols = [('sample', 'SampleNum', 'Value')]\n",
    "\n",
    "sortPreRepAscend = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preReport = ads.MCDSResultsPreReport(resultsSet=preResults,\n",
    "                                     title='Validation AutoDS : Pré-analyses', subTitle='Rapport de pré-analyse',\n",
    "                                     anlysSubTitle='Détail des pré-analyses',\n",
    "                                     description=(\"Résultats de pré-analyses exécutées \"\n",
    "                                                  + ('en parallèle' if mcds.workDir.name.endswith('pout')\n",
    "                                                     else 'séquentiellement')),\n",
    "                                     keywords='autods, validation', lang='fr', superSynthPlotsHeight=288,\n",
    "                                     #plotImgSize=(640, 400), plotLineWidth=1, plotDotWidth=4,\n",
    "                                     #plotFontSizes=dict(title=11, axes=10, ticks=9, legend=10),\n",
    "                                     sampleCols=samplePreRepCols, paramCols=paramPreRepCols,\n",
    "                                     resultCols=resultPreRepCols, synthCols=synthPreRepCols,\n",
    "                                     sortCols=sortPreRepCols, sortAscend=sortPreRepAscend,\n",
    "                                     tgtFolder=mcds.workDir, tgtPrefix='autods-validation-prereport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xlsxPreRep = preReport.toExcel()\n",
    "\n",
    "HTML(f'Rapport Excel : <a href=\"{xlsxPreRep}\" target=\"blank\">{xlsxPreRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "htmlPreRep = preReport.toHtml()\n",
    "\n",
    "HTML(f'Pré-rapport HTML : <a href=\"{htmlPreRep}\" target=\"blank\">{htmlPreRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preResults.specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Parallel run of same pre-analyses (2/2 : long code, short duration)\n",
    "\n",
    "And compare results to sequential run's.\n",
    "\n",
    "Note: Don't use this low level method : MCDSPreAnalyser is here for than now.\n",
    "\n",
    "Here we directly call MCDSPreAnalysis class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis engine : Non-parallel executor here: MCDSPreAnalysis takes care of this !\n",
    "mcds = ads.MCDSEngine(workDir=pl.Path('tmp') / 'mcds-prepout', \n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial', clustering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results object construction\n",
    "parPreResults = ads.MCDSPreAnalysisResultsSet(miCustomCols=miCustCols, dfCustomColTrans=dfCustColTrans,\n",
    "                                              sampleIndCol=sampMIndCol, \n",
    "                                              distanceUnit='Meter', areaUnit='Hectare',\n",
    "                                              surveyType='Point', distanceType='Radial', clustering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Or : Really run pre-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-analysis executor (kind of overkill here, with only 5 pre-analyses ... but still works twice as rapidly !).\n",
    "parallelExecutor = ads.Executor(threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run all analyses\n",
    "lastInFileName = None\n",
    "parPreAnalyses = dict()\n",
    "for _, sSamp in dfSamples.iterrows():\n",
    "    \n",
    "    nSamp = sSamp.SampleNum\n",
    "    sampId = '{}-{}-{}mn-{}dec' \\\n",
    "             .format(sSamp.Species,\n",
    "                     'AB' if 'A+B' in sSamp.Periods else 'A' if 'A' in sSamp.Periods else 'B',\n",
    "                     sSamp.Duration.split(' ')[0], sSamp['Prec.'].split(' ')[0])\n",
    "    logger.info(f'#{nSamp+1:3d} {sampId}')\n",
    "    \n",
    "    # Create data set if not already done.\n",
    "    inFileName = 'ACDC2019-Papyrus-{}-dist.txt'.format(sampId)\n",
    "    if lastInFileName != inFileName:\n",
    "        sds = ads.SampleDataSet(pl.Path('refin', inFileName), decimalFields=decimalFields)\n",
    "        lastInFileName = inFileName\n",
    "        \n",
    "    # Start running analysis (but don't wait for it's finished)\n",
    "    sResHead = sSamp.copy()\n",
    "    sResHead.index = miCustCols\n",
    "    \n",
    "    preAnlys = ads.MCDSPreAnalysis(engine=mcds, sampleDataSet=sds, name=sampId,\n",
    "                                   customData=sResHead, executor=parallelExecutor,\n",
    "                                   logData=False, modelStrategy=KPreEstimModStrat)\n",
    "    preAnlysFut = preAnlys.submit()\n",
    "    \n",
    "    # Store analysis object and associated \"future\" for later use (should be running soon or later).\n",
    "    parPreAnalyses[preAnlysFut] = preAnlys\n",
    "    \n",
    "logger.info('All pre-analyses started ; now waiting for their end, and results ...')\n",
    "\n",
    "# For each analysis as it gets completed (first completed => first yielded)\n",
    "for preAnlysFut in parallelExecutor.asCompleted(parPreAnalyses):\n",
    "\n",
    "    # Retrieve pre-analysis object from its associated future object\n",
    "    preAnlys = parPreAnalyses[preAnlysFut]\n",
    "    \n",
    "    # Get pre-analysis results\n",
    "    sResult = preAnlys.getResults()\n",
    "\n",
    "    # Save results with header\n",
    "    parPreResults.append(sResult, sCustomHead=preAnlys.customData)\n",
    "    \n",
    "# shutdown executor\n",
    "parallelExecutor.shutdown()\n",
    "\n",
    "# shutdown analysis engine\n",
    "mcds.shutdown()\n",
    "\n",
    "# Done.\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at results\n",
    "parPreResults.dfTransData('fr')[['NumEchant', 'Espèce', 'Périodes', 'Préc.', 'Durée', 'Fn Clé',\n",
    "                                 'Sér Ajust', 'CodEx', 'NObs', 'AIC', 'Chi2 P', 'KS P', \n",
    "                                 'Densité', 'CoefVar Densité', 'Min Densité', 'Max Densité']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save results in case need for not recomputing them\n",
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-preresults-par.xlsx')\n",
    "\n",
    "parPreResults.toExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Or : Load analyses from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    resFileName = os.path.join(mcds.workDir, 'autods-validation-preresults-par.xlsx')\n",
    "    print('Loading pre-results from {} ...'.format(resFileName))\n",
    "\n",
    "    parPreResults.fromExcel(resFileName, sheetName='AutoDSVal')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} pre-analyses loaded'.format(len(parPreResults)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at results\n",
    "parPreResults.dfTransData('fr')[['NumEchant', 'Espèce', 'Périodes', 'Préc.', 'Durée', 'Fn Clé',\n",
    "                                 'Sér Ajust', 'CodEx', 'NObs', 'AIC', 'Chi2 P', 'KS P', \n",
    "                                 'Densité', 'CoefVar Densité', 'Min Densité', 'Max Densité']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare parallel results to sequential ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare sequential results for comparison\n",
    "dfSeqCmpRes = preResults.dfTransData('en')\n",
    "\n",
    "dfSeqCmpRes.fillna(-9999, inplace=True) # Get rid of the Nan pb (because NaN != NaN :-)\n",
    "\n",
    "# Start date-time and elapsed time and folder can never be the same\n",
    "dfSeqCmpRes.drop(columns=['StartTime', 'ElapsedTime', 'RunFolder'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare parallel results for comparison\n",
    "dfParCmpRes = parPreResults.dfTransData('en')\n",
    "\n",
    "dfParCmpRes.sort_values(by='SampleNum', inplace=True) # Back to original test case order = sequential run order\n",
    "\n",
    "dfParCmpRes.reset_index(inplace=True, drop=True) # Enforce same index as a consequence\n",
    "\n",
    "dfParCmpRes.fillna(-9999, inplace=True) # And get rid of the Nan pb (because NaN != Nan :-)\n",
    "\n",
    "# Start date-time and elapsed time and folder can never be the same\n",
    "dfParCmpRes.drop(columns=['StartTime', 'ElapsedTime', 'RunFolder'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (dfSeqCmpRes == dfParCmpRes).all().all(), 'Oh, oh, something went differently when run parallely ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build HTML and Excel pre-analyses reports\n",
    "\n",
    "See [4. HTML and Excel pre-analyses reports](#4.-HTML-and-Excel-pre-analyses-reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Truncation optimisation (short code and fast run)\n",
    "\n",
    "Thanks to MCDSZeroOrderTruncationOptimiser class.\n",
    "\n",
    "Note: Don't use this low level method, MCDSTruncationOptanalyser class is now here for that (easier from far, and shorter code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    ads.logger('ads.opr', level=ads.DEBUG, reset=True)\n",
    "    ads.logger('ads.dat', level=ads.DEBUG, reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimAbbrev(sAnlys):\n",
    "    \n",
    "    # Sample abbreviation\n",
    "    spcAbbrev = ''.join(word[:4].title() for word in sAnlys['Espèce'].split(' ')[:2])\n",
    "    sampAbbrev = [str(x) for x in [spcAbbrev, sAnlys.Passage.replace('+', ''),\n",
    "                                   sAnlys.Adulte.replace('+', ''), sAnlys['Durée']]]\n",
    "\n",
    "    # Model + Parameters abbreviation\n",
    "    modParAbbrev = [sAnlys['FonctionClé'][:3].lower(), sAnlys['SérieAjust'][:3].lower()]\n",
    "    \n",
    "    return '-'.join(sampAbbrev + modParAbbrev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Optimiser parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source / Results data\n",
    "transectPlaceCols = ['Point']\n",
    "passIdCol = 'Passage'\n",
    "effortCol = 'Effort'\n",
    "\n",
    "sampleDistCol = 'Distance'\n",
    "sampleDecCols = [effortCol, sampleDistCol]\n",
    "\n",
    "sampleNumCol = 'NumEchant'\n",
    "sampleSelCols = ['Espèce', passIdCol, 'Adulte', 'Durée']\n",
    "\n",
    "sampleAbbrevCol = 'AbrevEchant'\n",
    "\n",
    "optIndCol = 'IndOptim'\n",
    "optAbbrevCol = 'AbrevOptim'\n",
    "\n",
    "dSurveyArea = dict(Zone='ACDC', Surface='2400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les paramètres généraux d'analyse DS\n",
    "distanceUnit = 'Meter'\n",
    "areaUnit = 'Hectare'\n",
    "surveyType = 'Point'\n",
    "distanceType = 'Radial'\n",
    "clustering = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default optimisation params.\n",
    "defEstimKeyFn = 'HNORMAL'\n",
    "defEstimAdjustFn = 'COSINE'\n",
    "defEstimCriterion = 'AIC'\n",
    "defCVInterval = 95\n",
    "defMinDist = None\n",
    "defMaxDist = None, \n",
    "defFitDistCuts = None\n",
    "defDiscrDistCuts = None\n",
    "\n",
    "defExpr2Optimise = 'chi2'\n",
    "defMinimiseExpr = False\n",
    "defOutliersMethod = 'tucquant'\n",
    "defOutliersQuantCutPct = 7\n",
    "defFitDistCutsFctr = ads.Interval(min=0.6, max=1.4)\n",
    "defDiscrDistCutsFctr = ads.Interval(min=0.5, max=1.2)\n",
    "\n",
    "defSubmitTimes = 1\n",
    "defSubmitOnlyBest = None\n",
    "\n",
    "defCoreEngine = 'zoopt'\n",
    "defCoreMaxIters = 100\n",
    "defCoreTermExprValue = None\n",
    "defCoreAlgorithm = 'racos'\n",
    "defCoreMaxRetries = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Individuals data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:34:11,344 ads.dat INFO0\tLoaded 1543 total rows in data set ...\n",
      "2021-09-02 08:34:11,345 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observateur</th>\n",
       "      <th>Point</th>\n",
       "      <th>Passage</th>\n",
       "      <th>DateHeure</th>\n",
       "      <th>Espèce</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Adulte</th>\n",
       "      <th>Durée</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>146</td>\n",
       "      <td>a</td>\n",
       "      <td>2019-05-02 08:00:00</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>43.418829</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>146</td>\n",
       "      <td>a</td>\n",
       "      <td>2019-05-02 08:00:00</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>43.418829</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>146</td>\n",
       "      <td>a</td>\n",
       "      <td>2019-05-02 08:00:00</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>43.418829</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>146</td>\n",
       "      <td>a</td>\n",
       "      <td>2019-05-02 08:00:00</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>43.418829</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>146</td>\n",
       "      <td>a</td>\n",
       "      <td>2019-05-02 08:01:00</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>76.630008</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>H</td>\n",
       "      <td>216</td>\n",
       "      <td>b</td>\n",
       "      <td>2019-05-25 10:17:00</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>278.261431</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>H</td>\n",
       "      <td>216</td>\n",
       "      <td>b</td>\n",
       "      <td>2019-05-25 10:17:00</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>278.261431</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>H</td>\n",
       "      <td>216</td>\n",
       "      <td>b</td>\n",
       "      <td>2019-05-25 10:23:00</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>110.957560</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>H</td>\n",
       "      <td>216</td>\n",
       "      <td>b</td>\n",
       "      <td>2019-05-25 10:15:00</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>66.591277</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>H</td>\n",
       "      <td>216</td>\n",
       "      <td>b</td>\n",
       "      <td>2019-05-25 10:15:00</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>66.591277</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1543 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Observateur  Point Passage           DateHeure                 Espèce  \\\n",
       "0              A    146       a 2019-05-02 08:00:00          Turdus merula   \n",
       "1              A    146       a 2019-05-02 08:00:00          Turdus merula   \n",
       "2              A    146       a 2019-05-02 08:00:00          Turdus merula   \n",
       "3              A    146       a 2019-05-02 08:00:00          Turdus merula   \n",
       "4              A    146       a 2019-05-02 08:01:00  Luscinia megarhynchos   \n",
       "...          ...    ...     ...                 ...                    ...   \n",
       "1538           H    216       b 2019-05-25 10:17:00          Turdus merula   \n",
       "1539           H    216       b 2019-05-25 10:17:00          Turdus merula   \n",
       "1540           H    216       b 2019-05-25 10:23:00          Turdus merula   \n",
       "1541           H    216       b 2019-05-25 10:15:00     Sylvia atricapilla   \n",
       "1542           H    216       b 2019-05-25 10:15:00     Sylvia atricapilla   \n",
       "\n",
       "        Distance Adulte Durée  \n",
       "0      43.418829      m  10mn  \n",
       "1      43.418829      m  10mn  \n",
       "2      43.418829      m   5mn  \n",
       "3      43.418829      m   5mn  \n",
       "4      76.630008      m  10mn  \n",
       "...          ...    ...   ...  \n",
       "1538  278.261431      m  10mn  \n",
       "1539  278.261431      m   5mn  \n",
       "1540  110.957560      m  10mn  \n",
       "1541   66.591277      m  10mn  \n",
       "1542   66.591277      m   5mn  \n",
       "\n",
       "[1543 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfObsIndiv = ads.DataSet('refin/ACDC2019-Naturalist-ExtraitObsIndiv.ods', sheet='DonnéesIndiv').dfData\n",
    "dfObsIndiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Observateur': array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], dtype=object),\n",
       " 'Point': array([146, 162, 129, 113, 130, 147, 301, 300, 299, 280, 262, 281, 263,\n",
       "        282, 196, 198, 194, 197, 202, 218, 201, 199, 219, 200,  90,  91,\n",
       "         88, 105, 106, 122,  89, 141, 161, 123, 125, 142, 212, 145, 213,\n",
       "        229, 144, 143, 110, 112, 126, 128, 127, 109, 166, 185, 183, 184,\n",
       "        182, 165, 164, 148, 163, 159, 158, 157, 174, 192, 175, 176, 193,\n",
       "         56,  57,  58,  59,  41,  60,  40,  39,  23,  42, 210, 228, 246,\n",
       "        245, 284, 265, 247, 266, 177, 160, 178, 180, 179, 181, 215, 216,\n",
       "        250, 233, 232, 195, 211], dtype=int64),\n",
       " 'Passage': array(['a', 'b'], dtype=object),\n",
       " 'Adulte': array(['m'], dtype=object),\n",
       " 'Durée': array(['10mn', '5mn'], dtype=object),\n",
       " 'Espèce': array(['Turdus merula', 'Luscinia megarhynchos', 'Sylvia atricapilla'],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ col: dfObsIndiv[col].unique() for col in ['Observateur', 'Point', 'Passage', 'Adulte', 'Durée', 'Espèce'] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Actual transects\n",
    "\n",
    "(can't deduce them from data, some points are missing because of data selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:34:12,699 ads.dat INFO0\tLoaded 190 total rows in data set ...\n",
      "2021-09-02 08:34:12,700 ads.dat INFO0\t... found columns: [Point|Observateur|Date|Passage|Effort]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point</th>\n",
       "      <th>Observateur</th>\n",
       "      <th>Date</th>\n",
       "      <th>Passage</th>\n",
       "      <th>Effort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>G</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>G</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>G</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>G</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>G</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>299</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>300</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>300</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>301</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>301</td>\n",
       "      <td>B</td>\n",
       "      <td>2019-06-08</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Point Observateur       Date Passage  Effort\n",
       "0       23           G 2019-04-13       a       1\n",
       "1       23           G 2019-06-01       b       1\n",
       "2       39           G 2019-04-13       a       1\n",
       "3       39           G 2019-06-01       b       1\n",
       "4       40           G 2019-04-13       a       1\n",
       "..     ...         ...        ...     ...     ...\n",
       "185    299           B 2019-06-08       b       1\n",
       "186    300           B 2019-05-01       a       1\n",
       "187    300           B 2019-06-08       b       1\n",
       "188    301           B 2019-05-01       a       1\n",
       "189    301           B 2019-06-08       b       1\n",
       "\n",
       "[190 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTransects = ads.DataSet('refin/ACDC2019-Naturalist-ExtraitObsIndiv.ods', sheet='Inventaires').dfData\n",
    "dfTransects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Samples and analyses to optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir = pl.Path('tmp') / 'mcds-optr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. For testing all optimisation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "varOpt = '-all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfRawOptimExplSpecs = ads.Analyser.explicitVariantSpecs('refin/ACDC2019-Naturalist-ExtraitSpecsAnalyses.xlsx', \n",
    "                                                        ignore=['Params3_expl'])\n",
    "\n",
    "# No use of these cols, as we'll compute them !\n",
    "dfRawOptimExplSpecs = dfRawOptimExplSpecs.drop(columns=['TrGche', 'TrDrte', 'NbTrchMod']) \\\n",
    "                                         .drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "nOptimExplSpecs = len(dfRawOptimExplSpecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Espèce</th>\n",
       "      <th>Passage</th>\n",
       "      <th>Adulte</th>\n",
       "      <th>Durée</th>\n",
       "      <th>FonctionClé</th>\n",
       "      <th>SérieAjust</th>\n",
       "      <th>CritChx</th>\n",
       "      <th>IntervConf</th>\n",
       "      <th>TrGche</th>\n",
       "      <th>TrDrte</th>\n",
       "      <th>MethOutliers</th>\n",
       "      <th>NbTrchMod</th>\n",
       "      <th>NbTrDiscr</th>\n",
       "      <th>ExprOpt</th>\n",
       "      <th>MoteurOpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Espèce Passage Adulte Durée FonctionClé SérieAjust CritChx  \\\n",
       "0      Sylvia atricapilla     a+b      m   5mn     HNORMAL     COSINE     AIC   \n",
       "1      Sylvia atricapilla     a+b      m   5mn      HAZARD     COSINE     AIC   \n",
       "2      Sylvia atricapilla     a+b      m  10mn     HNORMAL     COSINE     AIC   \n",
       "3      Sylvia atricapilla     a+b      m  10mn      HAZARD     COSINE     AIC   \n",
       "4           Turdus merula     a+b      m   5mn     HNORMAL     COSINE     AIC   \n",
       "5           Turdus merula     a+b      m   5mn      HAZARD     COSINE     AIC   \n",
       "6           Turdus merula     a+b      m  10mn     HNORMAL     COSINE     AIC   \n",
       "7           Turdus merula     a+b      m  10mn      HAZARD     COSINE     AIC   \n",
       "8   Luscinia megarhynchos       b      m   5mn     HNORMAL     COSINE     AIC   \n",
       "9   Luscinia megarhynchos       b      m   5mn      HAZARD     COSINE     AIC   \n",
       "10  Luscinia megarhynchos       b      m  10mn     HNORMAL     COSINE     AIC   \n",
       "11  Luscinia megarhynchos       b      m  10mn      HAZARD     COSINE     AIC   \n",
       "\n",
       "    IntervConf TrGche TrDrte   MethOutliers       NbTrchMod NbTrDiscr  \\\n",
       "0           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "1           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "2           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "3           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "4           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "5           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "6           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "7           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "8           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "9           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "10          95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "11          95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "\n",
       "      ExprOpt   MoteurOpt  \n",
       "0   max(chi2)  zoopt(160)  \n",
       "1   max(chi2)  zoopt(160)  \n",
       "2   max(chi2)  zoopt(160)  \n",
       "3   max(chi2)  zoopt(160)  \n",
       "4   max(chi2)  zoopt(160)  \n",
       "5   max(chi2)  zoopt(160)  \n",
       "6   max(chi2)  zoopt(160)  \n",
       "7   max(chi2)  zoopt(160)  \n",
       "8   max(chi2)  zoopt(160)  \n",
       "9   max(chi2)  zoopt(160)  \n",
       "10  max(chi2)  zoopt(160)  \n",
       "11  max(chi2)  zoopt(160)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add optim. params\n",
    "dfMoreOptimCols = pd.DataFrame([dict(CritChx='AIC', IntervConf=95,\n",
    "                                     TrGche='auto', TrDrte='auto', MethOutliers='tucquant(2.5)',\n",
    "                                     NbTrchMod='mult(2/3, 3/2)', NbTrDiscr=None,\n",
    "                                     #TroncGche='auto', TroncDrte='auto', MethOutliers='tucquant(2.5)',\n",
    "                                     #NbTrModel='mult(2/3, 3/2)', NbTrDiscr=None,\n",
    "                                     ExprOpt='max(chi2)', MoteurOpt='zoopt(160)')]*len(dfRawOptimExplSpecs))\n",
    "\n",
    "dfRawOptimExplSpecs = pd.concat([dfRawOptimExplSpecs, dfMoreOptimCols], axis='columns')\n",
    "dfRawOptimExplSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nOptimedAnlyses = nOptimExplSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes de dfRawOptimExplSpecs donnant les paramètres d'analyse / optimisation\n",
    "optimParamSpecCols  = ['FonctionClé', 'SérieAjust', 'CritChx', 'IntervConf',\n",
    "                       'TrGche', 'TrDrte', 'MethOutliers', 'NbTrchMod', 'NbTrDiscr',\n",
    "                       #'TroncGche', 'TroncDrte', 'MethOutliers', 'NbTrModel', 'NbTrDiscr',\n",
    "                       'ExprOpt', 'MoteurOpt']\n",
    "\n",
    "# Et en version interne\n",
    "intOptimParamSpecCols = ['EstimKeyFn', 'EstimAdjustFn', 'EstimCriterion', 'CvInterval',\n",
    "                          'MinDist', 'MaxDist', 'OutliersMethod', 'FitDistCuts', 'DiscrDistCuts',\n",
    "                          'Expr2Optimise', 'OptimisationCore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Or: Only main optimisation parameters\n",
    "\n",
    "* for comparison with X below,\n",
    "* for comparing results goodness with various optimisation parameters, in XI below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varOpt = '-main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfRawOptimExplSpecs = ads.Analyser.explicitVariantSpecs('refin/ACDC2019-Naturalist-ExtraitSpecsOptanalyses.xlsx', \n",
    "                                                        ignore=['Params1_expl', 'Params2_expl'])\n",
    "\n",
    "dfRawOptimExplSpecs.drop(dfRawOptimExplSpecs[dfRawOptimExplSpecs[['TrGche', 'TrDrte', 'NbTrchMod', 'MultiOpt']]\n",
    "                                    .isnull().all(axis='columns')].index,\n",
    "                         inplace=True)\n",
    "\n",
    "dfRawOptimExplSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nOptimExplSpecs = len(dfRawOptimExplSpecs) - dfRawOptimExplSpecs.duplicated().sum()  # Duplicates will be removed\n",
    "\n",
    "nOptimedAnlyses = 22  # See MultiOpt col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes de dfRawOptimExplSpecs donnant les paramètres d'analyse / optimisation\n",
    "optimParamSpecCols  = ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod', 'MultiOpt']\n",
    "\n",
    "# Et en version interne\n",
    "intOptimParamSpecCols = ['EstimKeyFn', 'EstimAdjustFn', 'MinDist', 'MaxDist', 'FitDistCuts', 'SubmitParams']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4A. Or : Really run optimisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. MCDS Zeroth Order Truncation Optimiser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:35:05,919 ads.dat INFO0\tLoaded 1543 total rows in data set ...\n",
      "2021-09-02 08:35:05,921 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée]\n",
      "2021-09-02 08:35:05,922 ads.dat INFO0\tIndividuals data : 1543 sightings, 190 transects\n"
     ]
    }
   ],
   "source": [
    "zoptr = ads.MCDSZerothOrderTruncationOptimiser \\\n",
    "                (dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea, \n",
    "                 transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                 sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleDistCol=sampleDistCol,\n",
    "                 abbrevCol=optAbbrevCol, abbrevBuilder=optimAbbrev,\n",
    "                 anlysIndCol=optIndCol, sampleIndCol=sampleNumCol,\n",
    "                 distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                 surveyType=surveyType, distanceType=distanceType, clustering=clustering,\n",
    "                 resultsHeadCols=dict(before=[optIndCol], sample=sampleSelCols, after=optimParamSpecCols),\n",
    "                 workDir=workDir, runMethod='os.system', runTimeOut=None, logProgressEvery=1, backupEvery=5,\n",
    "                 defEstimKeyFn=defEstimKeyFn, defEstimAdjustFn=defEstimAdjustFn,\n",
    "                 defEstimCriterion=defEstimCriterion, defCVInterval=defCVInterval,\n",
    "                 defExpr2Optimise=defExpr2Optimise, defMinimiseExpr=defMinimiseExpr,\n",
    "                 defOutliersMethod=defOutliersMethod, defOutliersQuantCutPct=defOutliersQuantCutPct,\n",
    "                 defFitDistCutsFctr=defFitDistCutsFctr, defDiscrDistCutsFctr=defDiscrDistCutsFctr,\n",
    "                 defSubmitTimes=defSubmitTimes, defSubmitOnlyBest=defSubmitOnlyBest,\n",
    "                 defCoreMaxIters=defCoreMaxIters, defCoreTermExprValue=defCoreTermExprValue,\n",
    "                 defCoreAlgorithm=defCoreAlgorithm, defCoreMaxRetries=defCoreMaxRetries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Run optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:35:07,598 ads.anr INFO0\tDropped 0 last duplicate specs of 12, on [Espèce, Passage, Adulte, Durée, FonctionClé, SérieAjust, CritChx, IntervConf, TrGche, TrDrte, MethOutliers, NbTrchMod, NbTrDiscr, ExprOpt, MoteurOpt] columns\n",
      "{'checkVerdict': True, 'checkErrors': [], 'nActualOptimExplSpecs': 12, 'nExpectedOptimExplSpecs': 12, 'optimParamSpecCols': ['FonctionClé', 'SérieAjust', 'CritChx', 'IntervConf', 'TrGche', 'TrDrte', 'MethOutliers', 'NbTrchMod', 'NbTrDiscr', 'ExprOpt', 'MoteurOpt'], 'intOptimParamSpecCols': ['EstimKeyFn', 'EstimAdjustFn', 'EstimCriterion', 'CvInterval', 'MinDist', 'MaxDist', 'OutliersMethod', 'FitDistCuts', 'DiscrDistCuts', 'Expr2Optimise', 'OptimisationCore'], 'unmUserParamSpecCols': []}\n"
     ]
    }
   ],
   "source": [
    "dfOptimExplSpecs, userParamSpecCols, intParamSpecCols, unmUserParamSpecCols, checkVerdict, checkErrors = \\\n",
    "    zoptr.explicitParamSpecs(dfExplParamSpecs=dfRawOptimExplSpecs, dropDupes=True, check=True)\n",
    "\n",
    "print(dict(checkVerdict=checkVerdict, checkErrors=checkErrors, \n",
    "           nActualOptimExplSpecs=len(dfOptimExplSpecs), nExpectedOptimExplSpecs=nOptimExplSpecs,\n",
    "           optimParamSpecCols=optimParamSpecCols, intOptimParamSpecCols=intOptimParamSpecCols,\n",
    "           unmUserParamSpecCols=unmUserParamSpecCols))\n",
    "\n",
    "assert len(dfOptimExplSpecs) == nOptimExplSpecs\n",
    "assert userParamSpecCols == optimParamSpecCols\n",
    "assert intParamSpecCols == intOptimParamSpecCols\n",
    "assert unmUserParamSpecCols == []\n",
    "assert checkVerdict\n",
    "assert not checkErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Espèce</th>\n",
       "      <th>Passage</th>\n",
       "      <th>Adulte</th>\n",
       "      <th>Durée</th>\n",
       "      <th>FonctionClé</th>\n",
       "      <th>SérieAjust</th>\n",
       "      <th>CritChx</th>\n",
       "      <th>IntervConf</th>\n",
       "      <th>TrGche</th>\n",
       "      <th>TrDrte</th>\n",
       "      <th>MethOutliers</th>\n",
       "      <th>NbTrchMod</th>\n",
       "      <th>NbTrDiscr</th>\n",
       "      <th>ExprOpt</th>\n",
       "      <th>MoteurOpt</th>\n",
       "      <th>AbrevOptim</th>\n",
       "      <th>IndOptim</th>\n",
       "      <th>NumEchant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>SylvAtri-ab-m-5mn-hno-cos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>SylvAtri-ab-m-5mn-haz-cos</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>SylvAtri-ab-m-10mn-hno-cos</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>SylvAtri-ab-m-10mn-haz-cos</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>TurdMeru-ab-m-5mn-hno-cos</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>TurdMeru-ab-m-5mn-haz-cos</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>TurdMeru-ab-m-10mn-hno-cos</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>TurdMeru-ab-m-10mn-haz-cos</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>LuscMega-b-m-5mn-hno-cos</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>LuscMega-b-m-5mn-haz-cos</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>LuscMega-b-m-10mn-hno-cos</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>tucquant(2.5)</td>\n",
       "      <td>mult(2/3, 3/2)</td>\n",
       "      <td>None</td>\n",
       "      <td>max(chi2)</td>\n",
       "      <td>zoopt(160)</td>\n",
       "      <td>LuscMega-b-m-10mn-haz-cos</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Espèce Passage Adulte Durée FonctionClé SérieAjust CritChx  \\\n",
       "0      Sylvia atricapilla     a+b      m   5mn     HNORMAL     COSINE     AIC   \n",
       "1      Sylvia atricapilla     a+b      m   5mn      HAZARD     COSINE     AIC   \n",
       "2      Sylvia atricapilla     a+b      m  10mn     HNORMAL     COSINE     AIC   \n",
       "3      Sylvia atricapilla     a+b      m  10mn      HAZARD     COSINE     AIC   \n",
       "4           Turdus merula     a+b      m   5mn     HNORMAL     COSINE     AIC   \n",
       "5           Turdus merula     a+b      m   5mn      HAZARD     COSINE     AIC   \n",
       "6           Turdus merula     a+b      m  10mn     HNORMAL     COSINE     AIC   \n",
       "7           Turdus merula     a+b      m  10mn      HAZARD     COSINE     AIC   \n",
       "8   Luscinia megarhynchos       b      m   5mn     HNORMAL     COSINE     AIC   \n",
       "9   Luscinia megarhynchos       b      m   5mn      HAZARD     COSINE     AIC   \n",
       "10  Luscinia megarhynchos       b      m  10mn     HNORMAL     COSINE     AIC   \n",
       "11  Luscinia megarhynchos       b      m  10mn      HAZARD     COSINE     AIC   \n",
       "\n",
       "    IntervConf TrGche TrDrte   MethOutliers       NbTrchMod NbTrDiscr  \\\n",
       "0           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "1           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "2           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "3           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "4           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "5           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "6           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "7           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "8           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "9           95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "10          95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "11          95   auto   auto  tucquant(2.5)  mult(2/3, 3/2)      None   \n",
       "\n",
       "      ExprOpt   MoteurOpt                  AbrevOptim  IndOptim  NumEchant  \n",
       "0   max(chi2)  zoopt(160)   SylvAtri-ab-m-5mn-hno-cos         0          0  \n",
       "1   max(chi2)  zoopt(160)   SylvAtri-ab-m-5mn-haz-cos         1          0  \n",
       "2   max(chi2)  zoopt(160)  SylvAtri-ab-m-10mn-hno-cos         2          1  \n",
       "3   max(chi2)  zoopt(160)  SylvAtri-ab-m-10mn-haz-cos         3          1  \n",
       "4   max(chi2)  zoopt(160)   TurdMeru-ab-m-5mn-hno-cos         4          2  \n",
       "5   max(chi2)  zoopt(160)   TurdMeru-ab-m-5mn-haz-cos         5          2  \n",
       "6   max(chi2)  zoopt(160)  TurdMeru-ab-m-10mn-hno-cos         6          3  \n",
       "7   max(chi2)  zoopt(160)  TurdMeru-ab-m-10mn-haz-cos         7          3  \n",
       "8   max(chi2)  zoopt(160)    LuscMega-b-m-5mn-hno-cos         8          4  \n",
       "9   max(chi2)  zoopt(160)    LuscMega-b-m-5mn-haz-cos         9          4  \n",
       "10  max(chi2)  zoopt(160)   LuscMega-b-m-10mn-hno-cos        10          5  \n",
       "11  max(chi2)  zoopt(160)   LuscMega-b-m-10mn-haz-cos        11          5  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOptimExplSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:35:10,105 ads.eng INFO0\tDSEngine work folder: C:\\git\\perso\\autods\\tmp\\mcds-optr\n",
      "2021-09-02 08:35:10,109 ads.anr INFO0\tDropped 0 last duplicate specs of 12, on [Espèce, Passage, Adulte, Durée, FonctionClé, SérieAjust, CritChx, IntervConf, TrGche, TrDrte, MethOutliers, NbTrchMod, NbTrDiscr, ExprOpt, MoteurOpt] columns\n",
      "2021-09-02 08:35:10,112 ads.opr INFO0\tRunning MCDS truncation optimisations for 12 analyses specs (12 parallel threads) ...\n",
      "2021-09-02 08:35:10,114 ads.opr INFO0\t#1/12: SylvAtri-ab-m-5mn-hno-cos (Id 0)\n",
      "2021-09-02 08:35:10,133 ads.dat INFO0\tLoaded 276 total rows in data set ...\n",
      "2021-09-02 08:35:10,134 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:35:10,136 ads.dat INFO0\tSample data : 276 sightings = 261 individuals + 15 absence rows\n",
      "2021-09-02 08:35:10,140 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[10.843323181859, 22.12912149316365], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[260.5202889635435, 488.187599344441], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[11, 24], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,144 ads.opr INFO0\t#2/12: SylvAtri-ab-m-5mn-haz-cos (Id 1)\n",
      "2021-09-02 08:35:10,149 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[10.843323181859, 22.12912149316365], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[260.5202889635435, 488.187599344441], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[11, 24], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,159 ads.opr INFO0\t#3/12: SylvAtri-ab-m-10mn-hno-cos (Id 2)\n",
      "2021-09-02 08:35:10,191 ads.dat INFO0\tLoaded 393 total rows in data set ...\n",
      "2021-09-02 08:35:10,192 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:35:10,197 ads.dat INFO0\tSample data : 393 sightings = 388 individuals + 5 absence rows\n",
      "2021-09-02 08:35:10,201 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[1.21209447400735, 20.460494898449987], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[280.2722444867953, 511.40974530097], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[13, 30], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,204 ads.opr INFO0\t#4/12: SylvAtri-ab-m-10mn-haz-cos (Id 3)\n",
      "2021-09-02 08:35:10,210 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[1.21209447400735, 20.460494898449987], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[280.2722444867953, 511.40974530097], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[13, 30], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,221 ads.opr INFO0\t#5/12: TurdMeru-ab-m-5mn-hno-cos (Id 4)\n",
      "2021-09-02 08:35:10,266 ads.dat INFO0\tLoaded 244 total rows in data set ...\n",
      "2021-09-02 08:35:10,268 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:35:10,272 ads.dat INFO0\tSample data : 244 sightings = 231 individuals + 13 absence rows\n",
      "2021-09-02 08:35:10,279 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[2.92857962277939, 17.317766053799225], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[383.4344793146267, 714.125795314758], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[10, 23], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,285 ads.opr INFO0\t#6/12: TurdMeru-ab-m-5mn-haz-cos (Id 5)\n",
      "2021-09-02 08:35:10,300 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[2.92857962277939, 17.317766053799225], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[383.4344793146267, 714.125795314758], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[10, 23], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,308 ads.opr INFO0\t#7/12: TurdMeru-ab-m-10mn-hno-cos (Id 6)\n",
      "2021-09-02 08:35:10,354 ads.dat INFO0\tLoaded 403 total rows in data set ...\n",
      "2021-09-02 08:35:10,357 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:35:10,363 ads.dat INFO0\tSample data : 403 sightings = 400 individuals + 3 absence rows\n",
      "2021-09-02 08:35:10,371 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[2.92857962277939, 20.345190063058773], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[414.8642417761789, 785.995389460555], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[13, 30], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,375 ads.opr INFO0\t#8/12: TurdMeru-ab-m-10mn-haz-cos (Id 7)\n",
      "2021-09-02 08:35:10,399 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[2.92857962277939, 20.345190063058773], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[414.8642417761789, 785.995389460555], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[13, 30], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,415 ads.opr INFO0\t#9/12: LuscMega-b-m-5mn-hno-cos (Id 8)\n",
      "2021-09-02 08:35:10,466 ads.dat INFO0\tLoaded 109 total rows in data set ...\n",
      "2021-09-02 08:35:10,467 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:35:10,471 ads.dat INFO0\tSample data : 109 sightings = 57 individuals + 52 absence rows\n",
      "2021-09-02 08:35:10,478 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[32.7402715554949, 40.420672642533944], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[525.4956860322544, 1005.38511434534], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[5, 11], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,503 ads.opr INFO0\t#10/12: LuscMega-b-m-5mn-haz-cos (Id 9)\n",
      "2021-09-02 08:35:10,516 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[32.7402715554949, 40.420672642533944], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[525.4956860322544, 1005.38511434534], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[5, 11], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,537 ads.opr INFO0\t#11/12: LuscMega-b-m-10mn-hno-cos (Id 10)\n",
      "2021-09-02 08:35:10,617 ads.dat INFO0\tLoaded 122 total rows in data set ...\n",
      "2021-09-02 08:35:10,619 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:35:10,626 ads.dat INFO0\tSample data : 122 sightings = 84 individuals + 38 absence rows\n",
      "2021-09-02 08:35:10,632 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[32.7402715554949, 45.209489646176074], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[555.7901308543621, 1005.38511434534], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[6, 14], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,675 ads.opr INFO0\t#12/12: LuscMega-b-m-10mn-haz-cos (Id 11)\n",
      "2021-09-02 08:35:10,738 ads.opn INFO0\tZOTrOptimisation({'minDist': Parameter(name='MinDist', interval=[32.7402715554949, 45.209489646176074], continuous=True, ordered=True), 'maxDist': Parameter(name='MaxDist', interval=[555.7901308543621, 1005.38511434534], continuous=True, ordered=True), 'fitDistCuts': Parameter(name='FitDistCuts', interval=[6, 14], continuous=False, ordered=True)})\n",
      "2021-09-02 08:35:10,782 ads.opr INFO0\tAll optimisations started; now waiting for their end, and results ...\n",
      "[zoopt] expected remaining running time: 00:02:29\n",
      "[zoopt] expected remaining running time: 00:02:53\n",
      "[zoopt] expected remaining running time: 00:02:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[zoopt] expected remaining running time: 00:02:38\n",
      "[zoopt] expected remaining running time: 00:03:08\n",
      "[zoopt] expected remaining running time: 00:03:18\n",
      "[zoopt] expected remaining running time: 00:02:47\n",
      "[zoopt] expected remaining running time: 00:03:10\n",
      "[zoopt] expected remaining running time: 00:03:24\n",
      "[zoopt] expected remaining running time: 00:03:32\n",
      "[zoopt] expected remaining running time: 00:03:44\n",
      "[zoopt] expected remaining running time: 00:07:31\n",
      "[zoopt] x: [40.42035415622268, 984.3765547187332, 5]\n",
      "[zoopt] value: -0.8066809\n",
      "[zoopt] x: [17.291720088212642, 479.38829225525956, 19]\n",
      "[zoopt] value: -0.3229441\n",
      "[zoopt] x: [7.160333494003399, 455.4583465747577, 15]\n",
      "[zoopt] value: -0.7893247\n",
      "[zoopt] x: [41.24782286823763, 632.1681011761734, 11]\n",
      "[zoopt] value: -0.861603\n",
      "[zoopt] x: [21.44846976885328, 311.3066557655076, 14]\n",
      "[zoopt] value: -0.4094353\n",
      "2021-09-02 08:38:15,393 ads.dat INFO0\t5x34 results rows x columns and 2 specs saved to tmp\\mcds-optr\\optr-resbak-1.pickle.xz in 0.028s\n",
      "[zoopt] x: [11.291140947386898, 290.68710339470266, 24]\n",
      "[zoopt] value: -0.1340325\n",
      "[zoopt] x: [5.495316464450522, 417.51398747841927, 14]\n",
      "[zoopt] value: -0.5209918\n",
      "[zoopt] x: [21.70035911218673, 379.71127835736496, 12]\n",
      "[zoopt] value: -0.3132493\n",
      "[zoopt] x: [14.60009502905971, 665.0937740649324, 23]\n",
      "[zoopt] value: -0.6796248\n",
      "[zoopt] x: [19.729552859588402, 337.7338482454092, 17]\n",
      "[zoopt] value: -0.1939089\n",
      "2021-09-02 08:38:33,181 ads.dat INFO0\t10x34 results rows x columns and 2 specs saved to tmp\\mcds-optr\\optr-resbak-0.pickle.xz in 0.021s\n",
      "[zoopt] x: [36.6298253018779, 617.7298939829031, 10]\n",
      "[zoopt] value: -0.75144\n",
      "[zoopt] x: [37.87633661914276, 688.3900354671996, 12]\n",
      "[zoopt] value: -0.6573235\n",
      "2021-09-02 08:40:54,945 ads.opr INFO0\tOptimisations completed (1920 analyses => 12 results).\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Analyses\n",
    "results = zoptr.run(dfOptimExplSpecs, threads=12)\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target:**\n",
    "* Computer: Lenovo T490 Core i5 8365U 4 HT Cores, Ruindows 10\n",
    "* runMethod: os.system\n",
    "\n",
    "**Variant 3a: \"all\"**\n",
    "\n",
    "* 22 analyses specs (12 parallel threads)\n",
    "* Paramètres dans refin/ACDC2019-Naturalist-ExtraitSpecsOptanalyses.xlsx nettoyé de Param1_expl et Param2_expl.\n",
    "* MoteurOpt='zoopt(120)' => 2020-08-21 22:41:56,626 2880 analyses => 22 results, Wall time: 4min 21s\n",
    "* MoteurOpt='zoopt(160)' => 2021-08-22 1920 analyses => 12 results, Wall time: 2min 44s\n",
    "\n",
    "**Variant 3b: \"main\"**\n",
    "\n",
    "* 12 analyses specs (6 parallel threads)\n",
    "* CritChx='AIC', IntervConf=95, TroncGche='auto', TroncDrte='auto', MethOutliers='tucquant(2.5)', NbTrModel='mult(2/3, 3/2)', NbTrDiscr=None, ExprOpt='max(chi2)'\n",
    "* MoteurOpt='zoopt(160)' => 2020-06-29 21:18:04,727 Wall time: 4min 31s\n",
    "* MoteurOpt='zoopt(250, tv=0.6)' => 2020-06-28 19:23:38,868 Wall time: 9min 19s\n",
    "\n",
    "**Variant 3b: \"main\"**\n",
    "\n",
    "* 12 analyses specs (12 parallel threads)\n",
    "* CritChx='AIC', IntervConf=95, TroncGche='auto', TroncDrte='auto', MethOutliers='tucquant(2.5)', NbTrModel='mult(2/3, 3/2)', NbTrDiscr=None, ExprOpt='max(chi2)'\n",
    "* MoteurOpt='zoopt(160)' => 2020-07-18 15:22:47,289 Wall time: 3min 51s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target:**\n",
    "* Computer: Lenovo T490 Core i5 8365U 4 HT Cores, Ruindows 10\n",
    "* runMethod: subprocess.run\n",
    "\n",
    "**Variant 3a: \"all\"**\n",
    "\n",
    "* 12 analyses specs (12 parallel threads)\n",
    "* Paramètres dans refin/ACDC2019-Naturalist-ExtraitSpecsOptanalyses.xlsx nettoyé de Param1_expl et Param2_expl.\n",
    "* default: CritChx='AIC', IntervConf=95, MethOutliers='tucquant(7)', NbTrModel='mult(0.6, 1.4)', NbTrDiscr='mult(0.5, 1.2)', ExprOpt='max(chi2)'\n",
    "* MoteurOpt='zoopt(100)' => 2021-01-14 10:52:28,040 1920 analyses => 12 results, Wall time: 3min 45s\n",
    "* MoteurOpt='zoopt(100)' => 2021-08-22 10:52:28,040 1920 analyses => 12 results, Wall time: 3min 45s\n",
    "\n",
    "**Variant 3b: \"main\"**\n",
    "\n",
    "* 16 analyses specs (12 parallel threads)\n",
    "* default: CritChx='AIC', IntervConf=95, MethOutliers='tucquant(7)', NbTrModel='mult(0.6, 1.4)', NbTrDiscr='mult(0.5, 1.2)', ExprOpt='max(chi2)'\n",
    "* MoteurOpt='zoopt(100)' => 2021-01-14 10:30:19,463 2400 analyses => 22 results, Wall time: 4min 28s\n",
    "* MoteurOpt='zoopt(100)' => 2021-08-22 18:55:55,701 2400 analyses => 22 results, Wall time: 3min 31s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoptr.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IndOptim</th>\n",
       "      <th>Espèce</th>\n",
       "      <th>Passage</th>\n",
       "      <th>Adulte</th>\n",
       "      <th>Durée</th>\n",
       "      <th>FonctionClé</th>\n",
       "      <th>SérieAjust</th>\n",
       "      <th>CritChx</th>\n",
       "      <th>IntervConf</th>\n",
       "      <th>TrGche</th>\n",
       "      <th>...</th>\n",
       "      <th>Tranch Dist Mod</th>\n",
       "      <th>Tranch Dist Discr</th>\n",
       "      <th>SetupStatus</th>\n",
       "      <th>SubmitStatus</th>\n",
       "      <th>NFunEvals</th>\n",
       "      <th>MeanFunElapd</th>\n",
       "      <th>minDist</th>\n",
       "      <th>maxDist</th>\n",
       "      <th>fitDistCuts</th>\n",
       "      <th>chi2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[5, 11]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.015248</td>\n",
       "      <td>40.420354</td>\n",
       "      <td>984.376555</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.806681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[10, 23]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.146336</td>\n",
       "      <td>17.291720</td>\n",
       "      <td>479.388292</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.322944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[10, 23]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.151660</td>\n",
       "      <td>7.160333</td>\n",
       "      <td>455.458347</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.789325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[6, 14]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.151840</td>\n",
       "      <td>41.247823</td>\n",
       "      <td>632.168101</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.861603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[11, 24]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.156590</td>\n",
       "      <td>21.448470</td>\n",
       "      <td>311.306656</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.409435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[13, 30]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.161211</td>\n",
       "      <td>11.291141</td>\n",
       "      <td>290.687103</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.134032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[13, 30]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.191375</td>\n",
       "      <td>5.495316</td>\n",
       "      <td>417.513987</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.520992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[11, 24]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.214987</td>\n",
       "      <td>21.700359</td>\n",
       "      <td>379.711278</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.313249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[13, 30]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.242310</td>\n",
       "      <td>14.600095</td>\n",
       "      <td>665.093774</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.679625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[13, 30]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.266454</td>\n",
       "      <td>19.729553</td>\n",
       "      <td>337.733848</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.193909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[5, 11]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.301584</td>\n",
       "      <td>36.629825</td>\n",
       "      <td>617.729894</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.751440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>AIC</td>\n",
       "      <td>95</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>[6, 14]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.149858</td>\n",
       "      <td>37.876337</td>\n",
       "      <td>688.390035</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.657323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IndOptim                 Espèce Passage Adulte Durée FonctionClé  \\\n",
       "0          8  Luscinia megarhynchos       b      m   5mn     HNORMAL   \n",
       "1          5          Turdus merula     a+b      m   5mn      HAZARD   \n",
       "2          4          Turdus merula     a+b      m   5mn     HNORMAL   \n",
       "3         10  Luscinia megarhynchos       b      m  10mn     HNORMAL   \n",
       "4          0     Sylvia atricapilla     a+b      m   5mn     HNORMAL   \n",
       "5          2     Sylvia atricapilla     a+b      m  10mn     HNORMAL   \n",
       "6          7          Turdus merula     a+b      m  10mn      HAZARD   \n",
       "7          1     Sylvia atricapilla     a+b      m   5mn      HAZARD   \n",
       "8          6          Turdus merula     a+b      m  10mn     HNORMAL   \n",
       "9          3     Sylvia atricapilla     a+b      m  10mn      HAZARD   \n",
       "10         9  Luscinia megarhynchos       b      m   5mn      HAZARD   \n",
       "11        11  Luscinia megarhynchos       b      m  10mn      HAZARD   \n",
       "\n",
       "   SérieAjust CritChx  IntervConf TrGche  ... Tranch Dist Mod  \\\n",
       "0      COSINE     AIC          95   auto  ...         [5, 11]   \n",
       "1      COSINE     AIC          95   auto  ...        [10, 23]   \n",
       "2      COSINE     AIC          95   auto  ...        [10, 23]   \n",
       "3      COSINE     AIC          95   auto  ...         [6, 14]   \n",
       "4      COSINE     AIC          95   auto  ...        [11, 24]   \n",
       "5      COSINE     AIC          95   auto  ...        [13, 30]   \n",
       "6      COSINE     AIC          95   auto  ...        [13, 30]   \n",
       "7      COSINE     AIC          95   auto  ...        [11, 24]   \n",
       "8      COSINE     AIC          95   auto  ...        [13, 30]   \n",
       "9      COSINE     AIC          95   auto  ...        [13, 30]   \n",
       "10     COSINE     AIC          95   auto  ...         [5, 11]   \n",
       "11     COSINE     AIC          95   auto  ...         [6, 14]   \n",
       "\n",
       "   Tranch Dist Discr SetupStatus SubmitStatus NFunEvals MeanFunElapd  \\\n",
       "0               None         NaN          NaN     160.0     1.015248   \n",
       "1               None         NaN          NaN     160.0     1.146336   \n",
       "2               None         NaN          NaN     160.0     1.151660   \n",
       "3               None         NaN          NaN     160.0     1.151840   \n",
       "4               None         NaN          NaN     160.0     1.156590   \n",
       "5               None         NaN          NaN     160.0     1.161211   \n",
       "6               None         NaN          NaN     160.0     1.191375   \n",
       "7               None         NaN          NaN     160.0     1.214987   \n",
       "8               None         NaN          NaN     160.0     1.242310   \n",
       "9               None         NaN          NaN     160.0     1.266454   \n",
       "10              None         NaN          NaN     160.0     1.301584   \n",
       "11              None         NaN          NaN     160.0     2.149858   \n",
       "\n",
       "      minDist     maxDist fitDistCuts      chi2  \n",
       "0   40.420354  984.376555         5.0  0.806681  \n",
       "1   17.291720  479.388292        19.0  0.322944  \n",
       "2    7.160333  455.458347        15.0  0.789325  \n",
       "3   41.247823  632.168101        11.0  0.861603  \n",
       "4   21.448470  311.306656        14.0  0.409435  \n",
       "5   11.291141  290.687103        24.0  0.134032  \n",
       "6    5.495316  417.513987        14.0  0.520992  \n",
       "7   21.700359  379.711278        12.0  0.313249  \n",
       "8   14.600095  665.093774        23.0  0.679625  \n",
       "9   19.729553  337.733848        17.0  0.193909  \n",
       "10  36.629825  617.729894        10.0  0.751440  \n",
       "11  37.876337  688.390035        12.0  0.657323  \n",
       "\n",
       "[12 rows x 34 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Save results for later reload or examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:40:55,291 ads.dat INFO0\t12x34 results rows x columns and 2 specs saved to tmp\\mcds-optr\\valtests-mcds-optimiser-all-results.xlsx in 0.099s\n"
     ]
    }
   ],
   "source": [
    "results.toExcel(workDir / f'valtests-mcds-optimiser{varOpt}-results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.toExcel(workDir / 'valtests-mcds-optimiser-results-fr.xlsx', lang='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4B. Or : Restart optimisation from recovery file\n",
    "\n",
    "(already run above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. MCDS Zeroth Order Truncation Optimiser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Must be a real clone of the above one, otherwise recovery may not work !\n",
    "zoptr = ads.MCDSZerothOrderTruncationOptimiser \\\n",
    "                (dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea, \n",
    "                 transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                 sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleDistCol=sampleDistCol,\n",
    "                 abbrevCol=optAbbrevCol, abbrevBuilder=optimAbbrev,\n",
    "                 anlysIndCol=optIndCol, sampleIndCol=sampleNumCol,\n",
    "                 distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                 surveyType=surveyType, distanceType=distanceType, clustering=clustering,\n",
    "                 resultsHeadCols=dict(before=[optIndCol], sample=sampleSelCols, after=optimParamSpecCols),\n",
    "                 workDir=workDir, runMethod='os.system', runTimeOut=None, logProgressEvery=1,\n",
    "                 defEstimKeyFn=defEstimKeyFn, defEstimAdjustFn=defEstimAdjustFn,\n",
    "                 defEstimCriterion=defEstimCriterion, defCVInterval=defCVInterval,\n",
    "                 defExpr2Optimise=defExpr2Optimise, defMinimiseExpr=defMinimiseExpr,\n",
    "                 defOutliersMethod=defOutliersMethod, defOutliersQuantCutPct=defOutliersQuantCutPct,\n",
    "                 defFitDistCutsFctr=defFitDistCutsFctr, defDiscrDistCutsFctr=defDiscrDistCutsFctr,\n",
    "                 defSubmitTimes=defSubmitTimes, defSubmitOnlyBest=defSubmitOnlyBest,\n",
    "                 defCoreMaxIters=defCoreMaxIters, defCoreTermExprValue=defCoreTermExprValue,\n",
    "                 defCoreAlgorithm=defCoreAlgorithm, defCoreMaxRetries=defCoreMaxRetries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Run optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOptimExplSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optimisations with recovery\n",
    "results2 = zoptr.run(dfOptimExplSpecs, recover=True, threads=12)\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoptr.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Save results for later reload or examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2.toExcel(workDir / f'valtests-mcds-optimiser{varOpt}-results2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4C. Or : Load optimisation results from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    # An analyser object knowns how to build an empty results object ...\n",
    "    zoptr = ads.MCDSZerothOrderTruncationOptimiser \\\n",
    "                    (dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea, \n",
    "                     transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                     sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleDistCol=sampleDistCol,\n",
    "                     abbrevCol=optAbbrevCol, abbrevBuilder=optimAbbrev,\n",
    "                     anlysIndCol=optIndCol, sampleIndCol=sampleNumCol,\n",
    "                     distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                     surveyType=surveyType, distanceType=distanceType, clustering=clustering,\n",
    "                     resultsHeadCols=dict(before=[optIndCol], sample=sampleSelCols, after=optimParamSpecCols))\n",
    "    \n",
    "    # TODO: use new loadFrom param to load data !!!\n",
    "    results = zoptr.setupResults()\n",
    "    \n",
    "    # Load results from file.\n",
    "    resFileName = workDir / f'valtests-mcds-optimiser{varOpt}-results.xlsx'\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    results.fromExcel(resFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} optimisations to analyse'.format(len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deduce analyses specs from optimisation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short string for sample \"identification\"\n",
    "def sampleAbbrev(sSample):\n",
    "    \n",
    "    abrvSpe = ''.join(word[:4].title() for word in sSample['Espèce'].split(' ')[:2])\n",
    "    \n",
    "    sampAbbrev = '{}-{}-{}-{}'.format(abrvSpe, sSample.Passage.replace('+', ''),\n",
    "                                      sSample.Adulte.replace('+', ''), sSample['Durée'])\n",
    "    \n",
    "    return sampAbbrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short string for analysis \"identification\"\n",
    "def analysisAbbrev(sAnlys):\n",
    "    \n",
    "    # Sample abbreviation\n",
    "    abbrevs = [sampleAbbrev(sAnlys)]\n",
    "\n",
    "    # Model + Parameters abbreviation\n",
    "    abbrevs += [sAnlys['FonctionClé'][:3].lower(), sAnlys['SérieAjust'][:3].lower()]\n",
    "    dTroncAbrv = { 'l': 'TrGche' if 'TrGche' in sAnlys.index else 'TroncGche',\n",
    "                   'r': 'TrDrte' if 'TrDrte' in sAnlys.index else 'TroncDrte',\n",
    "                   'm': 'NbTrches' if 'NbTrches' in sAnlys.index else 'NbTrModel'\n",
    "                                   if 'NbTrModel' in sAnlys.index else  'NbTrchMod',\n",
    "                   'd': 'NbTrDiscr' }\n",
    "    for abrv, name in dTroncAbrv.items():\n",
    "        if name in sAnlys.index and not pd.isnull(sAnlys[name]):\n",
    "            abbrevs.append('{}{}'.format(abrv, sAnlys[name][0].lower() if isinstance(sAnlys[name], str)\n",
    "                                               else int(sAnlys[name])))\n",
    "   \n",
    "    return '-'.join(abbrevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "varIndCol = 'NumAnlys'\n",
    "anlysAbbrevCol = 'AbrevAnlys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample and analysis params, and above all optimised truncation param. values from optimiser results.\n",
    "optTgtCols = ['TrGche', 'TrDrte', 'NbTrchMod']\n",
    "#optTgtCols = ['TroncGche', 'TroncDrte', 'NbTrModel']\n",
    "dfAnlysSpecs = results.dfData[['Espèce', 'Passage', 'Adulte', 'Durée', 'FonctionClé', 'SérieAjust',\n",
    "                               'minDist', 'maxDist', 'fitDistCuts'] + optTgtCols].copy()\n",
    "\n",
    "# Add analysis abbreviation from truncation params optim. specs (not from optimised results).\n",
    "dfAnlysSpecs[anlysAbbrevCol] = dfAnlysSpecs.apply(analysisAbbrev, axis='columns')\n",
    "\n",
    "# No need for the truncation params optim. specs anymore\n",
    "dfAnlysSpecs.drop(columns=optTgtCols, inplace=True)\n",
    "\n",
    "# Rename optimised truncation param. columns for analysis\n",
    "dfAnlysSpecs.rename(columns=dict(minDist='TrGche', maxDist='TrDrte', fitDistCuts='NbTrchMod'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But non-optimised truncation parameters are not in optimiser result columns (minDist, maxDist, fitDisCuts, ...) ...\n",
    "# so we have to get them back from optimisation specs (TrGche, TrDrte, NbTrchMod, ...)\n",
    "\n",
    "# String specs are optimisation params, numerical ones are already determined truncation params.\n",
    "bdfToBeKeptSpecCells = results.dfData[optTgtCols].applymap(lambda v: isinstance(v, str))\n",
    "\n",
    "dfAnlysSpecs[optTgtCols] = dfAnlysSpecs[optTgtCols].where(bdfToBeKeptSpecCells,\n",
    "                                                          other=results.dfData[optTgtCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Espèce</th>\n",
       "      <th>Passage</th>\n",
       "      <th>Adulte</th>\n",
       "      <th>Durée</th>\n",
       "      <th>FonctionClé</th>\n",
       "      <th>SérieAjust</th>\n",
       "      <th>TrGche</th>\n",
       "      <th>TrDrte</th>\n",
       "      <th>NbTrchMod</th>\n",
       "      <th>AbrevAnlys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>40.420354</td>\n",
       "      <td>984.376555</td>\n",
       "      <td>5.0</td>\n",
       "      <td>LuscMega-b-m-5mn-hno-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>17.291720</td>\n",
       "      <td>479.388292</td>\n",
       "      <td>19.0</td>\n",
       "      <td>TurdMeru-ab-m-5mn-haz-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>7.160333</td>\n",
       "      <td>455.458347</td>\n",
       "      <td>15.0</td>\n",
       "      <td>TurdMeru-ab-m-5mn-hno-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>41.247823</td>\n",
       "      <td>632.168101</td>\n",
       "      <td>11.0</td>\n",
       "      <td>LuscMega-b-m-10mn-hno-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>21.448470</td>\n",
       "      <td>311.306656</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SylvAtri-ab-m-5mn-hno-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>11.291141</td>\n",
       "      <td>290.687103</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SylvAtri-ab-m-10mn-hno-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>5.495316</td>\n",
       "      <td>417.513987</td>\n",
       "      <td>14.0</td>\n",
       "      <td>TurdMeru-ab-m-10mn-haz-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>21.700359</td>\n",
       "      <td>379.711278</td>\n",
       "      <td>12.0</td>\n",
       "      <td>SylvAtri-ab-m-5mn-haz-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>14.600095</td>\n",
       "      <td>665.093774</td>\n",
       "      <td>23.0</td>\n",
       "      <td>TurdMeru-ab-m-10mn-hno-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>19.729553</td>\n",
       "      <td>337.733848</td>\n",
       "      <td>17.0</td>\n",
       "      <td>SylvAtri-ab-m-10mn-haz-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>36.629825</td>\n",
       "      <td>617.729894</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LuscMega-b-m-5mn-haz-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>37.876337</td>\n",
       "      <td>688.390035</td>\n",
       "      <td>12.0</td>\n",
       "      <td>LuscMega-b-m-10mn-haz-cos-la-ra-mm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Espèce Passage Adulte Durée FonctionClé SérieAjust  \\\n",
       "0   Luscinia megarhynchos       b      m   5mn     HNORMAL     COSINE   \n",
       "1           Turdus merula     a+b      m   5mn      HAZARD     COSINE   \n",
       "2           Turdus merula     a+b      m   5mn     HNORMAL     COSINE   \n",
       "3   Luscinia megarhynchos       b      m  10mn     HNORMAL     COSINE   \n",
       "4      Sylvia atricapilla     a+b      m   5mn     HNORMAL     COSINE   \n",
       "5      Sylvia atricapilla     a+b      m  10mn     HNORMAL     COSINE   \n",
       "6           Turdus merula     a+b      m  10mn      HAZARD     COSINE   \n",
       "7      Sylvia atricapilla     a+b      m   5mn      HAZARD     COSINE   \n",
       "8           Turdus merula     a+b      m  10mn     HNORMAL     COSINE   \n",
       "9      Sylvia atricapilla     a+b      m  10mn      HAZARD     COSINE   \n",
       "10  Luscinia megarhynchos       b      m   5mn      HAZARD     COSINE   \n",
       "11  Luscinia megarhynchos       b      m  10mn      HAZARD     COSINE   \n",
       "\n",
       "       TrGche      TrDrte  NbTrchMod                           AbrevAnlys  \n",
       "0   40.420354  984.376555        5.0    LuscMega-b-m-5mn-hno-cos-la-ra-mm  \n",
       "1   17.291720  479.388292       19.0   TurdMeru-ab-m-5mn-haz-cos-la-ra-mm  \n",
       "2    7.160333  455.458347       15.0   TurdMeru-ab-m-5mn-hno-cos-la-ra-mm  \n",
       "3   41.247823  632.168101       11.0   LuscMega-b-m-10mn-hno-cos-la-ra-mm  \n",
       "4   21.448470  311.306656       14.0   SylvAtri-ab-m-5mn-hno-cos-la-ra-mm  \n",
       "5   11.291141  290.687103       24.0  SylvAtri-ab-m-10mn-hno-cos-la-ra-mm  \n",
       "6    5.495316  417.513987       14.0  TurdMeru-ab-m-10mn-haz-cos-la-ra-mm  \n",
       "7   21.700359  379.711278       12.0   SylvAtri-ab-m-5mn-haz-cos-la-ra-mm  \n",
       "8   14.600095  665.093774       23.0  TurdMeru-ab-m-10mn-hno-cos-la-ra-mm  \n",
       "9   19.729553  337.733848       17.0  SylvAtri-ab-m-10mn-haz-cos-la-ra-mm  \n",
       "10  36.629825  617.729894       10.0    LuscMega-b-m-5mn-haz-cos-la-ra-mm  \n",
       "11  37.876337  688.390035       12.0   LuscMega-b-m-10mn-haz-cos-la-ra-mm  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAnlysSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir = pl.Path('tmp/mcds-anaftopt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6A. Or : Really run analyses\n",
    "\n",
    "(now truncation parameters have been auto-computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. MCDS Analyser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:48:37,309 ads.dat INFO0\tLoaded 1543 total rows in data set ...\n",
      "2021-09-02 08:48:37,309 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée]\n",
      "2021-09-02 08:48:37,311 ads.dat INFO0\tIndividuals data : 1543 sightings, 190 transects\n"
     ]
    }
   ],
   "source": [
    "anlysParamCols = ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod']\n",
    "\n",
    "anlysr = ads.MCDSAnalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea,\n",
    "                          transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                          sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols,\n",
    "                          abbrevCol=anlysAbbrevCol, anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                          distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                          surveyType=surveyType, distanceType=distanceType, clustering=clustering,\n",
    "                          resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                               after=anlysParamCols + [anlysAbbrevCol]),\n",
    "                          workDir=workDir, logProgressEvery=1,\n",
    "                          defEstimKeyFn=defEstimKeyFn, defEstimAdjustFn=defEstimAdjustFn,\n",
    "                          defEstimCriterion=defEstimCriterion, defCVInterval=defCVInterval,\n",
    "                          defMinDist=defMinDist, defMaxDist=defMaxDist,\n",
    "                          defFitDistCuts=defFitDistCuts, defDiscrDistCuts=defDiscrDistCuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Check analysis explicit specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:48:41,176 ads.anr INFO0\tDropped 0 last duplicate specs of 12, on [Espèce, Passage, Adulte, Durée, FonctionClé, SérieAjust, TrGche, TrDrte, NbTrchMod] columns\n"
     ]
    }
   ],
   "source": [
    "dfAnlysSpecs, userParamSpecCols, intParamSpecCols, unmUserParamSpecCols, verdict, reasons = \\\n",
    "    anlysr.explicitParamSpecs(dfExplParamSpecs=dfAnlysSpecs, dropDupes=True, check=True)\n",
    "\n",
    "assert len(dfAnlysSpecs) == nOptimedAnlyses, f'{len(dfAnlysSpecs)} != {nOptimedAnlyses}'\n",
    "assert userParamSpecCols == ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod'], str(userParamSpecCols)\n",
    "assert intParamSpecCols == ['EstimKeyFn', 'EstimAdjustFn', 'MinDist', 'MaxDist', 'FitDistCuts'], str(intParamSpecCols)\n",
    "assert unmUserParamSpecCols == []\n",
    "assert verdict\n",
    "assert not reasons, str(reasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Run analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:48:42,403 ads.eng INFO0\tDSEngine work folder: C:\\git\\perso\\autods\\tmp\\mcds-anaftopt\n",
      "2021-09-02 08:48:42,406 ads.anr INFO0\tDropped 0 last duplicate specs of 12, on [Espèce, Passage, Adulte, Durée, FonctionClé, SérieAjust, TrGche, TrDrte, NbTrchMod] columns\n",
      "2021-09-02 08:48:42,408 ads.anr INFO0\tRunning 12 MCDS analyses (12 parallel threads) ...\n",
      "2021-09-02 08:48:42,410 ads.anr INFO0\t#1/12 : LuscMega-b-m-5mn-hno-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,430 ads.dat INFO0\tLoaded 109 total rows in data set ...\n",
      "2021-09-02 08:48:42,431 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:42,433 ads.dat INFO0\tSample data : 109 sightings = 57 individuals + 52 absence rows\n",
      "2021-09-02 08:48:42,438 ads.anr INFO0\t#2/12 : TurdMeru-ab-m-5mn-haz-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,461 ads.dat INFO0\tLoaded 244 total rows in data set ...\n",
      "2021-09-02 08:48:42,462 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:42,465 ads.dat INFO0\tSample data : 244 sightings = 231 individuals + 13 absence rows\n",
      "2021-09-02 08:48:42,470 ads.anr INFO0\t#3/12 : TurdMeru-ab-m-5mn-hno-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,482 ads.anr INFO0\t#4/12 : LuscMega-b-m-10mn-hno-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,518 ads.dat INFO0\tLoaded 122 total rows in data set ...\n",
      "2021-09-02 08:48:42,520 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:42,523 ads.dat INFO0\tSample data : 122 sightings = 84 individuals + 38 absence rows\n",
      "2021-09-02 08:48:42,530 ads.anr INFO0\t#5/12 : SylvAtri-ab-m-5mn-hno-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,571 ads.dat INFO0\tLoaded 276 total rows in data set ...\n",
      "2021-09-02 08:48:42,572 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:42,577 ads.dat INFO0\tSample data : 276 sightings = 261 individuals + 15 absence rows\n",
      "2021-09-02 08:48:42,584 ads.anr INFO0\t#6/12 : SylvAtri-ab-m-10mn-hno-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,621 ads.dat INFO0\tLoaded 393 total rows in data set ...\n",
      "2021-09-02 08:48:42,623 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:42,628 ads.dat INFO0\tSample data : 393 sightings = 388 individuals + 5 absence rows\n",
      "2021-09-02 08:48:42,636 ads.anr INFO0\t#7/12 : TurdMeru-ab-m-10mn-haz-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,684 ads.dat INFO0\tLoaded 403 total rows in data set ...\n",
      "2021-09-02 08:48:42,685 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:42,691 ads.dat INFO0\tSample data : 403 sightings = 400 individuals + 3 absence rows\n",
      "2021-09-02 08:48:42,700 ads.anr INFO0\t#8/12 : SylvAtri-ab-m-5mn-haz-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,757 ads.dat INFO0\tLoaded 276 total rows in data set ...\n",
      "2021-09-02 08:48:42,759 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:42,763 ads.dat INFO0\tSample data : 276 sightings = 261 individuals + 15 absence rows\n",
      "2021-09-02 08:48:42,782 ads.anr INFO0\t#9/12 : TurdMeru-ab-m-10mn-hno-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,850 ads.dat INFO0\tLoaded 403 total rows in data set ...\n",
      "2021-09-02 08:48:42,861 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:42,877 ads.dat INFO0\tSample data : 403 sightings = 400 individuals + 3 absence rows\n",
      "2021-09-02 08:48:42,885 ads.anr INFO0\t#10/12 : SylvAtri-ab-m-10mn-haz-cos-la-ra-mm\n",
      "2021-09-02 08:48:42,978 ads.dat INFO0\tLoaded 393 total rows in data set ...\n",
      "2021-09-02 08:48:42,989 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:43,031 ads.dat INFO0\tSample data : 393 sightings = 388 individuals + 5 absence rows\n",
      "2021-09-02 08:48:43,060 ads.anr INFO0\t#11/12 : LuscMega-b-m-5mn-haz-cos-la-ra-mm\n",
      "2021-09-02 08:48:43,139 ads.dat INFO0\tLoaded 109 total rows in data set ...\n",
      "2021-09-02 08:48:43,150 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:43,165 ads.dat INFO0\tSample data : 109 sightings = 57 individuals + 52 absence rows\n",
      "2021-09-02 08:48:43,189 ads.anr INFO0\t#12/12 : LuscMega-b-m-10mn-haz-cos-la-ra-mm\n",
      "2021-09-02 08:48:43,247 ads.dat INFO0\tLoaded 122 total rows in data set ...\n",
      "2021-09-02 08:48:43,256 ads.dat INFO0\t... found columns: [Observateur|Point|Passage|DateHeure|Espèce|Distance|Adulte|Durée|Effort|Zone|Surface]\n",
      "2021-09-02 08:48:43,261 ads.dat INFO0\tSample data : 122 sightings = 84 individuals + 38 absence rows\n",
      "2021-09-02 08:48:43,268 ads.anr INFO0\tAll analyses started ; now waiting for their end, and results ...\n",
      "2021-09-02 08:48:46,377 ads.anr INFO0\tAnalyses completed (12 results).\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Analyses : min=5, max=11s elapsed for 64 analyses with 6 threads on a Lenovo P52 (6-HT-core i7-8850H with PCI-e SSD)\n",
    "# Analyses : min=2.1, max=2.5s elapsed for 22 analyses with 6-12 threads on a Lenovo T490 (4-HT-core i5-8365U with PCI-e SSD)\n",
    "# Analyses : 1.5s elapsed for 12 analyses with 6-12 threads on a Lenovo T490 (4-HT-core i5-8365U with PCI-e SSD)\n",
    "results = anlysr.run(dfAnlysSpecs, threads=12)\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "anlysr.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumAnlys</th>\n",
       "      <th>NumEchant</th>\n",
       "      <th>Espèce</th>\n",
       "      <th>Passage</th>\n",
       "      <th>Adulte</th>\n",
       "      <th>Durée</th>\n",
       "      <th>FonctionClé</th>\n",
       "      <th>SérieAjust</th>\n",
       "      <th>TrGche</th>\n",
       "      <th>TrDrte</th>\n",
       "      <th>...</th>\n",
       "      <th>Ordre Tronc Proch Qual Equi KS+</th>\n",
       "      <th>Ordre Tronc Proch Qual Equi DCv+</th>\n",
       "      <th>Ordre Global Chi2 KS DCv</th>\n",
       "      <th>Ordre Global Qual Equi 1</th>\n",
       "      <th>Ordre Global Qual Equi 2</th>\n",
       "      <th>Ordre Global Qual Equi 3</th>\n",
       "      <th>Ordre Global Qual Equi Chi2+</th>\n",
       "      <th>Ordre Global Qual Equi KS+</th>\n",
       "      <th>Ordre Global Qual Equi DCv+</th>\n",
       "      <th>Ordre Global DeltaAIC Chi2 KS DCv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>40.420354</td>\n",
       "      <td>984.376555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>17.291720</td>\n",
       "      <td>479.388292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>7.160333</td>\n",
       "      <td>455.458347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>41.247823</td>\n",
       "      <td>632.168101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>21.448470</td>\n",
       "      <td>311.306656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>11.291141</td>\n",
       "      <td>290.687103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>5.495316</td>\n",
       "      <td>417.513987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>21.700359</td>\n",
       "      <td>379.711278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>14.600095</td>\n",
       "      <td>665.093774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>19.729553</td>\n",
       "      <td>337.733848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>36.629825</td>\n",
       "      <td>617.729894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>37.876337</td>\n",
       "      <td>688.390035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NumAnlys  NumEchant                 Espèce Passage Adulte Durée  \\\n",
       "6          0          0  Luscinia megarhynchos       b      m   5mn   \n",
       "1          1          1          Turdus merula     a+b      m   5mn   \n",
       "2          2          1          Turdus merula     a+b      m   5mn   \n",
       "4          3          2  Luscinia megarhynchos       b      m  10mn   \n",
       "5          4          3     Sylvia atricapilla     a+b      m   5mn   \n",
       "3          5          4     Sylvia atricapilla     a+b      m  10mn   \n",
       "0          6          5          Turdus merula     a+b      m  10mn   \n",
       "7          7          3     Sylvia atricapilla     a+b      m   5mn   \n",
       "8          8          5          Turdus merula     a+b      m  10mn   \n",
       "9          9          4     Sylvia atricapilla     a+b      m  10mn   \n",
       "11        10          0  Luscinia megarhynchos       b      m   5mn   \n",
       "10        11          2  Luscinia megarhynchos       b      m  10mn   \n",
       "\n",
       "   FonctionClé SérieAjust     TrGche      TrDrte  ...  \\\n",
       "6      HNORMAL     COSINE  40.420354  984.376555  ...   \n",
       "1       HAZARD     COSINE  17.291720  479.388292  ...   \n",
       "2      HNORMAL     COSINE   7.160333  455.458347  ...   \n",
       "4      HNORMAL     COSINE  41.247823  632.168101  ...   \n",
       "5      HNORMAL     COSINE  21.448470  311.306656  ...   \n",
       "3      HNORMAL     COSINE  11.291141  290.687103  ...   \n",
       "0       HAZARD     COSINE   5.495316  417.513987  ...   \n",
       "7       HAZARD     COSINE  21.700359  379.711278  ...   \n",
       "8      HNORMAL     COSINE  14.600095  665.093774  ...   \n",
       "9       HAZARD     COSINE  19.729553  337.733848  ...   \n",
       "11      HAZARD     COSINE  36.629825  617.729894  ...   \n",
       "10      HAZARD     COSINE  37.876337  688.390035  ...   \n",
       "\n",
       "    Ordre Tronc Proch Qual Equi KS+ Ordre Tronc Proch Qual Equi DCv+  \\\n",
       "6                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "5                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "0                               0.0                              0.0   \n",
       "7                               0.0                              0.0   \n",
       "8                               0.0                              0.0   \n",
       "9                               0.0                              0.0   \n",
       "11                              0.0                              0.0   \n",
       "10                              0.0                              0.0   \n",
       "\n",
       "    Ordre Global Chi2 KS DCv  Ordre Global Qual Equi 1  \\\n",
       "6                        0.0                       0.0   \n",
       "1                        1.0                       1.0   \n",
       "2                        0.0                       0.0   \n",
       "4                        0.0                       0.0   \n",
       "5                        0.0                       1.0   \n",
       "3                        1.0                       1.0   \n",
       "0                        1.0                       1.0   \n",
       "7                        1.0                       0.0   \n",
       "8                        0.0                       0.0   \n",
       "9                        0.0                       0.0   \n",
       "11                       1.0                       1.0   \n",
       "10                       1.0                       1.0   \n",
       "\n",
       "    Ordre Global Qual Equi 2 Ordre Global Qual Equi 3  \\\n",
       "6                        0.0                      0.0   \n",
       "1                        1.0                      1.0   \n",
       "2                        0.0                      0.0   \n",
       "4                        0.0                      0.0   \n",
       "5                        1.0                      1.0   \n",
       "3                        1.0                      1.0   \n",
       "0                        1.0                      1.0   \n",
       "7                        0.0                      0.0   \n",
       "8                        0.0                      0.0   \n",
       "9                        0.0                      0.0   \n",
       "11                       1.0                      1.0   \n",
       "10                       1.0                      1.0   \n",
       "\n",
       "   Ordre Global Qual Equi Chi2+ Ordre Global Qual Equi KS+  \\\n",
       "6                           0.0                        1.0   \n",
       "1                           1.0                        1.0   \n",
       "2                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "5                           1.0                        1.0   \n",
       "3                           1.0                        1.0   \n",
       "0                           1.0                        1.0   \n",
       "7                           0.0                        0.0   \n",
       "8                           0.0                        0.0   \n",
       "9                           0.0                        0.0   \n",
       "11                          1.0                        0.0   \n",
       "10                          1.0                        1.0   \n",
       "\n",
       "    Ordre Global Qual Equi DCv+  Ordre Global DeltaAIC Chi2 KS DCv  \n",
       "6                           0.0                                1.0  \n",
       "1                           1.0                                1.0  \n",
       "2                           0.0                                0.0  \n",
       "4                           0.0                                1.0  \n",
       "5                           1.0                                0.0  \n",
       "3                           1.0                                0.0  \n",
       "0                           1.0                                0.0  \n",
       "7                           0.0                                1.0  \n",
       "8                           0.0                                1.0  \n",
       "9                           0.0                                1.0  \n",
       "11                          1.0                                0.0  \n",
       "10                          1.0                                0.0  \n",
       "\n",
       "[12 rows x 114 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">header (head)</th>\n",
       "      <th colspan=\"4\" halign=\"left\">header (sample)</th>\n",
       "      <th colspan=\"4\" halign=\"left\">header (tail)</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">auto filter sort</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>NumAnlys</th>\n",
       "      <th>NumEchant</th>\n",
       "      <th>Espèce</th>\n",
       "      <th>Passage</th>\n",
       "      <th>Adulte</th>\n",
       "      <th>Durée</th>\n",
       "      <th>FonctionClé</th>\n",
       "      <th>SérieAjust</th>\n",
       "      <th>TrGche</th>\n",
       "      <th>TrDrte</th>\n",
       "      <th>...</th>\n",
       "      <th>Bal. quality KS+ (close trunc)</th>\n",
       "      <th>Bal. quality DCv+ (close trunc)</th>\n",
       "      <th>Chi2 KS DCv (global)</th>\n",
       "      <th>Bal. quality 1 (global)</th>\n",
       "      <th>Bal. quality 2 (global)</th>\n",
       "      <th>Bal. quality 3 (global)</th>\n",
       "      <th>Bal. quality Chi2+ (global)</th>\n",
       "      <th>Bal. quality KS+ (global)</th>\n",
       "      <th>Bal. quality DCv+ (global)</th>\n",
       "      <th>DeltaAIC Chi2 KS DCv (global)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "      <th>...</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "      <th>Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>40.420354</td>\n",
       "      <td>984.376555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>17.291720</td>\n",
       "      <td>479.388292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>7.160333</td>\n",
       "      <td>455.458347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>41.247823</td>\n",
       "      <td>632.168101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>21.448470</td>\n",
       "      <td>311.306656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>11.291141</td>\n",
       "      <td>290.687103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>5.495316</td>\n",
       "      <td>417.513987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>21.700359</td>\n",
       "      <td>379.711278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Turdus merula</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HNORMAL</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>14.600095</td>\n",
       "      <td>665.093774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Sylvia atricapilla</td>\n",
       "      <td>a+b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>19.729553</td>\n",
       "      <td>337.733848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>5mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>36.629825</td>\n",
       "      <td>617.729894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Luscinia megarhynchos</td>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>10mn</td>\n",
       "      <td>HAZARD</td>\n",
       "      <td>COSINE</td>\n",
       "      <td>37.876337</td>\n",
       "      <td>688.390035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   header (head)                  header (sample)                       \\\n",
       "        NumAnlys NumEchant                 Espèce Passage Adulte Durée   \n",
       "           Value     Value                  Value   Value  Value Value   \n",
       "6              0         0  Luscinia megarhynchos       b      m   5mn   \n",
       "1              1         1          Turdus merula     a+b      m   5mn   \n",
       "2              2         1          Turdus merula     a+b      m   5mn   \n",
       "4              3         2  Luscinia megarhynchos       b      m  10mn   \n",
       "5              4         3     Sylvia atricapilla     a+b      m   5mn   \n",
       "3              5         4     Sylvia atricapilla     a+b      m  10mn   \n",
       "0              6         5          Turdus merula     a+b      m  10mn   \n",
       "7              7         3     Sylvia atricapilla     a+b      m   5mn   \n",
       "8              8         5          Turdus merula     a+b      m  10mn   \n",
       "9              9         4     Sylvia atricapilla     a+b      m  10mn   \n",
       "11            10         0  Luscinia megarhynchos       b      m   5mn   \n",
       "10            11         2  Luscinia megarhynchos       b      m  10mn   \n",
       "\n",
       "   header (tail)                                    ...  \\\n",
       "     FonctionClé SérieAjust     TrGche      TrDrte  ...   \n",
       "           Value      Value      Value       Value  ...   \n",
       "6        HNORMAL     COSINE  40.420354  984.376555  ...   \n",
       "1         HAZARD     COSINE  17.291720  479.388292  ...   \n",
       "2        HNORMAL     COSINE   7.160333  455.458347  ...   \n",
       "4        HNORMAL     COSINE  41.247823  632.168101  ...   \n",
       "5        HNORMAL     COSINE  21.448470  311.306656  ...   \n",
       "3        HNORMAL     COSINE  11.291141  290.687103  ...   \n",
       "0         HAZARD     COSINE   5.495316  417.513987  ...   \n",
       "7         HAZARD     COSINE  21.700359  379.711278  ...   \n",
       "8        HNORMAL     COSINE  14.600095  665.093774  ...   \n",
       "9         HAZARD     COSINE  19.729553  337.733848  ...   \n",
       "11        HAZARD     COSINE  36.629825  617.729894  ...   \n",
       "10        HAZARD     COSINE  37.876337  688.390035  ...   \n",
       "\n",
       "                 auto filter sort                                  \\\n",
       "   Bal. quality KS+ (close trunc) Bal. quality DCv+ (close trunc)   \n",
       "                            Order                           Order   \n",
       "6                             0.0                             0.0   \n",
       "1                             0.0                             0.0   \n",
       "2                             0.0                             0.0   \n",
       "4                             0.0                             0.0   \n",
       "5                             0.0                             0.0   \n",
       "3                             0.0                             0.0   \n",
       "0                             0.0                             0.0   \n",
       "7                             0.0                             0.0   \n",
       "8                             0.0                             0.0   \n",
       "9                             0.0                             0.0   \n",
       "11                            0.0                             0.0   \n",
       "10                            0.0                             0.0   \n",
       "\n",
       "                                                                         \\\n",
       "   Chi2 KS DCv (global) Bal. quality 1 (global) Bal. quality 2 (global)   \n",
       "                  Order                   Order                   Order   \n",
       "6                   0.0                     0.0                     0.0   \n",
       "1                   1.0                     1.0                     1.0   \n",
       "2                   0.0                     0.0                     0.0   \n",
       "4                   0.0                     0.0                     0.0   \n",
       "5                   0.0                     1.0                     1.0   \n",
       "3                   1.0                     1.0                     1.0   \n",
       "0                   1.0                     1.0                     1.0   \n",
       "7                   1.0                     0.0                     0.0   \n",
       "8                   0.0                     0.0                     0.0   \n",
       "9                   0.0                     0.0                     0.0   \n",
       "11                  1.0                     1.0                     1.0   \n",
       "10                  1.0                     1.0                     1.0   \n",
       "\n",
       "                                                        \\\n",
       "   Bal. quality 3 (global) Bal. quality Chi2+ (global)   \n",
       "                     Order                       Order   \n",
       "6                      0.0                         0.0   \n",
       "1                      1.0                         1.0   \n",
       "2                      0.0                         0.0   \n",
       "4                      0.0                         0.0   \n",
       "5                      1.0                         1.0   \n",
       "3                      1.0                         1.0   \n",
       "0                      1.0                         1.0   \n",
       "7                      0.0                         0.0   \n",
       "8                      0.0                         0.0   \n",
       "9                      0.0                         0.0   \n",
       "11                     1.0                         1.0   \n",
       "10                     1.0                         1.0   \n",
       "\n",
       "                                                         \\\n",
       "   Bal. quality KS+ (global) Bal. quality DCv+ (global)   \n",
       "                       Order                      Order   \n",
       "6                        1.0                        0.0   \n",
       "1                        1.0                        1.0   \n",
       "2                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "5                        1.0                        1.0   \n",
       "3                        1.0                        1.0   \n",
       "0                        1.0                        1.0   \n",
       "7                        0.0                        0.0   \n",
       "8                        0.0                        0.0   \n",
       "9                        0.0                        0.0   \n",
       "11                       0.0                        1.0   \n",
       "10                       1.0                        1.0   \n",
       "\n",
       "                                  \n",
       "   DeltaAIC Chi2 KS DCv (global)  \n",
       "                           Order  \n",
       "6                            1.0  \n",
       "1                            1.0  \n",
       "2                            0.0  \n",
       "4                            1.0  \n",
       "5                            0.0  \n",
       "3                            0.0  \n",
       "0                            0.0  \n",
       "7                            1.0  \n",
       "8                            1.0  \n",
       "9                            1.0  \n",
       "11                           0.0  \n",
       "10                           0.0  \n",
       "\n",
       "[12 rows x 114 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dfData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Save results for later reload or examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-02 08:48:48,171 ads.dat INFO0\t12x114 results rows x columns and 3 specs saved to tmp\\mcds-anaftopt\\valtests-mcds-analyser-afteropt-all-results.xlsx in 0.173s\n"
     ]
    }
   ],
   "source": [
    "results.toExcel(workDir / f'valtests-mcds-analyser-afteropt{varOpt}-results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.toExcel(workDir / 'valtests-mcds-analyser-afteropt-fr.xlsx', lang='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6B. Or : Load analyses results from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    # An analyser object knowns how to build an empty results object ...\n",
    "    anlysr = ads.MCDSAnalyser(dfObsIndiv, dfTransects=dfTransects, dSurveyArea=dSurveyArea,\n",
    "                              resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                                   after=[anlysAbbrevCol]),\n",
    "                              transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                              sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols,\n",
    "                              abbrevCol=anlysAbbrevCol, anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                              distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                              surveyType=surveyType, distanceType=distanceType, clustering=clustering)\n",
    "    \n",
    "    results = anlysr.setupResults()\n",
    "    \n",
    "    # Load results from file.\n",
    "    resFileName = workDir / f'valtests-mcds-analyser-afteropt{varOpt}-results.xlsx'\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    results.fromExcel(resFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} analyses to compare'.format(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII. Truncation optimisation : Study on parameter variants\n",
    "\n",
    "Objective: How to choose key parameters ?\n",
    "* how many outliers ?\n",
    "* how many max iters ?\n",
    "* correlation with number of sightings ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as plyx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data set, samples, transects, analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: First run [VII. Truncation optimisation (short code / fast run)](#VII.-Truncation-optimisation-(short-code-and-fast-run)) 0, 1 and 2 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfOptimExplSpecs = ads.Analyser.explicitVariantSpecs('refin/ACDC2019-Naturalist-ExtraitSpecsOptanalyses.xlsx', \n",
    "                                                     ignore=['Params1_expl', 'Params2_expl'])\n",
    "\n",
    "dfOptimExplSpecs.drop(dfOptimExplSpecs[dfOptimExplSpecs[['TrGche', 'TrDrte', 'NbTrchMod', 'MultiOpt']]\n",
    "                                           .isnull().all(axis='columns')].index,\n",
    "                      inplace=True)\n",
    "\n",
    "dfOptimExplSpecs.drop(columns=['TrGche', 'TrDrte', 'NbTrchMod', 'MultiOpt'], inplace=True)\n",
    "\n",
    "nOptimExplSpecs = len(dfOptimExplSpecs)\n",
    "\n",
    "dfOptimExplSpecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameter variants plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTimes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr2MaxPlan = ['chi2', 'ks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliersPctPlan = [2.5, 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxItersPlan = [50, 100, 150, 200, 250, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A. Or: Run optimisations according to the plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nParSets = len(expr2MaxPlan) * len(outliersPctPlan) * len(maxItersPlan)\n",
    "nOpt2Run = len(dfOptimExplSpecs) * nTimes * nParSets\n",
    "print(f'About to run {nOpt2Run} optimisations !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes de dfOptimExplSpecs donnant les paramètres d'analyse / optimisation\n",
    "optimParamsSpecsCols  = ['FonctionClé', 'SérieAjust', 'CritChx', 'IntervConf',\n",
    "                         'TroncGche', 'TroncDrte', 'MethOutliers', 'NbTrModel', 'NbTrDiscr',\n",
    "                         'ExprOpt', 'ParExec', 'MoteurOpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ldfResults = list()\n",
    "\n",
    "nParSetInd = 1\n",
    "for expr2Max in expr2MaxPlan:\n",
    "    \n",
    "    for olrsPct in outliersPctPlan:\n",
    "\n",
    "        for maxIters in maxItersPlan:\n",
    "\n",
    "            logger.info(f'Params set {nParSetInd}/{nParSets}: {expr2Max=}, {nTimes=}, {maxIters=}, {olrsPct=:.1f}')\n",
    "            \n",
    "            # Prepare optim. params.\n",
    "            dfMoreOptimCols = \\\n",
    "                pd.DataFrame([dict(CritChx='AIC', IntervConf=95,\n",
    "                                   TroncGche='auto', TroncDrte='auto',\n",
    "                                   MethOutliers=f'tucquant({olrsPct:.1f})',\n",
    "                                   NbTrModel='mult(2/3, 3/2)', NbTrDiscr=None,\n",
    "                                   ExprOpt=f'max({expr2Max})', ParExec=f'times({nTimes})',\n",
    "                                   MoteurOpt=f'zoopt({maxIters})')]*len(dfOptimExplSpecs))\n",
    "\n",
    "            dfOptVarExplSpecs = pd.concat([dfOptimExplSpecs.reset_index(drop=True), dfMoreOptimCols], axis='columns')\n",
    "\n",
    "            # Run optimisation.\n",
    "            zoptr = ads.MCDSZerothOrderTruncationOptimiser \\\n",
    "                            (dfObsIndiv, effortConstVal=1, dSurveyArea=dSurveyArea, \n",
    "                             transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                             sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleDistCol=sampleDistCol,\n",
    "                             abbrevCol=optAbbrevCol, abbrevBuilder=optimAbbrev,\n",
    "                             anlysIndCol=optIndCol, sampleIndCol=sampleNumCol,\n",
    "                             distanceUnit='Meter', areaUnit='Hectare',\n",
    "                             surveyType='Point', distanceType='Radial', clustering=False,\n",
    "                             resultsHeadCols=dict(before=[optIndCol], sample=sampleSelCols, after=optimParamsSpecsCols),\n",
    "                             workDir='/tmp', logData=False,                 \n",
    "                             defCoreMaxIters=120)\n",
    "\n",
    "            results = zoptr.run(dfOptVarExplSpecs, threads=12)\n",
    "\n",
    "            zoptr.shutdown()\n",
    "\n",
    "            # Save results for this run\n",
    "            ldfResults.append(results.dfData)\n",
    "            \n",
    "            nParSet += 1\n",
    "        \n",
    "# Done : concat and save results.\n",
    "dfResults = pd.concat(ldfResults, ignore_index=True)\n",
    "\n",
    "resFileName = 'tmp/valtests-mcds-opter-res4stats.xlsx'\n",
    "dfResults.to_excel(resFileName, index=False)\n",
    "logger.info(f'Results saved to {resFileName}')\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B. Or : Load results from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'computed' not in dir():\n",
    "    computed = False\n",
    "if not computed:\n",
    "    \n",
    "    # Load results from file.\n",
    "    #resFileName = 'tmp/valtests-mcds-opter-res4stats-20200705.xlsx'\n",
    "    resFileName = 'tmp/valtests-mcds-opter-res4stats-20201103.xlsx'\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    dfResults = pd.read_excel(resFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} results to process'.format(len(dfResults)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. First stats on optimisation results\n",
    "\n",
    "* raw stats : mean and std\n",
    "* first correlations : number of analyses / optimised criterium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfResults), dfResults.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optResCols = ['minDist', 'maxDist', 'fitDistCuts', 'chi2', 'ks', 'chi2*ks']\n",
    "#groupCols = [col for col in dfResults.columns if col not in optResCols]\n",
    "groupCols = ['Espèce', 'Passage', 'Adulte', 'Durée', 'FonctionClé', 'SérieAjust', 'MethOutliers', 'ExprOpt',\n",
    "             'MinDist', 'MaxDist', 'FitDistCuts', 'NFunEvals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Raw stats : mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStats = dfResults.groupby(groupCols).agg(['mean', 'std'])\n",
    "dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resFileName = 'tmp/valtests-mcds-opter-stats.xlsx'\n",
    "dfStats.reset_index().to_excel(resFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Visual correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResults['NFunEvalsR'] = dfResults.NFunEvals.apply(lambda v: int(50*np.ceil(v/50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for esp in dfResults['Espèce'].unique():\n",
    "    axes = dfResults[dfResults['Espèce'] == esp].plot.hexbin(y='NFunEvalsR', x='chi2', gridsize=(20, 6), figsize=(14, 3))\n",
    "    axes.set_title(f'{esp} : chi2 / NFunEvals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for esp in dfResults['Espèce'].unique():\n",
    "    axes = dfResults[dfResults['Espèce'] == esp].plot.hexbin(y='NFunEvalsR', x='ks', gridsize=(20, 6), figsize=(14, 3))\n",
    "    axes.set_title(f'{esp} : ks / NFunEvals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResults['Outliers'] = dfResults.MethOutliers.apply(lambda s: float(s[len('tucquant('):-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dfResults.plot.scatter(y='Outliers', x='chi2', figsize=(14, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = dfResults.plot.scatter(y='Outliers', x='ks', figsize=(14, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plyx.violin(dfResults, x='chi2', y='NFunEvalsR', facet_row='Outliers', color=\"Espèce\", orientation='h', height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plyx.violin(dfResults, x='ks', y='NFunEvalsR', facet_row='Outliers', color=\"Espèce\", orientation='h', height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Computed correlations\n",
    "\n",
    "(linéaires, de Pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonCorr(df, x, y):\n",
    "    \n",
    "    cv = np.cov(df[x].values, df[y].values)\n",
    "    \n",
    "    return pd.Series(dict(corr=cv[0, 1] / cv[0, 0] / cv[1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb of analyses run / optimisation criterium\n",
    "groupCols = ['Espèce', 'Passage', 'Adulte', 'Durée', 'FonctionClé', 'SérieAjust', 'MethOutliers', 'ExprOpt']\n",
    "\n",
    "df = dfResults.loc[dfResults.ExprOpt == 'max(chi2)',\n",
    "                   groupCols + ['NFunEvals', 'chi2']].groupby(groupCols).apply(pearsonCorr, x='NFunEvals', y='chi2')\n",
    "df.rename(columns=dict(corr='NFun/Expr'), inplace=True)\n",
    "dfCorr = df.copy()\n",
    "\n",
    "df = dfResults.loc[dfResults.ExprOpt == 'max(ks)',\n",
    "                   groupCols + ['NFunEvals', 'ks']].groupby(groupCols).apply(pearsonCorr, x='NFunEvals', y='ks')\n",
    "df.rename(columns=dict(corr='NFun/Expr'), inplace=True)\n",
    "dfCorr = dfCorr.append(df)\n",
    "\n",
    "dfCorr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCorr[dfCorr.index.get_level_values('ExprOpt') == 'max(ks)'].sort_values(by='NFun/Expr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCorr[dfCorr.index.get_level_values('ExprOpt') == 'max(chi2)'].sort_values(by='NFun/Expr', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of outliers excluded / optimisation criterium\n",
    "groupCols = ['Espèce', 'Passage', 'Adulte', 'Durée']\n",
    "\n",
    "df = dfResults.loc[dfResults.ExprOpt == 'max(chi2)',\n",
    "                   groupCols + ['Outliers', 'chi2']].groupby(groupCols).apply(pearsonCorr, x='Outliers', y='chi2')\n",
    "df.rename(columns=dict(corr='Outliers/Expr'), inplace=True)\n",
    "dfCorr = df.copy()\n",
    "\n",
    "df = dfResults.loc[dfResults.ExprOpt == 'max(ks)',\n",
    "                   groupCols + ['Outliers', 'ks']].groupby(groupCols).apply(pearsonCorr, x='Outliers', y='ks')\n",
    "df.rename(columns=dict(corr='Outliers/Expr'), inplace=True)\n",
    "dfCorr = dfCorr.append(df)\n",
    "\n",
    "dfCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run analyses with optimised truncations\n",
    "\n",
    "(to get the actual numbers of sightings retained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Deduce analyses specs from optimisation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResults.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varIndCol = 'NumAnlys'\n",
    "anlysAbbrevCol = 'AbrevAnlys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample and analysis params, and above all optimised truncation param. values from optimiser results.\n",
    "#optTgtCols = ['TrGche', 'TrDrte', 'NbTrchMod']\n",
    "optTgtCols = ['TroncGche', 'TroncDrte', 'NbTrModel']\n",
    "otherOptTgtCols = ['Outliers', 'NFunEvals']\n",
    "dfAnlysSpecs = dfResults[['Espèce', 'Passage', 'Adulte', 'Durée', 'FonctionClé', 'SérieAjust',\n",
    "                          'minDist', 'maxDist', 'fitDistCuts'] + optTgtCols + otherOptTgtCols].copy()\n",
    "\n",
    "# Add analysis abbreviation from truncation params optim. specs (not from optimised results).\n",
    "dfAnlysSpecs[anlysAbbrevCol] = dfAnlysSpecs.apply(analysisAbbrev, axis='columns')\n",
    "\n",
    "# No need for the truncation params optim. specs anymore\n",
    "dfAnlysSpecs.drop(columns=optTgtCols, inplace=True)\n",
    "\n",
    "# Rename optimised truncation param. columns for analysis\n",
    "dfAnlysSpecs.rename(columns=dict(minDist='TrGche', maxDist='TrDrte', fitDistCuts='NbTrchMod'), inplace=True)\n",
    "\n",
    "dfAnlysSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir = pl.Path('tmp/mcds-optstats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Or : Really run analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i. MCDS Analyser object\n",
    "anlysParamCols = ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod']\n",
    "\n",
    "anlysr = ads.MCDSAnalyser(dfObsIndiv, effortConstVal=1, dSurveyArea=dSurveyArea,\n",
    "                          transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                          sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols,\n",
    "                          abbrevCol=anlysAbbrevCol, anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                          distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                          surveyType=surveyType, distanceType=distanceType, clustering=clustering,\n",
    "                          resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                               after=anlysParamCols + [anlysAbbrevCol, 'Outliers', 'NFunEvals']),\n",
    "                          workDir=workDir,\n",
    "                          defEstimKeyFn=defEstimKeyFn, defEstimAdjustFn=defEstimAdjustFn,\n",
    "                          defEstimCriterion=defEstimCriterion, defCVInterval=defCVInterval,\n",
    "                          defMinDist=defMinDist, defMaxDist=defMaxDist,\n",
    "                          defFitDistCuts=defFitDistCuts, defDiscrDistCuts=defDiscrDistCuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii. Check analysis explicit specs\n",
    "dfAnlysSpecs, userParamSpecCols, intParamSpecCols, unmUserParamSpecCols, verdict, reasons = \\\n",
    "    anlysr.explicitParamSpecs(dfExplParamSpecs=dfAnlysSpecs, dropDupes=True, check=True)\n",
    "\n",
    "assert len(dfAnlysSpecs) == len(dfResults)\n",
    "assert userParamSpecCols == ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod'], str(userParamSpecCols)\n",
    "assert intParamSpecCols == ['EstimKeyFn', 'EstimAdjustFn', 'MinDist', 'MaxDist', 'FitDistCuts'], str(intParamSpecCols)\n",
    "assert unmUserParamSpecCols == []\n",
    "assert verdict\n",
    "assert not reasons, str(reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# iii. Run analyses\n",
    "\n",
    "# Analyses : 20mn for 8640 analyses with 12 threads on a Lenovo T490 (4-HT-core i5-8365U with PCI-e SSD)\n",
    "results = anlysr.run(dfAnlysSpecs, threads=12)\n",
    "\n",
    "computed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anlysr.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iiii. Save results for later reload or examination\n",
    "results.toExcel(workDir / 'valtests-mcds-analyser-afteropt-results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.toExcel(workDir / 'valtests-mcds-analyser-afteropt-fr.xlsx', lang='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Or : Load analyses from a previous run\n",
    "\n",
    "(already run and saved above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not computed:\n",
    "    \n",
    "    # An analyser object knowns how to build an empty results object ...\n",
    "    anlysr = ads.MCDSAnalyser(dfObsIndiv, effortConstVal=1, dSurveyArea=dSurveyArea,\n",
    "                              resultsHeadCols=dict(before=[varIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                                   after=[anlysAbbrevCol]),\n",
    "                              transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                              sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols,\n",
    "                              abbrevCol=anlysAbbrevCol, anlysIndCol=varIndCol, sampleIndCol=sampleNumCol,\n",
    "                              distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                              surveyType=surveyType, distanceType=distanceType, clustering=clustering)\n",
    "    \n",
    "    results = anlysr.setupResults()\n",
    "    \n",
    "    # Load results from file.\n",
    "    resFileName = workDir / 'valtests-mcds-analyser-afteropt-results.xlsx'\n",
    "    print('Loading results from {} ...'.format(resFileName))\n",
    "\n",
    "    results.fromExcel(resFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Just computed, not reloading ...')\n",
    "    \n",
    "print('... {} analyses to study'.format(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnRes = results.dfTransData('fr')\n",
    "dfAnRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Other stats on analysis results\n",
    "\n",
    "Through NObs mainly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfAnRes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for esp in dfAnRes['Espèce'].unique():\n",
    "    axes = dfAnRes[dfAnRes['Espèce'] == esp].plot.hexbin(y='NObs', x='Chi2 P', gridsize=(20, 6), figsize=(14, 3))\n",
    "    axes.set_title(f'{esp} : chi2 / NObs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for esp in dfAnRes['Espèce'].unique():\n",
    "    axes = dfAnRes[dfAnRes['Espèce'] == esp].plot.hexbin(y='NObs', x='KS P', gridsize=(20, 6), figsize=(14, 3))\n",
    "    axes.set_title(f'{esp} : KS / NObs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnRes['NFunEvalsR'] = dfAnRes.NFunEvals.apply(lambda v: int(50*np.ceil(v/50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plyx.scatter(dfAnRes[['Espèce', 'Chi2 P', 'NObs', 'Outliers', 'NFunEvalsR']].dropna(subset=['NObs']),\n",
    "             x='Chi2 P', y='NObs', facet_col='Outliers', facet_row='NFunEvalsR', color='Espèce', height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plyx.scatter(dfAnRes[['Espèce', 'KS P', 'NObs', 'Outliers', 'NFunEvalsR']].dropna(subset=['NObs']),\n",
    "             x='KS P', y='NObs', facet_col='Outliers', facet_row='NFunEvalsR', color='Espèce', height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plyx.scatter(dfAnRes[['Espèce', 'Chi2 P', 'NObs', 'Outliers', 'NFunEvals']].dropna(subset=['NObs']),\n",
    "            x='NObs', y='Chi2 P', facet_col='Outliers', facet_row='Espèce', color='NFunEvals', height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plyx.scatter(dfAnRes[['Espèce', 'KS P', 'NObs', 'Outliers', 'NFunEvals']].dropna(subset=['NObs']),\n",
    "             x='NObs', y='KS P', facet_col='Outliers', facet_row='Espèce', color='NFunEvals', height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sh.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

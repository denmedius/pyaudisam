{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Table des matières automatique -->\n",
    "<div style=\"overflow-y: auto\">\n",
    "  <h1>Table des matières</h1>\n",
    "  <div id=\"toc\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données STOC-EPS Auvergne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec as pltg\n",
    "\n",
    "import simplekml as skml # Simple KML generation API\n",
    "import kmlcircle # Circle generation for KML generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fichiers Romain STOC/SHOC juillet 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 0. Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annees = [2015, 2016, 2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chargement des données, correction des noms de lieux-dits et simplification du jeu de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strAnnees = str(annees[0])\n",
    "if len(annees) > 1:\n",
    "    strAnnees += '-' + str(annees[-1])\n",
    "strAnnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocBrut = pd.DataFrame()\n",
    "for annee in annees:\n",
    "    dfStocBrutAnnee = pd.read_excel('STOC/Export STOC-SHOC Auvergne {}.xlsx'.format(annee))\n",
    "    dfStocBrut = dfStocBrut.append(dfStocBrutAnnee)\n",
    "\n",
    "len(dfStocBrut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KLieuDitDeviant = re.compile(r'([0-9]+) \\(point ([0-9]+)\\)')\n",
    "def corrigerLieuDit(lieuDit):\n",
    "    \n",
    "    mo = KLieuDitDeviant.match(lieuDit)\n",
    "    if mo:\n",
    "        print(lieuDit, mo.group(1) + '_' + mo.group(2))\n",
    "        lieuDit = mo.group(1) + '_' + mo.group(2)\n",
    "        \n",
    "    return lieuDit\n",
    "\n",
    "dfStocBrut['Lieu-dit'] = dfStocBrut['Lieu-dit'].apply(corrigerLieuDit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocBrut.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On ne s'intéresse qu'au STOC EPS\n",
    "dfStocBrut = dfStocBrut[dfStocBrut['Protocole'] == 'STOC_EPS']\n",
    "len(dfStocBrut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes inutiles, fusion des colonnes similaires, ...\n",
    "dfStoc = dfStocBrut[['Ref', 'Nom latin', 'Ordre systématique', \n",
    "                     'Date', 'Année', 'Heure début', 'Lieu-dit', 'Commune', 'Département', 'Altitude',\n",
    "                     'Nombre', 'Détails',\n",
    "                     'Prénom', 'Nom', 'Remarque', 'Remarque privée', 'Commentaire']].copy()\n",
    "#del dfStocBrut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStoc.set_index('Ref', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des colonnes de commentaires\n",
    "dfStoc['Remarque'] = dfStoc['Remarque'].fillna(value='')\n",
    "dfStoc['Remarque privée'] = dfStoc['Remarque privée'].fillna(value='')\n",
    "dfStoc['Commentaire'] = dfStoc['Commentaire'].fillna(value='')\n",
    "\n",
    "def mergeComments(sRow):\n",
    "    strOut = sRow['Remarque']\n",
    "    if sRow['Remarque privée']:\n",
    "        if strOut:\n",
    "            strOut += ' ; '\n",
    "        strOut += sRow['Remarque privée']\n",
    "    if sRow['Commentaire']:\n",
    "        if strOut:\n",
    "            strOut += ' ; '\n",
    "        strOut += sRow['Commentaire']\n",
    "    return strOut\n",
    "\n",
    "dfStoc.Remarque = dfStoc.apply(mergeComments, axis=1)\n",
    "dfStoc.drop(['Remarque privée', 'Commentaire'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des colonnes observateur, initiales, anonymisation\n",
    "dfStoc['Observateur'] = dfStoc.apply(lambda sRow: sRow['Nom'] + ' ' + sRow['Prénom'], axis=1)\n",
    "\n",
    "dfStoc['Initiales'] = \\\n",
    "    dfStoc[['Prénom', 'Nom']].apply(lambda pn: ''.join([''.join([m[0].upper() for m in s.replace(' ', '-').split('-')]) \\\n",
    "                                                        for s in pn]), axis=1)\n",
    "dfStoc.drop(['Nom', 'Prénom'], axis=1, inplace=True)\n",
    "\n",
    "dObservateurs = dict()\n",
    "def anonymiser(nom):\n",
    "    if nom not in dObservateurs:\n",
    "        dObservateurs[nom] = chr(65+len(dObservateurs))\n",
    "    return dObservateurs[nom]\n",
    "dfStoc['Anonyme'] = dfStoc.Observateur.apply(anonymiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les observateurs.\n",
    "dfObsteurs = dfStoc[['Observateur', 'Initiales', 'Anonyme']].groupby('Initiales').first()\n",
    "dfObsteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStoc = dfStoc.reindex(columns=['Nom latin', 'Date', 'Lieu-dit', 'Nombre', 'Détails',\n",
    "                                 'Observateur', 'Anonyme', 'Initiales', \n",
    "                                 'Heure début', 'Commune', 'Département', 'Altitude',\n",
    "                                 'Remarque', 'Ordre systématique', 'Année'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb total de données brutes\n",
    "len(dfStoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Sélection éventuelles des données à traiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfStoc = dfStoc[dfStoc['Nom latin'] == 'Turdus merula']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfStoc = dfStoc[dfStoc['Observateur'] == 'Meuret Jean-Philippe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Quelques chiffres bruts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espèces contactées.\n",
    "dfStoc['Nom latin'].unique(), len(dfStoc['Nom latin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb total de données, d'individus\n",
    "len(dfStoc), dfStoc.Nombre.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbre de sites inventoriés.\n",
    "len(dfStoc['Lieu-dit'].unique()), dfStoc['Lieu-dit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbre d'inventaires (STOC => normalement 2 par année, mais il y a des trous)\n",
    "len(dfStoc.groupby(['Lieu-dit', 'Date']).first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Petit avant-goût\n",
    "dfStoc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Nbre de données par classe de distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectif par classe de distance { dist => eff. }, à partir de la colonne DETAIL,\n",
    "# supposée formatée ainsi : \"<n1>x nia nia ... (Distance moins de <d1>m) / ...\n",
    "#                            ... / <np>x nia nia ... (Distance plus de <dp>m) / <np>x nia nia ... (En transit)\"\n",
    "KDistanceClassValues = { \"25\" : 25/2.0, \"100\" : (100+25)/2.0, \"200\" : (100+200)/2.0, \"Plus\" : 400.0 }\n",
    "KReNumPerDistExpect = re.compile(r\"([0-9]+)x(.*)\\((.*) ([0-9]+)m\\)\")\n",
    "KReNumPerDistTrans = re.compile(r\"([0-9]+)x(.*)\\(En transit\\)\")\n",
    "KReNumPerDistOther = re.compile(r\"([0-9]+)x.*\")\n",
    "categories = dict()\n",
    "ignored = dict()\n",
    "def details2Distances(strDetail):\n",
    "\n",
    "    numPerDist = {}\n",
    "    rawNumDists = strDetail.split(\"/\")\n",
    "    for rawNumDist in rawNumDists:\n",
    "        \n",
    "        rawNumDist = rawNumDist.replace('Distance plus de', '>')\n",
    "        mo = KReNumPerDistExpect.match(rawNumDist.strip())\n",
    "        if mo:\n",
    "            num = int(mo.group(1))\n",
    "            cat = mo.group(2).strip()\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "            if 'poussin' in cat or '1ère année' in cat:\n",
    "                print(\"'{}' dans '{}' trop jeune\".format(rawNumDist, strDetail))\n",
    "                ignored['jeune'] = ignored.get('jeune', 0) + num\n",
    "                continue # On ignore les trop jeunes pour se reproduire sans faire d'histoires\n",
    "                \n",
    "            if mo.group(3) == \"<\":\n",
    "                rawDist = mo.group(4)\n",
    "            else:\n",
    "                rawDist = \"Plus\"\n",
    "            if rawDist not in KDistanceClassValues:\n",
    "                ignored['bad-class'] = ignored.get('bad-class', 0) + num\n",
    "                print(\"Attention, donnée ignorée : Classe de distance inconnue '{}' dans colonne DETAIL : '{}'\" \\\n",
    "                      .format(rawDist, strDetail))\n",
    "                print (\"  On attendait : moins de 25, 100, 200 ou plus de 200\")\n",
    "                break\n",
    "\n",
    "            numPerDist[KDistanceClassValues[rawDist]] = num\n",
    "            \n",
    "        elif \"En transit\" in rawNumDist:\n",
    "            mo = KReNumPerDistTrans.match(rawNumDist.strip())\n",
    "            num = 0 if not mo else int(mo.group(1))\n",
    "            ignored['transit'] = ignored.get('transit', 0) + num\n",
    "            if num == 0:\n",
    "                print(\"Attention, donnée ignorée : Nb '{}' malformé dans colonne DETAIL : '{}'\".format(rawNumDist, strDetail))\n",
    "                ignored['bad-num'] = ignored.get('bad-num', 0) + 1\n",
    "            continue # On ignore les \"en vol\" sans faire d'histoires\n",
    "            \n",
    "        else: # Autres cas : on essaie de compter quand même mais on râle\n",
    "            mo = KReNumPerDistOther.match(rawNumDist.strip())\n",
    "            num = 0 if not mo else int(mo.group(1))\n",
    "            ignored['other'] = ignored.get('other', 0) + num\n",
    "                \n",
    "            print(\"Attention, donnée ignorée : Colonne DETAIL malformée : '{}' dans '{}'\".format(rawNumDist, strDetail))\n",
    "            print(\"  On attendait : <n1>x nia nia ... (< <d1>m) / ... \"\n",
    "                  \"/ <np>x nia nia ... (> <dp>m) / <np>x nia nia ... (En transit)\")\n",
    "            if num == 0:\n",
    "                print(\"Attention, donnée ignorée : Nb '{}' malformé dans colonne DETAIL malformée : '{}'\".format(rawNumDist, strDetail))\n",
    "                ignored['bad-num'] = ignored.get('bad-num', 0) + 1\n",
    "\n",
    "    return pd.Series(numPerDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distClassCols = ['Dist'+ str(d) for d in KDistanceClassValues.keys()]\n",
    "\n",
    "dfStoc['Détails'].fillna(value='', inplace=True)\n",
    "dfStoc[distClassCols] = dfStoc['Détails'].apply(details2Distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégories trouvées et nb d'individus\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStoc['DistTot'] = dfStoc[['Dist25', 'Dist100', 'Dist200', 'DistPlus']].sum(axis=1).fillna(value=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStoc = dfStoc.reindex(columns=['Nom latin', 'Date', 'Lieu-dit', 'Dist25', 'Dist100', 'Dist200', 'DistPlus',\n",
    "                                 'Observateur', 'Anonyme', 'Initiales',\n",
    "                                 'Heure début', 'Commune', 'Département', 'Altitude',\n",
    "                                 'Nombre', 'Détails',  'Remarque', 'Ordre systématique', 'Année', 'DistTot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStoc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfStoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison nb individu total et somme des classes de distances : différence normale =\n",
    "# - les 'en transit' ignorés (TurMer : 36)\n",
    "# - et qq autres, faute du saisisseur (TurMer : 4)\n",
    "#   Ex: '1x' sans classe de distance\n",
    "dict(NombreSum=dfStoc['Nombre'].sum(), DistTotSum=int(dfStoc['DistTot'].sum()),\n",
    "     Difference=dfStoc['Nombre'].sum() - int(dfStoc['DistTot'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majorité des explications : Nb individus ignorés, par classe de raison\n",
    "ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Voici les lignes coupables des différences en questions, hors \"en transit\"\n",
    "dfDistErr = \\\n",
    "  dfStoc.loc[(dfStoc['DistTot'] != dfStoc['Nombre']) & ~dfStoc['Détails'].str.contains('En transit'),\n",
    "             ['Nom latin', 'Lieu-dit', 'Dist25', 'Dist100', 'Dist200', 'DistPlus', 'DistTot',\n",
    "              'Nombre', 'Détails', 'Date', 'Observateur']]\n",
    "dfDistErr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Individualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indivDataCols = ['Nom latin', 'Date', 'Lieu-dit', 'Distance', 'Observateur']\n",
    "def generateIndivData(sGroupData):\n",
    "    \n",
    "    indivData = list()\n",
    "    \n",
    "    indivTmpl = pd.Series(data=[np.nan if col == 'Distance' else sGroupData[col] for col in indivDataCols],\n",
    "                          index=indivDataCols)\n",
    "    \n",
    "    #print(sGroupData)\n",
    "    \n",
    "    for distClass, distValue in KDistanceClassValues.items():\n",
    "        nbIndiv = sGroupData['Dist' + distClass]\n",
    "        if nbIndiv > 0:\n",
    "            for ind in range(int(nbIndiv)):\n",
    "                indivDatum = indivTmpl.copy()\n",
    "                indivDatum['Distance'] = distValue\n",
    "                indivData.append(indivDatum)\n",
    "            \n",
    "    \n",
    "    #print(indivData)\n",
    "    \n",
    "    return indivData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfStocIndiv = pd.DataFrame(columns=indivDataCols)\n",
    "for ref, sGroupData in dfStoc.iterrows():\n",
    "    dfStocIndiv = dfStocIndiv.append(pd.DataFrame(data=generateIndivData(sGroupData)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le nb d'individu total (comptés dans les classes de distance) n'a normalement pas changé lors l'individualisation\n",
    "assert len(dfStocIndiv) == dfStoc['DistTot'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mais comme certaines données ne sont pas classées en distances,\n",
    "# on a peut-être perdu des sites / lieux-dit inventoriés\n",
    "# En voici le nombre.\n",
    "len(dfStoc['Lieu-dit'].unique()) - len(dfStocIndiv['Lieu-dit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Voici les données avec 0 donnée classée en distance au moins 1 fois\n",
    "dfNoDist = dfDistErr[dfDistErr.DistTot == 0]\n",
    "dfNoDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbre de lieux-dits associés\n",
    "len(dfNoDist['Lieu-dit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mais certains de ces lieux ont d'autre données correctement classées en distance\n",
    "len(set(dfStocIndiv['Lieu-dit'].unique()).intersection(set(dfNoDist['Lieu-dit'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Au total, les sites / lieux-dits perdus sont ceux qui ont eut 0 donnée classée en distance\n",
    "# lors d'au moins 1 inventaire (dfNoDist), et qui n'ont aucune autre donnée dans aucun autre inventaire.\n",
    "assert set(dfStoc['Lieu-dit'].unique()) - set(dfStocIndiv['Lieu-dit'].unique()) \\\n",
    "       == set(dfNoDist['Lieu-dit'].unique()) \\\n",
    "          - set(dfStocIndiv['Lieu-dit'].unique()).intersection(set(dfNoDist['Lieu-dit'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfStocIndiv.groupby(['Lieu-dit', 'Date']).first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfStocIndiv.groupby(['Lieu-dit', 'Observateur', 'Date']).first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Inventaires (points, observateurs, dates => effort d'inventaire par point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInventaires = \\\n",
    "  dfStocIndiv[['Lieu-dit', 'Observateur', 'Date', 'Nom latin']] \\\n",
    "    .groupby(['Lieu-dit', 'Observateur', 'Date']).first() \\\n",
    "    .reset_index().set_index('Lieu-dit').drop('Nom latin', axis=1)\n",
    "dfInventaires.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInventaires['Effort'] = dfInventaires.groupby('Lieu-dit').apply(lambda dfChk: len(dfChk)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInventaires = dfInventaires.reset_index().set_index(['Lieu-dit', 'Observateur', 'Date'])\n",
    "dfInventaires.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbre total d'inventaires\n",
    "len(dfInventaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfInventaires.reset_index()['Lieu-dit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfInventaires[dfInventaires['Effort'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification que le fait de tenir compte des observateurs ne change rien à l'inventaire ... des inventaires\n",
    "assert len(dfStocIndiv[['Lieu-dit', 'Date', 'Observateur']] \\\n",
    "            .groupby(['Lieu-dit', 'Date']).first() \\\n",
    "            .reset_index().set_index('Lieu-dit').drop('Observateur', axis=1)) \\\n",
    "       == len(dfInventaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Nbres d'inventaires par classe d'effort\n",
    "dfInventaires.reset_index().groupby('Effort').count() \\\n",
    "             .drop(['Observateur', 'Date'], axis=1).rename(columns={'Lieu-dit' : 'Nb inventaires'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de l'effort d'inventaire à chaque donnée individualisée\n",
    "dfStocIndiv.set_index(['Lieu-dit', 'Observateur', 'Date'], inplace=True)\n",
    "dfStocIndiv = dfStocIndiv.join(dfInventaires)\n",
    "dfStocIndiv.reset_index(inplace=True)\n",
    "dfStocIndiv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ajout des données d'absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble complet des espèces d'intérêt (= contactées, puisqu'elles ont probablement toutes été contactées)\n",
    "# NB: Cette méthode d'obtention est fiable, même si elle n'en a pas l'air \\\n",
    "# (espèces sans aucune donnée chaque année ? pas crédible)\n",
    "stEspeces = set(dfStocIndiv['Nom latin'].unique())\n",
    "print(len(stEspeces), 'espèces contactées :', ', '.join(sorted(stEspeces)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espèces contactées pour chaque lieu-dit (tous inventaires confondus)\n",
    "dfEspecesContactees = dfStocIndiv.groupby(['Lieu-dit', 'Nom latin']).first().reset_index()[['Lieu-dit', 'Nom latin']]\n",
    "dfEspecesContactees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espèces non contactées pour chaque lieu-dit (tous inventaires confondus)\n",
    "# (=> un set d'espèces pour chaque site)\n",
    "dfEspecesManquees = \\\n",
    "  dfEspecesContactees.groupby(['Lieu-dit']).agg(lambda sEsp: stEspeces - set(sEsp.unique()))\n",
    "\n",
    "# Ajout des infos inventaire (effort)\n",
    "dfEspecesManquees = dfEspecesManquees.join(dfInventaires.groupby('Lieu-dit').first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEspecesManquees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des données d'absence\n",
    "dfStocAbsc = \\\n",
    "  pd.DataFrame(data=[{'Lieu-dit' : point, 'Observateur' : 'X', 'Date' : '',\n",
    "                      'Nom latin' : espece, 'Distance' : np.nan, 'Effort' : sEspece.Effort } \\\n",
    "                     for point, sEspece in dfEspecesManquees.iterrows() \\\n",
    "                     for espece in sEspece['Nom latin']])\n",
    "dfStocAbsc = dfStocAbsc.reindex(columns=dfStocIndiv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification : Chaque espèce doit avoir au moins 1 ligne pour chaque site/lieu-dit inventorié au moins 1 fois\n",
    "assert len(dfStocAbsc) + len(dfStocIndiv.groupby(['Lieu-dit', 'Nom latin']).first()) \\\n",
    "       - len(stEspeces) * len(dfInventaires.groupby('Lieu-dit').first()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tablea final : Données de contact individualisé et d'absence.\n",
    "dfStocTotal = dfStocIndiv.append(dfStocAbsc).sort_values(by=['Lieu-dit', 'Observateur', 'Date', 'Nom latin']) \\\n",
    "                    .reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification rudimentaire en nombre d'espèces : on doit avoir 1 ligne par espèce et par point !\n",
    "assert dfStocTotal.groupby(['Lieu-dit']) \\\n",
    "       .apply(lambda dfChk: len(dfChk['Nom latin'].unique()) == len(stEspeces)).all(), \\\n",
    "       \"Attention : Il manque des données d'absence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfStocTotal), len(dfStocIndiv), len(dfStocAbsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 8. Export Excel (tout sur 1 feuille)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsWriter = pd.ExcelWriter('STOC-EPS-{}-PourDistance.xlsx' \\\n",
    "                           .format(strAnnees), datetime_format='DD/MM/YYYY')\n",
    "dfStocTotal.to_excel(xlsWriter, 'ToutesEspeces', index=False, float_format='%.1f')\n",
    "xlsWriter.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 9. Export CSV pour distance, pour une liste d'espèce, avec génération d'un log (stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dfStoc['Nom latin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom latin exact (Cf. colonne 'Nom latin' dans fichier Biolovision)\n",
    "especes = ['Turdus merula', 'Fringilla coelebs', 'Sylvia atricapilla', 'Parus major', 'Phylloscopus collybita']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfInventaires2 = dfInventaires.reset_index()[['Lieu-dit', 'Effort']].groupby('Lieu-dit').first()\n",
    "strLog = 'STOC EPS {}\\n\\n'.format('+'.join([str(annee) for annee in annees]))\n",
    "strLog += '* Nbre de site / lieux-dits inventoriés : {}\\n' .format(len(dfInventaires2))\n",
    "strLog += '* Effort total (au sens de Distance) : {}\\n'.format(dfInventaires2.Effort.sum())\n",
    "strLog += '* Nombre des sites/lieux-dits par valeur d\\'effort :\\n'\n",
    "strEffortTable = dfInventaires2.reset_index().groupby('Effort').count() \\\n",
    "                 .rename(columns={'Lieu-dit' : 'Nb points'}).to_string()\n",
    "strLog += '\\n'.join([' '*4 + s for s in strEffortTable.split('\\n')]) + '\\n'\n",
    "\n",
    "for espece in especes:\n",
    "    \n",
    "    print(espece, '... ', end='')\n",
    "    \n",
    "    strLog += '* {}\\n'.format(espece)\n",
    "    dfCible = dfStocTotal[dfStocTotal['Nom latin'] == espece]\n",
    "\n",
    "    if len(dfCible) == 0:\n",
    "        print('Erreur : Aucune donnée !')\n",
    "        strLog += '  Aucune donnée.'\n",
    "        continue\n",
    "\n",
    "    dfCible = dfCible[['Lieu-dit', 'Effort', 'Distance']]\n",
    "    dfCible['Region'] = 'Auvergne'\n",
    "    dfCible['Surface'] = 26000*100 # ha\n",
    "    # Workaroung df.to_csv(float_format='%.1f') not working\n",
    "    # when not only floats in the columns ...\n",
    "    dfCible.Distance = \\\n",
    "      dfCible.Distance.apply(lambda x: '' if np.isnan(x) else '{:.1f}'.format(x).replace('.', ','))\n",
    "    dfCible = \\\n",
    "      dfCible.reindex(columns=['Region', 'Surface', 'Lieu-dit', 'Effort', 'Distance'])\n",
    "    dfCible.sort_values(by=['Lieu-dit'], inplace=True)\n",
    "\n",
    "    assert set(dfCible['Lieu-dit'].unique()) == set(dfInventaires.reset_index()['Lieu-dit'].unique())\n",
    "\n",
    "    strLog += '  - Nbre de données individuelles : total {}, d\\'absence {}\\n' \\\n",
    "              .format(len(dfCible), len(dfCible[dfCible.Distance == '']))\n",
    "\n",
    "    # Export final.\n",
    "    tgtFileName = ''.join([word.capitalize() for word in espece.split(' ')]) + '-' + strAnnees + '-dist.txt'\n",
    "    dfCible.to_csv(tgtFileName, index=False, sep='\\t', encoding='utf-8',\n",
    "                   header=['Region*Label', 'Region*Area', 'Point transect*Label',\n",
    "                           'Point transect*Survey effort', 'Observation*Radial distance'])\n",
    "\n",
    "    print(tgtFileName)\n",
    "\n",
    "print()\n",
    "print(strLog)\n",
    "print(strLog, file=open('STOC-EPS-' + strAnnees + '-dist.log', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Rien de grave, c\\'est juste terminé :-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Analyse des données à courtes distances\n",
    "\n",
    "(trop certaines années, pour certaines espèces ... pb observateur ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSpecies = dfStoc[['Nom latin', 'DistTot']].groupby('Nom latin').sum().sort_values(by='DistTot', ascending=False)\n",
    "dfSpecies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nCommSpecies = 24\n",
    "\n",
    "exclSpecies = ['Chroicocephalus ridibundus']\n",
    "\n",
    "commSpecies=  list(dfSpecies[~dfSpecies.index.isin(exclSpecies)].index[:nCommSpecies])\n",
    "\n",
    "dict(number=nCommSpecies, species=', '.join(commSpecies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Aucune distance => non en 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAllNullDists(dfGroup):\n",
    "    return (dfGroup[['Dist25', 'Dist100', 'Dist200', 'DistPlus']].isnull().all(axis=1) \\\n",
    "            & ~dfGroup['Détails'].str.contains('En transit')).sum()\n",
    "dfStocNoDist = dfStoc.groupby('Observateur').apply(countAllNullDists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Nombre de données sans aucune distance par observateur\n",
    "_ = dfStocNoDist.plot(kind='bar', color='b', figsize=(16, 3),\n",
    "                      title='Nb données sans aucune tranche de distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Liste de ces données.\n",
    "dfStoc.loc[dfStoc.Dist25.isnull() & dfStoc.Dist100.isnull() & dfStoc.Dist200.isnull() & dfStoc.DistPlus.isnull() \\\n",
    "           & ~dfStoc['Détails'].str.contains('En transit')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Répartition des données par classe de distance et par observateur,\n",
    "\n",
    "* soit par espèce (pour les les plus nombreuses),\n",
    "* soit pour toutes les espèces (quels que soit leurs effectifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1 planche pour nSpPerFig espèces communes\n",
    "# 1 graphique par espèce\n",
    "cols2Plot = ['Dist25', 'Dist100', 'Dist200', 'DistPlus']\n",
    "cols2Sum = cols2Plot + ['DistTot']\n",
    "\n",
    "nSpPerFig = 6\n",
    "exportFig = True\n",
    "\n",
    "# Pour chaque espèce :\n",
    "for nSpInd, spName in enumerate(commSpecies):\n",
    "\n",
    "    # Start a new figure for each new species chunk\n",
    "    if nSpInd % nSpPerFig == 0:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15, 3*nSpPerFig))\n",
    "\n",
    "        gs = pltg.GridSpec(nSpPerFig, 1)\n",
    "\n",
    "        fig.suptitle('Répartition des données {} par tranche de distance et par observateur (anonymisé), pour chaque espèce' \\\n",
    "                     .format(strAnnees),\n",
    "                     fontsize=18, x=0, horizontalalignment='left', y=1, verticalalignment='bottom')\n",
    "\n",
    "        nSubPltInd = 0\n",
    "\n",
    "    # Pour chaque espèce de la planche\n",
    "    # 1. Les données de l'espèce\n",
    "    df2Plot = dfStoc[dfStoc['Nom latin'] == spName]\n",
    "\n",
    "    # 2. Nb de données par classe de distance, par observateur\n",
    "    df2Plot = df2Plot.groupby(['Initiales']).agg({ col: sum for col in cols2Sum })\n",
    "    dNDists = { '<'+k[4:] : int(v) for k, v in df2Plot[cols2Plot].sum().to_dict().items() }\n",
    "    dNDists['>200'] = dNDists['<Plus']\n",
    "    del dNDists['<Plus']\n",
    "    nTotal = df2Plot['DistTot'].sum()\n",
    "\n",
    "    # 3.Poids des données de l'observateur dans le total de l'espèce (%)\n",
    "    df2Plot['Poids'] = round(100 * df2Plot.DistTot / df2Plot.DistTot.sum(), 1)\n",
    "\n",
    "    # %age de données par classe de distance, par observateur.\n",
    "    df2Plot[cols2Plot] = 100 * df2Plot[cols2Plot].divide(df2Plot.DistTot, axis='index')\n",
    "\n",
    "    # 4.Tracé.\n",
    "    axes = fig.add_subplot(gs[nSubPltInd])\n",
    "    df2Plot[cols2Plot].plot(ax=axes, kind='bar', stacked=True) \n",
    "    axes.set_title('#{} {} : {} individus ({})'.format(nSpInd+1, spName, nTotal,\n",
    "                                                   ', '.join(['{} {}m'.format(v, k) for k, v in dNDists.items()])),\n",
    "                   fontsize=14)\n",
    "    axes.set_xlabel('')\n",
    "    axes.set_ylabel('%', fontsize=12)\n",
    "    axes.legend(cols2Plot, bbox_to_anchor=(1.02, 1), loc=2, fontsize=12)\n",
    "\n",
    "    for i, v in enumerate(df2Plot.Poids):\n",
    "        axes.text(x=i-.2, y=3, s=str(v)+'%',fontsize=12,  color='k')\n",
    "\n",
    "    nSubPltInd += 1\n",
    "\n",
    "    # Terminate figure at the end of each species chunk\n",
    "    if nSpInd % nSpPerFig == nSpPerFig - 1 or nSpInd == nCommSpecies - 1:\n",
    "        \n",
    "        fig.tight_layout(h_pad=3)\n",
    "\n",
    "        if exportFig:\n",
    "            tgtImgFile = \\\n",
    "                'STOC-{}-Especes-{:02d}-{:02d}.jpg'.format(strAnnees, nSpPerFig * (nSpInd // nSpPerFig) + 1, nSpInd+1)\n",
    "            fig.savefig(os.path.join('STOC', tgtImgFile), format='jpg', bbox_inches='tight', transparent=False)\n",
    "            plt.close(fig)\n",
    "            print(tgtImgFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsteurs.to_excel(os.path.join('STOC', 'Observateurs-{}.xlsx'.format(strAnnees)), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix espèce\n",
    "#sp = 'Toutes espèces'\n",
    "sp = commSpecies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocSpNbPerDist = dfStoc[dfStoc['Nom latin'] == sp] if sp != 'Toutes espèces' else dfStoc\n",
    "\n",
    "'{} : {} données'.format(sp, dfStocSpNbPerDist.DistTot.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb de données par classe de distance, par observateur\n",
    "dfStocSpNbPerDist = dfStocSpNbPerDist.groupby(['Observateur']).agg({'Dist25': sum, 'Dist100': sum, 'Dist200': sum,\n",
    "                                                                    'DistPlus': sum, 'DistTot': sum })\n",
    "dfStocSpNbPerDist['Poids'] = round(100 * dfStocSpNbPerDist.DistTot / dfStocSpNbPerDist.DistTot.sum(), 1)\n",
    "dfStocSpNbPerDist[['Poids', 'DistTot', 'Dist25', 'Dist100', 'Dist200', 'DistPlus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb de données par classe de distance, tous observateurs confondus\n",
    "dfStocSpNbPerDist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocSpNbPerDist.sum()[['Dist25', 'Dist100', 'Dist200', 'DistPlus']] \\\n",
    "    .plot(kind='bar', figsize=(16, 4),\n",
    "          title='{} : Répartition des données par tranche de distance (tous observateurs)'.format(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %age de données par classe de distance, par observateur, et poids des données de l'observateur dans le total (%)\n",
    "for col in dfStocSpNbPerDist.columns:\n",
    "    if col not in ['Poids', 'DistTot']:\n",
    "        dfStocSpNbPerDist[col] = round(100 * dfStocSpNbPerDist[col] / dfStocSpNbPerDist.DistTot, 1)\n",
    "        \n",
    "dfStocSpNbPerDist[['Poids', 'DistTot', 'Dist25', 'Dist100', 'Dist200', 'DistPlus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé\n",
    "_ = dfStocSpNbPerDist[['Dist25', 'Dist100', 'Dist200', 'DistPlus']] \\\n",
    "        .plot(kind='bar', figsize=(16, 4), stacked=True,\n",
    "              title='{} : Répartition des données par tranche de distance et par observateur'.format(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Répartition des observateurs (fréquence) en fonction de leur %age de données à courtes distances\n",
    "_ = dfStocSpNbPerDist.Dist25.plot(kind='hist', bins=15, figsize=(16, 4), \n",
    "                                  title='{} : Nb d\\'observateurs selon leur %age de données proches'.format(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStoc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2Plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fichier STOC JPM 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocBrutJPM = pd.read_excel('STOC/STOC-EPS-2018-ExportJPM.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocBrutJPM = dfStocBrutJPM[['Nom espèce', 'Nom latin', 'Date',\n",
    "                               'Lieu-dit', 'Commune', 'Lat (WGS84)', 'Lon (WGS84)', 'Altitude',\n",
    "                               'Estimation', 'Nombre', 'Détails', 'Code atlas', 'Remarque', 'Remarque privée']]\n",
    "dfStocBrutJPM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Géolocalisation des points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocBrutJPM[['IdStoc', 'IdPoint']] = dfStocBrutJPM['Lieu-dit'].apply(lambda s:pd.Series(s.split('_'))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocBrutJPM.loc[dfStocBrutJPM.IdStoc == 630167, 'ComStoc'] = 'Saint-Hilaire-la-Croix (63)'\n",
    "dfStocBrutJPM.loc[dfStocBrutJPM.IdStoc == 630167, 'ComIStoc'] = 'SH'\n",
    "dfStocBrutJPM.loc[dfStocBrutJPM.IdStoc == 630136, 'ComStoc'] = 'Champs (63)'\n",
    "dfStocBrutJPM.loc[dfStocBrutJPM.IdStoc == 630136, 'ComIStoc'] = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocJPMPts = dfStocBrutJPM[['IdStoc', 'IdPoint', 'ComStoc', 'ComIStoc', 'Lat (WGS84)', 'Lon (WGS84)', 'Altitude']] \\\n",
    "                    .groupby(['IdStoc', 'IdPoint', 'ComStoc', 'ComIStoc'], as_index=False).first()\n",
    "dfStocJPMPts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Export KML des points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circlesSpecs = [(25, 20), (100, 30), (200, 40)]\n",
    "circlesColor = skml.Color.fuchsia\n",
    "\n",
    "labelStyle = skml.LabelStyle(color=skml.Color.lightgreen, scale=1)\n",
    "iconStyle = skml.IconStyle(icon=skml.Icon(href='http://maps.google.com/mapfiles/kml/shapes/placemark_circle.png'))\n",
    "ptStyle = skml.Style(labelstyle=labelStyle, iconstyle=iconStyle)\n",
    "\n",
    "circleStyle = skml.LineStyle(color=circlesColor, width=1)\n",
    "\n",
    "for idStoc in dfStocJPMPts.IdStoc.unique():\n",
    "    \n",
    "    dfPts = dfStocJPMPts[dfStocJPMPts.IdStoc == idStoc]\n",
    "    commune = dfPts.iloc[0].ComStoc\n",
    "    \n",
    "    kml = skml.Kml(name='STOC EPS JPM {} {}'.format(commune, idStoc))\n",
    "    \n",
    "    for lbl, sPt in dfPts.iterrows():\n",
    "        \n",
    "        # Point\n",
    "        pt = kml.newpoint(name='{} {}'.format(sPt.ComIStoc, sPt.IdPoint), \n",
    "                          coords=[(sPt['Lon (WGS84)'], sPt['Lat (WGS84)'], sPt['Altitude'])], extrude=1)\n",
    "        pt.style = ptStyle\n",
    "        pt.description = 'lat={:.4f}, long={:.4f}, alt={:.0f}'.format(sPt['Lon (WGS84)'], sPt['Lat (WGS84)'], sPt['Altitude'])\n",
    "        \n",
    "        # Cercles concentriques\n",
    "        for r, n in circlesSpecs:\n",
    "            ls = kml.newlinestring(name='rayon={}m'.format(r), extrude=1,\n",
    "                                   coords=kmlcircle.spoints(long=sPt['Lon (WGS84)'], lat=sPt['Lat (WGS84)'],\n",
    "                                                            meters=r, n=n, offset=0))\n",
    "            ls.linestyle = circleStyle\n",
    "\n",
    "    tgtKmlFileName = \\\n",
    "        'STOC/STOC-JPM-{}-{}.kml'.format(commune.replace('-', '').replace(' ', '').replace('(', '').replace(')', ''), idStoc)\n",
    "    kml.save(tgtKmlFileName)\n",
    "    \n",
    "    print(tgtKmlFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fichier STOC JPM 2015-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocBrutJPM = pd.read_excel('STOC-JPM-2015-2017.xlsx')\n",
    "dfStocBrutJPM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocBrutJPM.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfStocBrutJPM[['Année', 'Nom espèce', 'Nombre']].groupby(['Année', 'Nom espèce']).sum()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reset_index().set_index('Nom espèce')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame()\n",
    "y['2015'] = x[x['Année'] == 2015]['Nombre']\n",
    "y['2016'] = x[x['Année'] == 2016]['Nombre']\n",
    "y['2017'] = x[x['Année'] == 2017]['Nombre']\n",
    "y = y.fillna(value=0).astype(int)\n",
    "y['Cumul'] = y.sum(axis=1)\n",
    "y = y.sort_values(by='Cumul', ascending=False)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_excel('STOC-JPM-2015-2017-FrequenceEspeces.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fichier Pierre STOC fin 2015\n",
    "    (pas cohérent avec envoi Romain mi 2017, mais avec les habitats ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToutBrutPT = \\\n",
    "  pd.read_csv('Pierre2015/STOC-Auvergne-2015-utf8.csv', parse_dates=['Date'], infer_datetime_format=True, \n",
    "              low_memory=False, index_col=0, sep='\\t', decimal='.', encoding='utf-8', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfToutBrutPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToutBrutPT.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToutBrutPT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfToutBrutPT['Nom latin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTurMerPT = dfToutBrutPT[dfToutBrutPT['Nom latin'] == 'Turdus merula']\n",
    "assert len(dfTurMerPT) == 532, 'Nb données TurMer non concordant avec filtrage LibreOfficeCalc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb de points STOC\n",
    "assert len(dfTurMerPT['Lieu-dit'].unique()) == 338, 'Nb points avec TurMer non concordant avec filtrage LibreOfficeCalc'\n",
    "assert len(dfToutBrutPT['Lieu-dit'].unique()) == 381, 'Nb total points inventorié non concordant avec filtrage LibreOfficeCalc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb d'inventaires\n",
    "assert len(dfTurMerPT.groupby(['Date', 'Lieu-dit']).first()) in (531, 532),  'Nb inventaires avec TurMer non concordant avec filtrage LibreOfficeCalc'\n",
    "assert len(dfToutBrutPT.groupby(['Date', 'Lieu-dit']).first()) == 708,  'Nb total inventaire non concordant avec filtrage LibreOfficeCalc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTurMerPT['Nombre'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToutBrutPT['Habitat principal 1'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

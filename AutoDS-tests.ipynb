{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Auto table of contents -->\n",
    "<h1 class='tocIgnore'>AutoDS : Tests</h1>\n",
    "<div style=\"overflow-y: auto\">\n",
    "  <h2 class='tocIgnore'>Table des matières</h2>\n",
    "  <div id=\"toc\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('../ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise au point, tests unitaires et d'intégration du module autods\n",
    "\n",
    "(interface python à MCDS.exe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib as implib\n",
    "from packaging import version\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict as odict\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly as ply\n",
    "import plotly.graph_objs as plygo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate Warnings as Exception\n",
    "#import warnings\n",
    "#warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual / reference closeness measure : -round(log10((actual - reference) / max(abs(actual), abs(reference))), 1)\n",
    "# = Compute the orders of magnitude that separate the difference from the max. of the two values\n",
    "def closeness(sRefAct):\n",
    "    \n",
    "    x, y = sRefAct.to_list()\n",
    "    \n",
    "    # Special cases with 1 NaN, or 1 or more inf => all different\n",
    "    if np.isnan(x):\n",
    "        if not np.isnan(y):\n",
    "            return 0 # All different\n",
    "    elif np.isnan(y):\n",
    "        return 0 # All different\n",
    "    \n",
    "    if np.isinf(x) or np.isinf(y):\n",
    "        return 0 # All different\n",
    "    \n",
    "    # Normal case\n",
    "    c = abs(x - y)\n",
    "    if not np.isnan(c) and c != 0:\n",
    "        c = c / max(abs(x), abs(y))\n",
    "    \n",
    "    return round(-np.log10(c), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests unitaires et d'intégration module *autods*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Détection de Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autods as ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classe DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Excel source\n",
    "ds = ads.DataSet(source=os.path.join('AutoDS', 'refin', 'ACDC2019-Papyrus-ALAARV-saisie-ttes-cols.xlsx'),\n",
    "                 decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'])\n",
    "ds.dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV source with ',' as decimal point\n",
    "ds = ads.DataSet(source=os.path.join('AutoDS', 'refin', 'ACDC2019-Papyrus-TURMER-AB-5mn-1dec-dist.txt'),\n",
    "                 decimalFields=['Point transect*Survey effort', 'Observation*Radial distance'])\n",
    "\n",
    "assert not any(ds.dfData[col].dropna().apply(lambda v: isinstance(v, str)).any() for col in ds.decimalFields), \\\n",
    "       'Error: Some strings found in declared decimal fields ... any decimal format issue ?'\n",
    "\n",
    "ds.dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV source with '.' as decimal point\n",
    "ds = ads.DataSet(source=os.path.join('AutoDS', 'refin', 'ACDC2019-Papyrus-ALAARV-AB-10mn-1dotdec-dist.txt'),\n",
    "                 decimalFields=['Point transect*Survey effort', 'Observation*Radial distance'])\n",
    "\n",
    "assert not any(ds.dfData[col].dropna().apply(lambda v: isinstance(v, str)).any() for col in ds.decimalFields), \\\n",
    "       'Error: Some strings found in declared decimal fields ... any decimal format issue ?'\n",
    "\n",
    "ds.dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame source.\n",
    "dfData = pd.DataFrame(columns=['Date', 'TrucDec', 'Espece', 'Point', 'Effort', 'Distance'],\n",
    "                      data=[('2019-05-13', 3.5, 'TURMER', 23, 2,   83),\n",
    "                            ('2019-05-15', np.nan, 'TURMER', 23, 2,   27.355),\n",
    "                            ('2019-05-13', 0, 'ALAARV', 29, 2,   56.85),\n",
    "                            ('2019-04-03', 1.325, 'PRUMOD', 53, 1.3,  7.2),\n",
    "                            ('2019-06-01', 2, 'PHICOL', 12, 1,  np.nan),\n",
    "                            ('2019-06-19', np.nan, 'PHICOL', 17, 0.5, np.nan),\n",
    "                           ])\n",
    "dfData['Region'] = 'ACDC'\n",
    "dfData['Surface'] = '2400'\n",
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ads.DataSet(source=dfData, decimalFields=['Effort', 'Distance', 'TrucDec'])\n",
    "ds.dfData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classes XXEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Instanciation et chargement des spécifs sur les stats en sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'test out'))\n",
    "    print('Error: Should have raised an AssertionError !')\n",
    "except AssertionError as exc:\n",
    "    print('Good forbidden chars detection:', exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = eng.setupRunFolder(runPrefix='uni') # Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Génération fichier de données en entrée de MCDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataFileName = eng.buildDataFile(dataSet=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Génération fichier de \"commandes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmdFileName = eng.buildCmdFile(estimKeyFn='HNORMAL', estimAdjustFn='COSINE',\n",
    "                               estimCriterion='AIC', cvInterval=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### d. Execution en mode \"debug\"\n",
    "\n",
    "(génération des fichiers cmd et data, mais pas d'appel à l'exécutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runCode, runTime, runDir = eng.run(ds, realRun=False, runPrefix='int',\n",
    "                                   estimKeyFn='UNIFORM', estimAdjustFn='POLY',\n",
    "                                   estimCriterion='AIC', cvInterval=95)\n",
    "assert runCode == 0, 'Should have NOT run (run code = 0)'\n",
    "dict(runCode=runCode, runDir=runDir, runTime=runTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### e. Exécution réelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runCode, runTime, runDir = eng.run(ds, realRun=True, runPrefix='int',\n",
    "                                   estimKeyFn='UNIFORM', estimAdjustFn='POLY',\n",
    "                                   estimCriterion='AIC', cvInterval=95)\n",
    "assert runCode == 2, 'Should have run with warnings (run code = 2)'\n",
    "dict(runCode=runCode, runDir=runDir, runTime=runTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Génération fichier de données en entrée pour Distance\n",
    "\n",
    "(mode 'point transect' uniquement pour le moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(eng.workDir, 'distance-in'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distDataFileName = \\\n",
    "    eng.buildDistanceDataFile(ds, tgtFilePathName=os.path.join(eng.workDir, 'distance-in', 'import-data-noextra.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distDataFileName = \\\n",
    "    eng.buildDistanceDataFile(ds, tgtFilePathName=os.path.join(eng.workDir, 'distance-in', 'import-data-withextra.txt'),\n",
    "                              withExtraFields=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. classe ResultsSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miCustCols = pd.MultiIndex.from_tuples([('id', 'index', 'Value'),\n",
    "                                        ('sample', 'species', 'Value'),\n",
    "                                        ('sample', 'periods', 'Value'),\n",
    "                                        ('sample', 'duration', 'Value'),\n",
    "                                        ('variant', 'precision', 'Value')])\n",
    "dfCustColTrans = \\\n",
    "    pd.DataFrame(index=miCustCols,\n",
    "                 data=dict(en=['index', 'species', 'periods', 'duration', 'precision'],\n",
    "                           fr=['numéro', 'espèce', 'périodes', 'durée', 'précision']))\n",
    "\n",
    "rs = ads.ResultsSet(analysisClass=ads.MCDSAnalysis, miCustomCols=miCustCols, dfCustomColTrans=dfCustColTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rs.dfData.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sHead = pd.Series(index=miCustCols, data=list(range(len(miCustCols))))\n",
    "miResCols = ads.MCDSAnalysis.MIRunColumns.append(ads.MCDSEngine.statModCols())\n",
    "sResult = pd.Series(index=miResCols, data=list(range(len(miResCols))))\n",
    "rs.append(sResult, sCustomHead=sHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaw = rs.dfData\n",
    "dfRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrans = rs.dfTransData('fr')\n",
    "dfTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dfRaw.columns) == len(dfTrans.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests de validation module autods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MCDSEngine : Génération de fichiers d'entrée pour Distance\n",
    "\n",
    "* via un jeu de fichiers d'entrée bruts Excel, et leur export de référence, éprouvé dans Distance,\n",
    "* et comparaison du produit de XXEngine.buildDistanceDataFile à cette référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDistCases = pd.DataFrame([dict(inFileName='ACDC2019-Papyrus-ALAARV-saisie-ttes-cols.xlsx',\n",
    "                                 decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'],\n",
    "                                 refOutFileName='ACDC2019-Papyrus-ALAARV-saisie-5-cols.txt', withExtraFields=False),\n",
    "                            dict(inFileName='ACDC2019-Papyrus-ALAARV-saisie-ttes-cols.xlsx',\n",
    "                                 decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'],\n",
    "                                 refOutFileName='ACDC2019-Papyrus-ALAARV-saisie-ttes-cols.txt', withExtraFields=True)])\n",
    "dfDistCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails = 0\n",
    "for ind, sCase in dfDistCases.iterrows():\n",
    "    \n",
    "    print('#', ind, ':', sCase.inFileName)\n",
    "\n",
    "    # Create data set\n",
    "    ds = ads.DataSet(source=os.path.join('AutoDS', 'refin', sCase.inFileName),\n",
    "                     decimalFields=sCase.decimalFields)\n",
    "    \n",
    "    # Build distance import data file\n",
    "    ofn = os.path.join(eng.workDir, 'distance-in', sCase.refOutFileName)\n",
    "    ofn = eng.buildDistanceDataFile(dataSet=ds, tgtFilePathName=ofn, withExtraFields=sCase.withExtraFields)\n",
    "    \n",
    "    # Compare generated file to reference\n",
    "    rfn = os.path.join('AutoDS', 'refout', sCase.refOutFileName)\n",
    "    with open(ofn, 'r') as fOut, open(rfn, 'r') as fRef:\n",
    "        if fOut.read() == fRef.read():\n",
    "            print('Success : Conform to reference.')\n",
    "        else:\n",
    "            print('Error: Generated file differs from reference', rfn)\n",
    "            fails += 1\n",
    "            \n",
    "    print()\n",
    "    \n",
    "print('All test cases succeeded !' if fails == 0 else 'Error: {} test case(s) failed.'.format(fails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MCDSEngine : Exécution avec de vraies données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A virer : tests MCDSAnalysis ci-dessous englobants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ads.DataSet(source=os.path.join('AutoDS', 'refin', 'ACDC2019-Papyrus-ALAARV-saisie-ttes-cols.xlsx'),\n",
    "                 decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'])\n",
    "\n",
    "eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'))\n",
    "\n",
    "runCode, runTime, runDir = eng.run(ds, realRun=True, runPrefix='int',\n",
    "                                   estimKeyFn='UNIFORM', estimAdjustFn='POLY',\n",
    "                                   estimCriterion='AIC', cvInterval=95)\n",
    "assert runCode == 2, 'Should have run with warnings (run code = 2)'\n",
    "dict(runCode=runCode, runDir=runDir, runTime=runTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MCDSAnalysis : Analyse avec de vraies données\n",
    "\n",
    "(et comparaison à des analyses faites à la main avec Distance 7.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Construction des cas tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load refout results table\n",
    "dfRefRes = pd.read_excel(os.path.join('AutoDS', 'refout', 'ACDC2019-Papyrus-ALAARV-TURMER-resultats-distance-73.xlsx'))\n",
    "dfRefRes.rename(columns=dict(Name='Model'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRefRes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate test cases definition code from refout results file (don't cheat : only input columns :-)\n",
    "caseIdCols = ['Species', 'Sample', 'Precision', 'Duration', 'Model']\n",
    "dfAnlysCases = dfRefRes[caseIdCols].copy()\n",
    "\n",
    "#dfAnlysCases['Status'] = \\\n",
    "#    dfAnlysCases.Status.apply(lambda s: 1 if s == 'OK' else 2 if s == 'Warnings' else 3)\n",
    "dfAnlysCases['KeyFn'] = \\\n",
    "    dfAnlysCases.Model.apply(lambda s: 'UNIFORM' if s.startswith('Unif') \\\n",
    "                                                 else 'HNORMAL' if s.startswith('Half') else 'HAZARD')\n",
    "dfAnlysCases['AdjSer'] = \\\n",
    "    dfAnlysCases.Model.apply(lambda s: 'COSINE' if s.endswith('Cos') \\\n",
    "                                                else 'POLY' if s.endswith('SimPoly') else 'HERMITE')\n",
    "dfAnlysCases['InFileName'] = \\\n",
    "    dfAnlysCases.apply(lambda sRow: 'ACDC2019-Papyrus-{}-{}-{}mn-{}dec-dist.txt' \\\n",
    "                                    .format(sRow.Species,\n",
    "                                            'AB' if 'A+B' in sRow.Sample else 'A' if 'A' in sRow.Sample else 'B',\n",
    "                                            5 if '5' in sRow.Duration == '5 mn' else 10,\n",
    "                                            6 if sRow.Precision.startswith('6 déc') else 1),\n",
    "                       axis='columns')\n",
    "\n",
    "dfAnlysCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Préparation des analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimalFields = ['Point transect*Survey effort', 'Observation*Radial distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis engine\n",
    "mcds = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'),\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frozen analysis parameters (a choice here)\n",
    "KEstimCriterion = 'AIC'\n",
    "KCVInterval = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result object construction\n",
    "miCustCols = pd.MultiIndex.from_tuples([('sample', col, 'Value') for col in caseIdCols])\n",
    "dfCustColTrans = \\\n",
    "    pd.DataFrame(index=miCustCols,\n",
    "                 data=dict(en=caseIdCols, fr=['Espèce', 'Echantillon', 'Précision', 'Durée', 'Modèle']))\n",
    "\n",
    "results = ads.ResultsSet(analysisClass=ads.MCDSAnalysis, miCustomCols=miCustCols, dfCustomColTrans=dfCustColTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Ou : Exécution des analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsStart = pd.Timestamp.now()\n",
    "print('Started at', tsStart)\n",
    "print()\n",
    "\n",
    "# Run all analyses\n",
    "lastInFileName = ''\n",
    "for ind, sCase in dfAnlysCases.iterrows():\n",
    "    \n",
    "    prefix = sCase.InFileName[len('ACDC2019-Papyrus')+1:-len('-dist.txt')]\n",
    "    print('#{:3d}'.format(ind+1), prefix, sCase.KeyFn, sCase.AdjSer, end='\\n'*2)\n",
    "    \n",
    "    # Create data set if not already done.\n",
    "    if lastInFileName != sCase.InFileName:\n",
    "        ds = ads.DataSet(os.path.join('AutoDS', 'refin', sCase.InFileName), decimalFields=decimalFields)\n",
    "        lastInFileName = sCase.InFileName\n",
    "        \n",
    "    # Run analysis\n",
    "    analysis = ads.MCDSAnalysis(engine=mcds, dataSet=ds, namePrefix=prefix,\n",
    "                                estimKeyFn=sCase.KeyFn, estimAdjustFn=sCase.AdjSer,\n",
    "                                estimCriterion=KEstimCriterion, cvInterval=KCVInterval)\n",
    "    sResult = analysis.run()\n",
    "\n",
    "    # Save results\n",
    "    sHead = pd.Series(data=[sCase[col] for col in sCase.index[:len(caseIdCols)]], index=miCustCols)\n",
    "\n",
    "    results.append(sResult, sCustomHead=sHead)\n",
    "    \n",
    "tsEnd = pd.Timestamp.now()\n",
    "print('Finished at', tsEnd, ': duration', str(tsEnd - tsStart).replace('0 days ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analysis results\n",
    "dfActRes = results.dfData\n",
    "\n",
    "dfActRes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check translation\n",
    "dfActTrRes = results.dfTransData('fr')\n",
    "\n",
    "dfActTrRes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in case need for not recomputing them\n",
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "\n",
    "results.toExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Ou : Rechargement des résultats d'analyses\n",
    "\n",
    "(déjà faites ci-dessus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resFileName = os.path.join(mcds.workDir, 'autods-validation-results.xlsx')\n",
    "\n",
    "results.fromExcel(resFileName, sheetName='AutoDSVal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Comparaison des résultats à la référence\n",
    "\n",
    "(référence = analyses faites \"à la main\" avec distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes des résultats autos et association aux disponibles dans la référence, pour comparaison.\n",
    "dCompCols = \\\n",
    "{\n",
    "    ('sample', 'Species', 'Value'):   'Species',\n",
    "    ('sample', 'Sample', 'Value'):    'Sample',\n",
    "    ('sample', 'Precision', 'Value'): 'Precision',\n",
    "    ('sample', 'Duration', 'Value'):  'Duration',\n",
    "    ('sample', 'Model', 'Value'):     'Model',\n",
    "    \n",
    "    ('run output', 'run status', 'Value') : 'Status',\n",
    "    \n",
    "    ('detection probability', 'total number of parameters (m)', 'Value'): '# params',\n",
    "    ('encounter rate', 'number of observations (n)', 'Value'): '# obs',\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'): 'AIC',\n",
    "    ('detection probability', 'chi-square test probability (distance set 3)', 'Value')         : 'GOF Chi-p',\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value')                  : 'GOF K-S p',\n",
    "    ('detection probability', 'Cramér-von Mises (uniform weighting) test probability', 'Value'): 'GOF CvM (unif) p',\n",
    "    ('detection probability', 'Cramér-von Mises (cosine weighting) test probability', 'Value') : 'GOF CvM (cos) p',\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'): 'ESW/EDR',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl')  : 'ESW/EDR LCL',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl')  : 'ESW/EDR UCL',\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Cv')   : 'ESW/EDR CV',\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'): 'D',\n",
    "    ('density/abundance', 'density of animals', 'Lcl')  : 'D LCL',\n",
    "    ('density/abundance', 'density of animals', 'Ucl')  : 'D UCL',\n",
    "    ('density/abundance', 'density of animals', 'Cv')   : 'D CV',\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'): 'P',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl')  : 'P LCL',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl')  : 'P UCL',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Cv')   : 'P CV',\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df')   : 'P DF',\n",
    "}\n",
    "len(dCompCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sélection des colonnes de résultats, et renommage comme la référence, pour comparaison\n",
    "dfActRes4c = dfActRes[list(dCompCols.keys())].copy()\n",
    "dfActRes4c.columns = [dCompCols[col] for col in dCompCols]\n",
    "dfActRes4c.set_index(caseIdCols, inplace=True)\n",
    "\n",
    "dfActRes4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes utiles de la référence pour comparaison\n",
    "dfRefRes4c = dfRefRes.copy()\n",
    "dfRefRes4c.set_index(caseIdCols, inplace=True)\n",
    "dfRefRes4c.drop(columns=['Run', 'Delta AIC'], inplace=True)\n",
    "\n",
    "dfRefRes4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premières vérifications : égalité des listes de cas tests (index) et des listes de noms de colonnes (columns)\n",
    "assert sorted(dfActRes4c.index)   == sorted(dfRefRes4c.index)\n",
    "assert sorted(dfActRes4c.columns) == sorted(dfRefRes4c.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparaison actual / reference : mesure de proximité\n",
    "# => Plus c'est grand, plus petite est la différence relative entre les 2\n",
    "#    Ex: 3 = facteur 10**3 entre différence et valeurs absolues ; +inf = AUCUNE différence\n",
    "#        0 = pas bon, l'un des 2 est nul n'autre pas du tout\n",
    "#        inf = égalité parfaite ref/act\n",
    "# Cf. tests unitaires plus bas.\n",
    "dfRelDif = dfRefRes4c.copy()\n",
    "for col in dfRelDif.columns:\n",
    "    dfRelDif['act'] = dfActRes4c[col]\n",
    "    dfRelDif[col] = dfRelDif[[col, 'act']].apply(closeness, axis='columns')\n",
    "    dfRelDif.drop(columns='act', inplace=True)\n",
    "    \n",
    "dfRelDif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Sauvegarde des résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resCompFileName = os.path.join(mcds.workDir, 'autods-validation-rescomp.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(resCompFileName) as xlsxWriter:\n",
    "\n",
    "    dfRefRes.to_excel(xlsxWriter, sheet_name='RefResults', index=True)\n",
    "    dfActRes4c.reset_index().to_excel(xlsxWriter, sheet_name='ActResults', index=True)\n",
    "    dfRelDif.reset_index().to_excel(xlsxWriter, sheet_name='Diff2Ref', index=True)\n",
    "    dfActRes.to_excel(xlsxWriter, sheet_name='RawActResults', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Diagnostic automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic : on ne garde que ce qui n'est pas rigoureusement égal (lignes et colonnes).\n",
    "dfBadRelDif = dfRelDif.copy()\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Suppression lignes : Status identique et reste NaN (cas des status = 0/3/4 : erreur d'exécution ou pas d'exécution)\n",
    "valCols = [col for col in dfRelDif.columns if col != 'Status']\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif.Status.abs() == np.inf) & dfBadRelDif[valCols].isnull().all(axis='columns')].index,\n",
    "            axis='index', inplace=True)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Suppression lignes : Status et toutes autres colonnes à inf (stricte égalité)\n",
    "dfBadRelDif.drop(dfBadRelDif[dfBadRelDif.apply(np.isinf, axis='columns').all(axis='columns')].index,\n",
    "            axis='index', inplace=True)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Suppression lignes : Status identique et toutes autres colonnes suppérieures à 4 (quasi égalité)\n",
    "dfBadRelDif.drop(dfBadRelDif[(dfBadRelDif >= 4).all(axis='columns')].index,\n",
    "            axis='index', inplace=True)\n",
    "len(dfBadRelDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBadRelDif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRefRes4c.loc[dfBadRelDif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActRes4c.loc[dfBadRelDif.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('All test cases succeeded !' if fails == 0 else 'Error: {} test case(s) failed.'.format(fails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MCDSAnalysis : Rapport d'analyses Excel et HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes pour les tableaux de synthèse du rapport\n",
    "synthCols = \\\n",
    "[\n",
    "    ('sample', 'Species', 'Value'),\n",
    "    ('sample', 'Sample', 'Value'),\n",
    "    ('sample', 'Precision', 'Value'),\n",
    "    ('sample', 'Duration', 'Value'),\n",
    "    ('sample', 'Model', 'Value'),\n",
    "    \n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability (distance set 3)', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl'),\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df'),\n",
    "\n",
    "    ('run output', 'run folder', 'Value'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ads.ResultsReport(resultsSet=results, synthCols=synthCols, title='Validation du module autods',\n",
    "                           subTitle='Rapport d\\'analyse global', anlysSubTitle='Rapport détaillé',\n",
    "                           description='Qu\\'ajouter de plus ?', keywords='autods, validation',\n",
    "                           lang='fr', attachedDir='.', tgtFolder=mcds.workDir, tgtPrefix='autods-validation-report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlRep = report.toHtml()\n",
    "\n",
    "HTML(f'Rapport HTML : <a href=\"{htmlRep}\" target=\"blank\">{htmlRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlsxRep = report.toExcel()\n",
    "\n",
    "HTML(f'Rapport Excel : <a href=\"{xlsxRep}\" target=\"blank\">{xlsxRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode MCDS plots file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcFileName = os.path.join('AutoDS', 'mcds-out', 'TURMER-AB-10mn-1dec-hno-cos-01qn02hg', 'plots.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(srcFileName, 'r').readlines()\n",
    "lines = [line.strip() for line in lines]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itLines = iter(lines)\n",
    "chapters = list()\n",
    "for title in itLines:\n",
    "    #title = next(itLines)\n",
    "    subTitle = next(itLines)\n",
    "    xLabel = next(itLines)\n",
    "    yLabel = next(itLines)\n",
    "    xMin, xMax, yMin, yMax = [float(s) for s in next(itLines).split()]\n",
    "    nDataRows = int(next(itLines))\n",
    "    dataRows = list()\n",
    "    for l in range(nDataRows):\n",
    "        dataRows.append([float(s) for s in next(itLines).split()])\n",
    "    chapters.append(dict(title=title, subTitle=subTitle, dataRows=dataRows, #nDataRows=nDataRows,\n",
    "                         xLabel=xLabel, yLabel=yLabel, xMin=xMin, xMax=xMax, yMin=yMin, yMax=yMax))\n",
    "len(chapters), chapters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QQ-plot\n",
    "chapter = chapters[0]\n",
    "chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(chapter['dataRows'])\n",
    "dfQqData = pd.DataFrame(data=chapter['dataRows'], columns=['If the fit was perfect ...', 'Real observations'],\n",
    "                        index=np.linspace(0.5/n, 1.0-0.5/n, n))\n",
    "dfQqData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = dfQqData.plot(figsize=(16, 6), color=['blue', 'red'], grid=True,\n",
    "                     xlim=(chapter['xMin'], chapter['xMax']), ylim=(chapter['yMin'], chapter['yMax']))\n",
    "axes.legend(['If the fit was perfect ...', 'Real observations'], fontsize=12)\n",
    "axes.set_facecolor('#f9fbf3')\n",
    "axes.figure.patch.set_facecolor('#f9fbf3')\n",
    "axes.set_title(label=chapter['title'] + ' : ' + chapter['subTitle'], fontdict=dict(fontsize=16), pad=20)\n",
    "axes.set_xlabel(chapter['xLabel'], fontsize=12)\n",
    "_ = axes.set_ylabel(chapter['yLabel'], fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes.figure.savefig('tmp/mlb-qqplot.jpg', box_inches='tight')\n",
    "axes.figure.savefig('tmp/mlb-qqplot.png', box_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(axes.figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly 4\n",
    "fig = plygo.Figure()\n",
    "\n",
    "fig.add_trace(plygo.Scatter(x=dfQqData.index, y=dfQqData['If the fit was perfect ...'],\n",
    "                            name='If the fit was perfect ...', line=dict(color='blue', width=2), opacity=0.7))\n",
    "fig.add_trace(plygo.Scatter(x=dfQqData.index, y=dfQqData['Real observations'],\n",
    "                            name='Real observations', line=dict(color='red', width=2)))\n",
    "\n",
    "fig.update_layout(title=chapter['title'] + ' : ' + chapter['subTitle'],\n",
    "                  xaxis=dict(title=chapter['xLabel'], range=(chapter['xMin'], chapter['xMax']),\n",
    "                             zeroline=True, linewidth=1, linecolor='black'),\n",
    "                  yaxis=dict(title=chapter['yLabel'], range=(chapter['yMin'], chapter['yMax']),\n",
    "                             zeroline=True, linewidth=1, linecolor='black'),\n",
    "                  legend=plygo.layout.Legend(x=0.09, y=0.90, bordercolor='black', borderwidth=1),\n",
    "                  shapes=[plygo.layout.Shape(type='line', x0=chapter['xMax'], y0=chapter['yMin'],\n",
    "                                                          x1=chapter['xMax'], y1=chapter['yMax']),\n",
    "                          plygo.layout.Shape(type='line', x0=chapter['xMin'], y0=chapter['yMax'],\n",
    "                                                          x1=chapter['xMax'], y1=chapter['yMax'])],\n",
    "                  template='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow ... VERY slooooooooow !\n",
    "fig.write_image(\"tmp/ply-qqplot.svg\")\n",
    "fig.write_image(\"tmp/ply-qqplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection probability\n",
    "chapter = chapters[1]\n",
    "chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDetProbData = pd.DataFrame(data=chapter['dataRows'], \n",
    "                             columns=[chapter['xLabel'], chapter['yLabel'] + ' (sampled)', chapter['yLabel'] + ' (fitted)'])\n",
    "dfDetProbData.set_index(chapter['xLabel'], inplace=True)\n",
    "dfDetProbData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes = dfDetProbData.plot(figsize=(16, 6), color=['blue', 'red'], grid=True,\n",
    "                          xlim=(chapter['xMin'], chapter['xMax']), ylim=(chapter['yMin'], chapter['yMax']))\n",
    "\n",
    "axes.set_title(label=chapter['title'] + ' : ' + chapter['subTitle'], fontdict=dict(fontsize=16), pad=20)\n",
    "axes.legend(dfDetProbData.columns, fontsize=12)\n",
    "axes.set_xlabel(chapter['xLabel'], fontsize=12)\n",
    "_ = axes.set_ylabel(chapter['yLabel'], fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly 4\n",
    "fig = plygo.Figure()\n",
    "\n",
    "fig.add_trace(plygo.Scatter(x=dfDetProbData.index, y=dfDetProbData[chapter['yLabel'] + ' (sampled)'],\n",
    "                            name=chapter['yLabel'] + ' (sampled)', line=dict(color='blue', width=2), opacity=0.7))\n",
    "fig.add_trace(plygo.Scatter(x=dfDetProbData.index, y=dfDetProbData[chapter['yLabel'] + ' (fitted)'],\n",
    "                            name=chapter['yLabel'] + ' (fitted)', line=dict(color='red', width=2)))\n",
    "\n",
    "fig.update_layout(title=chapter['title'] + ' : ' + chapter['subTitle'],\n",
    "                  xaxis=dict(title=chapter['xLabel'], range=(chapter['xMin'], chapter['xMax']),\n",
    "                             zeroline=True, linewidth=1, linecolor='black'),\n",
    "                  yaxis=dict(title=chapter['yLabel'], range=(chapter['yMin'], chapter['yMax']),\n",
    "                             zeroline=True, linewidth=1, linecolor='black'),\n",
    "                  legend=plygo.layout.Legend(x=0.65, y=0.85*chapter['yMax'], bordercolor='black', borderwidth=1),\n",
    "                  shapes=[plygo.layout.Shape(type='line', x0=chapter['xMax'], y0=chapter['yMin'],\n",
    "                                                          x1=chapter['xMax'], y1=chapter['yMax']),\n",
    "                          plygo.layout.Shape(type='line', x0=chapter['xMin'], y0=chapter['yMax'],\n",
    "                                                          x1=chapter['xMax'], y1=chapter['yMax'])],\n",
    "                  template='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Detection probability\n",
    "chapter = chapters[2]\n",
    "chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfProdDensData = pd.DataFrame(data=chapter['dataRows'], \n",
    "                              columns=[chapter['xLabel'], chapter['yLabel'] + ' (sampled)', chapter['yLabel'] + ' (fitted)'])\n",
    "dfProdDensData.set_index(chapter['xLabel'], inplace=True)\n",
    "dfProdDensData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = dfProdDensData.plot(figsize=(16, 6), color=['blue', 'red'],\n",
    "                           xlim=(chapter['xMin'], chapter['xMax']), ylim=(chapter['yMin'], chapter['yMax']))\n",
    "axes.set_title(label=chapter['title'] + ' : ' + chapter['subTitle'], fontdict=dict(fontsize=16), pad=20)\n",
    "axes.legend(dfProdDensData.columns, fontsize=12)\n",
    "axes.set_xlabel(chapter['xLabel'], fontsize=12)\n",
    "_ = axes.set_ylabel(chapter['yLabel'], fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotly 4\n",
    "fig = plygo.Figure()\n",
    "\n",
    "fig.add_trace(plygo.Scatter(x=dfProdDensData.index, y=dfProdDensData[chapter['yLabel'] + ' (sampled)'],\n",
    "                            name=chapter['yLabel'] + ' (sampled)', line=dict(color='blue', width=2), opacity=0.7))\n",
    "fig.add_trace(plygo.Scatter(x=dfProdDensData.index, y=dfProdDensData[chapter['yLabel'] + ' (fitted)'],\n",
    "                            name=chapter['yLabel'] + ' (fitted)', line=dict(color='red', width=2)))\n",
    "\n",
    "fig.update_layout(title=chapter['title'] + ' : ' + chapter['subTitle'],\n",
    "                  xaxis=dict(title=chapter['xLabel'], range=(chapter['xMin'], chapter['xMax']),\n",
    "                             zeroline=True, linewidth=1, linecolor='black'),\n",
    "                  yaxis=dict(title=chapter['yLabel'], range=(chapter['yMin'], chapter['yMax']),\n",
    "                             zeroline=True, linewidth=1, linecolor='black'),\n",
    "                  legend=plygo.layout.Legend(xanchor='right', yanchor='top', bordercolor='black', borderwidth=1),\n",
    "                  #margin=plygo.layout.Margin(l=40, r=40, b=40, t=40, pad=0),\n",
    "                  shapes=[plygo.layout.Shape(type='line', x0=chapter['xMax'], y0=chapter['yMin'],\n",
    "                                                          x1=chapter['xMax'], y1=chapter['yMax']),\n",
    "                          plygo.layout.Shape(type='line', x0=chapter['xMin'], y0=chapter['yMax'],\n",
    "                                                          x1=chapter['xMax'], y1=chapter['yMax'])],\n",
    "                  template='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract results from MCDS work folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results set to store results into.\n",
    "miCustCols = pd.MultiIndex.from_tuples([('id', 'ExecCase', 'Value')])\n",
    "dfCustColTrans = \\\n",
    "    pd.DataFrame(index=miCustCols, data=dict(en=['ExecCase'], fr=['CasExec']))\n",
    "\n",
    "results = ads.ResultsSet(analysisClass=ads.MCDSAnalysis, miCustomCols=miCustCols, dfCustomColTrans=dfCustColTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis engine\n",
    "mcds = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'dist-order-sens'),\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process folders in engine work folder.\n",
    "for folder in os.listdir(mcds.workDir):\n",
    "    \n",
    "    # Skip folders that are not MCDS run ones.\n",
    "    folderPath = os.path.join(mcds.workDir, folder)\n",
    "    if not os.path.isdir(folderPath):\n",
    "        continue\n",
    "    if os.path.splitext(folder)[1] or 'stats.txt' not in os.listdir(folderPath):\n",
    "        print(f'Skipping {folderPath}, not an MCDS.exe run folder with a stats.txt file')\n",
    "        continue\n",
    "        \n",
    "    # Tell the engine were it has run (even it does not rember it ;-)\n",
    "    _ = mcds.setupRunFolder(forceSubFolder=folder)\n",
    "    \n",
    "    # Decode results.\n",
    "    sRes = mcds.decodeStats()\n",
    "    print()\n",
    "    \n",
    "    # Store them for later.\n",
    "    sHead = pd.Series(data=[folder], index=miCustCols)\n",
    "    results.append(sRes, sCustomHead=sHead)\n",
    "\n",
    "# Tadaaaaaaa !\n",
    "results.dfTransData('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dfTransData('en').to_excel(mcds.workDir + '.auto.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unitary tests for reference / actual results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [np.nan, -np.inf, -1.0e12, -1.0e5, -1.0-1e-5, -1.0, -1.0+1e-5, -1.0e-8, 0.0, 1.0e-8, 1.0, 1.0e5, 1.0e12, np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aClose = np.ndarray(shape=(len(values), len(values)))\n",
    "for r in range(len(values)):\n",
    "    for c in range(len(values)):\n",
    "        try:\n",
    "            aClose[r, c] = closeness(pd.Series([values[r], values[c]]))\n",
    "        except Exception as exc:\n",
    "            print(exc, r, c, values[r], values[c])\n",
    "pd.DataFrame(data=aClose, index=values, columns=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whereClose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proximité infinie sur la diagonale (sauf pour nan et +/-inf)\n",
    "assert all(np.isnan(values[i]) or np.isinf(values[i]) or np.isinf(aClose[i, i]) for i in range(len(values))), \\\n",
    "       'Error: Inequality on the diagonal'\n",
    "\n",
    "# Pas de proximité infinie ailleurs\n",
    "assert all(r == c or not np.isinf(aClose[r, c]) for r in range(len(values)) for c in range(len(values))), \\\n",
    "       'Error: No equality should be found outside the diagonal'\n",
    "\n",
    "# Bonne proximité uniquement autour de -1\n",
    "whereClose = [i for i in range(len(values)) if abs(values[i] + 1) <= 1.0e-5]\n",
    "assert all(aClose[r, c] > 4 for r in whereClose for c in whereClose), 'Error: Unexpectedly bad closeness around -1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancienne méthode qui ne marche pas.\n",
    "# Comparaison actual / reference : -round(log10((actual - reference) / max(abs(actual), abs(reference))), 1)\n",
    "# => Plus c'est grand, plus petite est la différence relative entre les 2\n",
    "#    Ex: 3 = facteur 10**3 entre différence et valeurs absolues ; +inf = AUCUNE différence\n",
    "#        0 = pas bon, l'un des 2 est nul n'autre pas du tout\n",
    "# Cf. tests unitaires plus bas.\n",
    "#dfRelDif = pd.DataFrame(index=dfRefRes4c.index)\n",
    "#for col in dfRefRes4c.columns:\n",
    "#    dfRelDif['NormalCases'] = ~((dfActRes4c[col].isnull() & dfRefRes4c.notnull()) \\\n",
    "#                                | (dfActRes4c[col].notnull() & dfRefRes4c.isnull()) \\\n",
    "#                                | dfActRes4c[col].notnull() | dfRefRes4c.isnull())\n",
    "#    dfRelDif[col] = abs(dfActRes4c[col] - dfRefRes4c[col])\n",
    "#    dfRelDif[col].where(dfRelDif[col].isnull() | dfRelDif[col] == 0,\n",
    "#                        dfRelDif[col] / pd.DataFrame(dict(act=dfActRes4c[col], ref=dfRefRes4c[col])).abs().max(axis='columns'),\n",
    "#                        inplace=True)\n",
    "#    dfRelDif[col].where(dfRelDif['NormalCases'], 1, inplace=True) # Force special case to \"all different\"\n",
    "#    dfRelDif.drop(columns=['NormalCases'], inplace=True)\n",
    "#    dfRelDif[col] = np.round(-np.log10(dfRelDif[col]), 1)\n",
    "#    \n",
    "#dfRelDif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate stats columns translation file\n",
    "\n",
    "(from documentation stats & modules specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtTransFileName = os.path.join('AutoDS', 'mcds-stat-mod-trans.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(object):\n",
    "    \n",
    "    def __init__(self, dTrans, lang='en'):\n",
    "        assert 'en' in dTrans, 'At least \"en\" translation must be defined'\n",
    "        self.dTrans = dTrans\n",
    "        self.setLang(lang)\n",
    "        \n",
    "    def setLang(self, lang):\n",
    "        self.lang = lang.lower()\n",
    "        assert self.lang in ['en', 'fr'], 'No support for \"{}\" language'.format(lang)\n",
    "        \n",
    "    def __call__(self, s):\n",
    "        return self.dTrans.get(self.lang, self.dTrans['en']).get(s, self.dTrans['en'].get(s, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFigureTrans = \\\n",
    "    dict(en=dict(Value='', Cv='ConfInd', Lcl='Min', Ucl='Max', Df='DoF'),\n",
    "         fr=dict(Value='', Cv='IndConf', Lcl='Min', Ucl='Max', Df='DegLib'))\n",
    "\n",
    "figtr = Translator(DFigureTrans, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DStatisticTrans = \\\n",
    "    dict(en={ 'number of observations (n)': 'NObs',\n",
    "              'number of samples (k)': 'NSamp',\n",
    "              'effort (L or K or T)': 'Effort',\n",
    "              'encounter rate (n/L or n/K or n/T)': 'EncRate',\n",
    "              'left truncation distance': 'LeftTruncDist',\n",
    "              'right truncation distance (w)': 'RightTruncDist',\n",
    "              'total number of parameters (m)': 'TotNumPars',\n",
    "              'AIC value': 'AIC',\n",
    "              'chi-square test probability (distance set 1)': 'Chi2 P 1',\n",
    "              'chi-square test probability (distance set 2)': 'Chi2 P 2',\n",
    "              'chi-square test probability (distance set 3)': 'Chi2 P 3',\n",
    "              'f(0) or h(0)': 'f/h(0)',\n",
    "              'probability of detection (Pw)': 'PDetec',\n",
    "              'effective strip width (ESW) or effective detection radius (EDR)': 'EDR/ESW',\n",
    "              'AICc': 'AICc',\n",
    "              'BIC': 'BIC',\n",
    "              'Log likelihood': 'LogLhood',\n",
    "              'Kolmogorov-Smirnov test probability': 'KS P',\n",
    "              'Cramér-von Mises (uniform weighting) test probability': 'CvM Uw P',\n",
    "              'Cramér-von Mises (cosine weighting) test probability': 'CvM Cw P',\n",
    "              'key function type': 'KeyFn',\n",
    "              'adjustment series type': 'AdjSer',\n",
    "              'number of key function parameters (NKP)': 'NumKFnPars',\n",
    "              'number of adjustment term parameters (NAP)': 'NumASerPars',\n",
    "              'number of covariate parameters (NCP)': 'NumCovars',\n",
    "              'estimated value of A(1) adjustment term parameter': 'EstA(1)',\n",
    "              'estimated value of A(2) adjustment term parameter': 'EstA(2)',\n",
    "              'estimated value of A(3) adjustment term parameter': 'EstA(3)',\n",
    "              'estimated value of A(4) adjustment term parameter': 'EstA(4)',\n",
    "              'estimated value of A(5) adjustment term parameter': 'EstA(5)',\n",
    "              'estimated value of A(6) adjustment term parameter': 'EstA(6)',\n",
    "              'estimated value of A(7) adjustment term parameter': 'EstA(7)',\n",
    "              'estimated value of A(8) adjustment term parameter': 'EstA(8)',\n",
    "              'estimated value of A(9) adjustment term parameter': 'EstA(9)',\n",
    "              'estimated value of A(10) adjustment term parameter': 'EstA(10)',\n",
    "              'average cluster size': 'AvgClustSz',\n",
    "              'size-bias regression correlation (r)': 'SzBias RegCorr',\n",
    "              'p-value for correlation significance (r-p)': 'CorSignPVal',\n",
    "              'estimate of expected cluster size corrected for size bias': 'EstExpFixedCluSz',\n",
    "              'density of clusters (or animal density if non-clustered)': 'DensClu',\n",
    "              'density of animals': 'Density',\n",
    "              'number of animals, if survey area is specified': 'Number',\n",
    "              'bootstrap density of clusters': 'BootsDensClu',\n",
    "              'bootstrap density of animals': 'BootDensity',\n",
    "              'bootstrap number of animals': 'BootNumber' },\n",
    "         fr={ 'number of samples (k)': 'NEchant',\n",
    "              'encounter rate (n/L or n/K or n/T)': 'TxContact',\n",
    "              'left truncation distance': 'DistTroncGche',\n",
    "              'right truncation distance (w)': 'DistTroncDte',\n",
    "              'total number of parameters (m)': 'NbTotPars',\n",
    "              'Log likelihood': 'LogProba',\n",
    "              'key function type': 'FnClé',\n",
    "              'adjustment series type': 'SérAjust',\n",
    "              'number of key function parameters (NKP)': 'NbParsFnClé',\n",
    "              'number of adjustment term parameters (NAP)': 'NbParsSérAjust',\n",
    "              'number of covariate parameters (NCP)': 'NbCovars',\n",
    "              'average cluster size': 'TailMoyClust',\n",
    "              'size-bias regression correlation (r)': 'CorrReg BiaisTail',\n",
    "              'p-value for correlation significance (r-p)': 'PVal SignifCorr',\n",
    "              'estimate of expected cluster size corrected for size bias': 'TailCorrCluAttEst',\n",
    "              'density of animals': 'Densité',\n",
    "              'number of animals, if survey area is specified': 'Nombre',\n",
    "              'bootstrap density of clusters': 'BootsDensClu',\n",
    "              'bootstrap density of animals': 'DensitéBoot',\n",
    "              'bootstrap number of animals': 'NombreBoot' })\n",
    "\n",
    "statr = Translator(DStatisticTrans, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatModTrans = ads.MCDSEngine.MIStatModColumns.to_frame()\n",
    "dfStatModTrans.reset_index(drop=True, inplace=True)\n",
    "dfStatModTrans.rename(columns={ 0: 'Module', 1: 'Statistic', 2: 'Figure' }, inplace=True)\n",
    "for lang in ['en', 'fr']:\n",
    "    figtr.setLang(lang)\n",
    "    statr.setLang(lang)\n",
    "    dfStatModTrans[lang] = \\\n",
    "        dfStatModTrans.apply(lambda sRow: '{} {}'.format(figtr(sRow.Figure), statr(sRow.Statistic)).strip(),\n",
    "                             axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatModTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatModTrans.to_csv(tgtTransFileName, sep='\\t', index=False)\n",
    "tgtTransFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(index=analysis.MIRunColumns,\n",
    "             data=dict(en=['ModKeyFn', 'ModAdjSer', 'ModChcCrit', 'ConfInter', 'RunCode', 'RunFolder'],\n",
    "                       fr=['FnCléMod', 'SérAjustMod', 'CritChxMod', 'InterConf', 'CodeExec', 'DossierExec']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatModTransExt = pd.read_csv(tgtTransFileName, sep='\\t')\n",
    "dfStatModTransExt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfStatModTransExt = pd.read_csv(tgtTransFileName, sep='\\t')dfStatModTransExt.set_index(['Module', 'Statistic', 'Figure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'fr'\n",
    "dTrans = dfStatModTransExt.set_index(['Module', 'Statistic', 'Figure'])[lang].to_dict()\n",
    "resultats.dfData.columns = [dTrans.get(col, col) for col in resultats.dfData.columns]\n",
    "resultats.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = resultats.dfData.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatModTransExt.set_index(['Module', 'Statistic', 'Figure'])[lang].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test case class\n",
    "\n",
    "(no use actually : pd.DataFrame already does the job !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-class for test cases\n",
    "class TestCase(object):\n",
    "    def __init__(self, **attrs):\n",
    "        if not hasattr(self.__class__, 'AttributeNames'):\n",
    "            self.__class__.AttributeNames = set(attrs.keys())\n",
    "        else:\n",
    "            assert set(attrs.keys()) == self.AttributeNames, \\\n",
    "                   'Some attribute name not in frozen set {{{}}}'.format(','.join(self.AttributeNames))\n",
    "        for attrName, AttrValue in attrs.items():\n",
    "            setattr(self, attrName, AttrValue)\n",
    "    def __repr__(self):\n",
    "        return '{}({})'.format(self.__class__.__name__, ','.join('{}:{}'.format(k, v) for k, v in self.__dict__.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test this super-class.\n",
    "class TCTest(TestCase):\n",
    "    pass\n",
    "\n",
    "tstTestCases = list()\n",
    "tstTestCases.append(TCTest(x=1, y='a')) # Define attributes\n",
    "tstTestCases.append(TCTest(x=2, y='b')) # Check attributes\n",
    "try:\n",
    "    tstTestCases.append(TCTest(x=2, z=None)) # Refuse new attributes\n",
    "    assert False, 'Error: New attributes should be refused'\n",
    "except AssertionError as exc:\n",
    "    print('Good refuse of new attributes:', exc)\n",
    "    \n",
    "[str(tc) for tc in tstTestCases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise au point décodage sorties de MCDS : fichier de stats\n",
    "\n",
    "TODO: Add french translation of variables / parameters names and descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nom et description des colonnes du tableau de stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'mcds-stat-row-specs.txt'\n",
    "\n",
    "fStatRowSpecs = open(fileName, mode='r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statRowSpecLines = [line.rstrip('\\n') for line in fStatRowSpecs.readlines() if not line.startswith('#')]\n",
    "statRowSpecs =  [(statRowSpecLines[i].strip(), statRowSpecLines[i+1].strip()) \\\n",
    "                 for i in range(0, len(statRowSpecLines)-2, 3)]\n",
    "dfStatRowSpecs = pd.DataFrame(columns=['Name', 'Description'], data=statRowSpecs).set_index('Name')\n",
    "\n",
    "dfStatRowSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatRowSpecs.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numéro et description des modules et statistiques associées\n",
    "\n",
    "(colonnes Module et Statistic du tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'mcds-stat-mod-specs.txt'\n",
    "\n",
    "fStatModSpecs = open(fileName, mode='r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nMaxAdjParams = 10\n",
    "\n",
    "statModSpecLines = [line.rstrip('\\n') for line in fStatModSpecs.readlines() if not line.startswith('#')]\n",
    "reModSpecNumName = re.compile('(.+) – (.+)')\n",
    "statModSpecs = list()\n",
    "moModule = None\n",
    "for line in statModSpecLines:\n",
    "    if not line:\n",
    "        continue\n",
    "    if moModule is None:\n",
    "        moModule = reModSpecNumName.match(line.strip())\n",
    "        continue\n",
    "    if line == ' ':\n",
    "        moModule = None\n",
    "        continue\n",
    "    moStatistic = reModSpecNumName.match(line.strip())\n",
    "    modNum, modDesc, statNum, statDescNotes = \\\n",
    "        moModule.group(1), moModule.group(2), moStatistic.group(1), moStatistic.group(2)\n",
    "    for i in range(len(statDescNotes)-1, -1, -1):\n",
    "        if not re.match('[\\d ,]', statDescNotes[i]):\n",
    "            statDesc = statDescNotes[:i+1]\n",
    "            statNotes = statDescNotes[i+1:].replace(' ', '')\n",
    "            break\n",
    "    modNum = int(modNum)\n",
    "    if statNum.startswith('101 '):\n",
    "        for num in range(nMaxAdjParams): # Assume no more than that ... a bit hacky !\n",
    "            statModSpecs.append((modNum, modDesc, 101+num, # Make statDesc unique for later indexing\n",
    "                                 statDesc.replace('each', 'A({})'.format(num+1)), statNotes))\n",
    "    else:\n",
    "        statNum = int(statNum)\n",
    "        if modNum == 2 and statNum == 3: # Actually, there are 0 or 3 of these ...\n",
    "            for num in range(3):\n",
    "                statModSpecs.append((modNum, modDesc, num+201,\n",
    "                                     # Change statNum & Make statDesc unique for later indexing\n",
    "                                     statDesc+' (distance set {})'.format(num+1), statNotes))\n",
    "        else:\n",
    "            statModSpecs.append((modNum, modDesc, statNum, statDesc, statNotes))\n",
    "dfStatModSpecs = pd.DataFrame(columns=['modNum', 'modDesc', 'statNum', 'statDesc', 'statNotes'],\n",
    "                              data=statModSpecs).set_index(['modNum', 'statNum'])\n",
    "\n",
    "dfStatModSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "dfStatModSpecs.modDesc.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Notes sur les statistiques des modules\n",
    "\n",
    "(infos supplémentaire indiquant comment utiliser ou pas les 5 dernières colonnes Value, Cv, Lcl, Ucl, Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'mcds-stat-mod-notes.txt'\n",
    "\n",
    "fStatModNotes = open(fileName, mode='r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statModNoteLines = [line.rstrip('\\n') for line in fStatModNotes.readlines() if not line.startswith('#')]\n",
    "statModNotes =  [(int(line[:2]), line[2:].strip()) for line in statModNoteLines if line]\n",
    "\n",
    "dfStatModNotes = pd.DataFrame(data=statModNotes, columns=['Note', 'Text']).set_index('Note')\n",
    "\n",
    "dfStatModNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lecture du tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = mcds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.statsFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatRows = pd.read_csv(eng.statsFileName, sep=' +', engine='python', names=dfStatRowSpecs.index)\n",
    "dfStatRows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Décodage du tableau\n",
    "\n",
    "Attention: On suppose 1 seule strate '0' (Stratum), 1 seul échantillon '0' (Sample) et 1 seul estimateur '1' (Estimator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Suppression des colonnes Stratum, Sample et Estimator\n",
    "\n",
    "(puisqu'on se limite ici aux cas où il n'y a qu'1 de chaque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatRows.drop(columns=['Stratum', 'Sample', 'Estimator'], inplace=True)\n",
    "dfStatRows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Nettoyage des données sans objets\n",
    "\n",
    "(selon les notes descriptives des statistiques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Empilage des \"chiffres\" (Figures) Value, Cv, Lcl, Ucl, Df pour chaque statistique / module\n",
    "dfStats = dfStatRows.set_index(['Module', 'Statistic'], append=True).stack() \\\n",
    "                    .reset_index().rename(columns={'level_0': 'id', 'level_3': 'Figure', 0: 'Value'})\n",
    "dfStats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Fix multiple Module=2 & Statistic=3 rows (before joining with self.DfStatModSpecs)\n",
    "newStatNum = 200\n",
    "for lbl, sRow in dfStats[(dfStats.Module == 2) & (dfStats.Statistic == 3)].iterrows():\n",
    "    if dfStats.loc[lbl, 'Figure'] == 'Value':\n",
    "        newStatNum += 1\n",
    "    dfStats.loc[lbl, 'Statistic'] = newStatNum\n",
    "dfStats[(dfStats.Module == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des colonnes de description/nommage des modules et statistiques\n",
    "dfStats = dfStats.join(dfStatModSpecs, on=['Module', 'Statistic'])\n",
    "dfStats.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfStats[(dfStats.Module == 2) & (dfStats.Statistic > 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification que les chiffres sans objet le sont vraiment (tous à 0.0 ?)\n",
    "# Attention: Il doit y avoir un bug dans MCDS avec Module 2 / Statistic 10x : certains Cv ne sont pas nuls ...\n",
    "sKeepOnlyValueFig = ~dfStats.statNotes.str.contains('1')\n",
    "sFigs2Drop = (dfStats.Figure != 'Value') & sKeepOnlyValueFig\n",
    "assert ~dfStats[sFigs2Drop & ((dfStats.Module != 2) | (dfStats.Statistic < 100))].Value.any(), \\\n",
    "       'Attention: Des chiffres supposés \"sans objet\" on des valeurs non nulles !'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nde vérif. visuelle\n",
    "dfStats[sFigs2Drop & dfStats.Value != 0].sort_values(by='Value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des lignes / chiffres sans objet.\n",
    "dfStats.drop(dfStats[sFigs2Drop].index, inplace=True)\n",
    "dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStats = dfStats.reindex(columns=['modDesc', 'statDesc', 'Figure', 'Value'])\n",
    "dfStats.set_index(['modDesc', 'statDesc', 'Figure'], inplace=True)\n",
    "dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStats.T.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bac à sable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecimalFields = ['SMP_EFFORT', 'DISTANCE']\n",
    "\n",
    "ImportFieldAliasREs = \\\n",
    "    odict([('STR_LABEL', ['region', 'zone', 'strate', 'stratum']),\n",
    "           ('STR_AREA', ['surface', 'area', 'ha', 'km2']),\n",
    "           ('SMP_LABEL', ['point', 'lieu', 'location']),\n",
    "           ('SMP_EFFORT', ['effort', 'passages', 'surveys', 'samplings']),\n",
    "           ('DISTANCE', ['distance'])])\n",
    "\n",
    "def matchDataFields(srcFields):\n",
    "\n",
    "    print('Matching required data columns:', end=' ')\n",
    "\n",
    "    # Try and match required data columns.\n",
    "    matFields = list()\n",
    "    matDecFields = list()\n",
    "    for tgtField in ImportFieldAliasREs:\n",
    "        print(tgtField, end='=')\n",
    "        foundTgtField = False\n",
    "        for srcField in srcFields:\n",
    "            print(srcField, end=':')\n",
    "            for pat in ImportFieldAliasREs[tgtField]:\n",
    "                print(pat, end=';')\n",
    "                if re.search(pat, srcField, flags=re.IGNORECASE):\n",
    "                    print(srcField, end=', ')\n",
    "                    matFields.append(srcField)\n",
    "                    if tgtField in DecimalFields:\n",
    "                        matDecFields.append(srcField)\n",
    "                    foundTgtField = True\n",
    "                    break\n",
    "            if foundTgtField:\n",
    "                break\n",
    "        if not foundTgtField:\n",
    "            raise Exception('Error: Failed to find a match for expected {} in dataset columns {}' \\\n",
    "                            .format(tgtField, srcFields))\n",
    "\n",
    "    # Extra fields.\n",
    "    extFields = [field for field in srcFields if field not in matFields]\n",
    "\n",
    "    print('... success.')\n",
    "\n",
    "    return matFields, matDecFields, extFields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchDataFields(['Region*Label', 'Region*Area', 'Point transect*Label',\n",
    "       'Point transect*Survey effort', 'Observation*Radial distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = re.search('area', 'Region*Area', flags=re.IGNORECASE)\n",
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safeFloat2Str(val, prec=None, decPt='.'):\n",
    "    strVal = '' if pd.isnull(val) else str(val) if prec is None \\\n",
    "                else '{:.{prec}f}'.format(val, prec=prec)\n",
    "    if decPt != '.':\n",
    "        strVal = strVal.replace('.', decPt)\n",
    "    return strVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeFloat2Str(12.53, prec=None, decPt='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeFloat2Str(12.53, prec=1, decPt='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeFloat2Str(12.53, prec=4, decPt='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeFloat2Str(12.53, prec=None, decPt=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdTxt = ads.MCDSEngine.CmdTxt.format(output='output.txt', log='log.txt',\n",
    "                            stats='stats.txt', plots='plots.txt',\n",
    "                            survType='Point', distType='Radial',\n",
    "                            distUnit='m', areaUnit='ha',\n",
    "                            dataFields=', '.join(['a', 'b', 'c']), dataFileName='data.txt',\n",
    "                            estKeyFn='HNORMAL', estAdjustFn='COSINE',\n",
    "                            estCriterion='AIC', cvInterv=95)\n",
    "cmdTxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.MCDSEngine.CmdTxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending series to series ... index order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=pd.MultiIndex.from_tuples([('B', 'b'), ('B', 'a'), ('A', 'c')]), data=[1, 2, 3], name=0)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.append(pd.Series(index=[('A', 'b'), ('A', 'a'), ('B', 'c')], data=[1, 2, 3], name=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending series to DataFrame ... columns order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=pd.MultiIndex.from_tuples([('B', 'b'), ('B', 'a'), ('A', 'c')]), data=[1, 2, 3], name=0)\n",
    "#df = df.append(s, ignore_index=False) # => df.columns pas MultiIndex !\n",
    "df = df.append([s], ignore_index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('A', 'c'), ('B', 'b'), ('B', 'a')], data=[4, 5, 6], name=1)  # Mêmes colonnes : append ne retrie pas\n",
    "#s = pd.Series(index=[('A', 'a'), ('A', 'b'), ('B', 'c')], data=[4, 5, 6], name=1)  # Nouvelle colonne : append retrie\n",
    "df = df.append([s], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('A', 'a'), ('B', 'c')], data=[7, 8])\n",
    "df = df.append(s, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series(index=[], data=[])\n",
    "df = df.append([s], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('C', 'd')], data=[9])\n",
    "df = df.append([s], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('d',)], data=[10])\n",
    "df = df.append(s, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=pd.MultiIndex.from_tuples([('B', 'b'), ('B', 'a'), ('A', 'c')]), data=[1, 2, 3], name=0)\n",
    "df = pd.concat([df, s], axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('B', 'b'), ('B', 'a'), ('A', 'c')], data=[4, 5, 6], name=1) # Mêmes colonnes : concat ne retrie pas\n",
    "#s = pd.Series(index=[('A', 'a'), ('A', 'b'), ('B', 'c')], data=[4, 5, 6], name=1) # Nouvelle colonne : concat retrie\n",
    "df = pd.concat([df, s], axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Restore desired columns\n",
    "\n",
    "* desired order,\n",
    "* desired list of columns : new ones, and / or ignored ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new A/b, D/a and remove B/c and C/d\n",
    "i = pd.MultiIndex.from_tuples([('A', 'c'), ('A', 'b'), ('A', 'a'), ('B', 'b'), ('B', 'a'), ('D', 'a')])\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep added columns (with no data inside)\n",
    "df2 = df.reindex(i, axis='columns')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove added columns (with no data inside)\n",
    "df2 .dropna(how='all', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib as implib\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import OrderedDict as odict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autods as ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests unitaires et d'intégration module *autods*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classe DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = pd.DataFrame(columns=['Date', 'TrucDec', 'Espece', 'Point', 'Effort', 'Distance'],\n",
    "                      data=[('2019-05-13', 3.5, 'TURMER', 23, 2,   83),\n",
    "                            ('2019-05-15', np.nan, 'TURMER', 23, 2,   27.355),\n",
    "                            ('2019-05-13', 0, 'ALAARV', 29, 2,   56.85),\n",
    "                            ('2019-04-03', 1.325, 'PRUMOD', 53, 1.3,  7.2),\n",
    "                            ('2019-06-01', 2, 'PHICOL', 12, 1,  np.nan),\n",
    "                            ('2019-06-19', np.nan, 'PHICOL', 17, 0.5, np.nan),\n",
    "                           ])\n",
    "dfData['Region'] = 'ACDC'\n",
    "dfData['Surface'] = '2400'\n",
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ads.DataSet(dfData, decimalFields=['Effort', 'Distance', 'TrucDec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classes XXEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Instanciation et détection de Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'test out'))\n",
    "    print('Error: Should have raised an AssertionError !')\n",
    "except AssertionError as exc:\n",
    "    print('Good forbidden chars detection:', exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = eng.setupRunFolder(runPrefix='uni') # Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Génération fichier de données en entrée de MCDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataFileName = eng.buildDataFile(dataSet=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Génération fichier de \"commandes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmdFileName = eng.buildCmdFile(estimKeyFn='HNORMAL', estimAdjustFn='COSINE',\n",
    "                               estimCriterion='AIC', cvInterval=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### d. Execution en mode \"debug\"\n",
    "\n",
    "(génération des fichiers cmd et data, mais pas d'appel à l'exécutable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runCode, runDir = eng.run(ds, realRun=False, runPrefix='int',\n",
    "                          estimKeyFn='UNIFORM', estimAdjustFn='POLY',\n",
    "                          estimCriterion='AIC', cvInterval=95)\n",
    "assert runCode == 0, 'Should have NOT run (run code = 0)'\n",
    "runDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### e. Exécution réelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runCode, runDir = eng.run(ds, realRun=True, runPrefix='int',\n",
    "                          estimKeyFn='UNIFORM', estimAdjustFn='POLY',\n",
    "                          estimCriterion='AIC', cvInterval=95)\n",
    "assert runCode == 2, 'Should have run with warnings (run code = 2)'\n",
    "runDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Génération fichier de données en entrée pour Distance\n",
    "\n",
    "(mode 'point transect' uniquement pour le moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(eng.workDir, 'distance-in'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distDataFileName = \\\n",
    "    eng.buildDistanceDataFile(ds, tgtFilePathName=os.path.join(eng.workDir, 'distance-in', 'import-data-noextra.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distDataFileName = \\\n",
    "    eng.buildDistanceDataFile(ds, tgtFilePathName=os.path.join(eng.workDir, 'distance-in', 'import-data-withextra.txt'),\n",
    "                              withExtraFields=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. classe ResultsSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customCols = pd.MultiIndex.from_tuples([('id', 'index', 'Value'),\n",
    "                                        ('sample', 'species', 'Value'),\n",
    "                                        ('sample', 'periods', 'Value'),\n",
    "                                        ('sample', 'duration', 'Value'),\n",
    "                                        ('variant', 'precision', 'Value')])\n",
    "\n",
    "rs = ads.ResultsSet(analysisClass=ads.MCDSAnalysis, customColumns=customCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rs.dfData.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.MCDSAnalysis.EngineClass.statModColumns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests de validation module autods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MCDSEngine : Génération de fichiers d'entrée pour Distance\n",
    "\n",
    "* via un jeu de fichiers d'entrée bruts Excel, et leur export de référence, éprouvé dans Distance,\n",
    "* et comparaison du produit de XXEngine.buildDistanceDataFile à cette référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCase(object):\n",
    "    pass\n",
    "class TCDistance(TestCase):\n",
    "    def __init__(self, inFileName, decimalFields, withExtraFields, refOutFileName):\n",
    "        self.inFileName, self.decimalFields, self.withExtraFields, self.refOutFileName = \\\n",
    "            inFileName, decimalFields, withExtraFields, refOutFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCases = [TCDistance(inFileName='ALAARV-saisie-ttes-cols.xlsx', decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'],\n",
    "                        refOutFileName='ALAARV-saisie-5-cols.txt', withExtraFields=False),\n",
    "             TCDistance(inFileName='ALAARV-saisie-ttes-cols.xlsx', decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'],\n",
    "                        refOutFileName='ALAARV-saisie-ttes-cols.txt', withExtraFields=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails = 0\n",
    "for ind, tc in enumerate(testCases):\n",
    "    \n",
    "    print('#', ind, ':', tc.inFileName)\n",
    "\n",
    "    # Create data set\n",
    "    ds = ads.DataSet(dfData=pd.read_excel(os.path.join('AutoDS', 'refin', tc.inFileName)),\n",
    "                     decimalFields=tc.decimalFields)\n",
    "    \n",
    "    # Build distance import data file\n",
    "    ofn = os.path.join(eng.workDir, 'distance-in', tc.refOutFileName)\n",
    "    ofn = eng.buildDistanceDataFile(dataSet=ds, tgtFilePathName=ofn, withExtraFields=tc.withExtraFields)\n",
    "    \n",
    "    # Compare generated file to reference\n",
    "    rfn = os.path.join('AutoDS', 'refout', tc.refOutFileName)\n",
    "    with open(ofn, 'r') as fOut, open(rfn, 'r') as fRef:\n",
    "        if fOut.read() == fRef.read():\n",
    "            print('Success : Conform to reference.')\n",
    "        else:\n",
    "            print('Error: Generated file differs from reference', rfn)\n",
    "            fails += 1\n",
    "            \n",
    "    print()\n",
    "    \n",
    "print('All test cases succeeded !' if fails == 0 else 'Error: {} test case(s) failed.'.format(fails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MCDSEngine : Exécution avec de vraies données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ads.DataSet(dfData=pd.read_excel(os.path.join('AutoDS', 'refin', 'ALAARV-saisie-ttes-cols.xlsx')),\n",
    "                 decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'])\n",
    "\n",
    "eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'))\n",
    "\n",
    "runCode, runDir = eng.run(ds, realRun=True, runPrefix='int',\n",
    "                          estimKeyFn='UNIFORM', estimAdjustFn='POLY',\n",
    "                          estimCriterion='AIC', cvInterval=95)\n",
    "assert runCode == 2, 'Should have run with warnings (run code = 2)'\n",
    "runDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MCDSAnalysis : Analyse avec de vraies données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds = ads.DataSet(dfData=pd.read_excel(os.path.join('AutoDS', 'refin', 'ALAARV-saisie-ttes-cols.xlsx')),\n",
    "                 decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'])\n",
    "\n",
    "eng = ads.MCDSEngine(workDir=os.path.join('AutoDS', 'mcds-out'))\n",
    "\n",
    "anlys = ads.MCDSAnalysis(engine=eng, dataSet=ds, namePrefix='mcds',\n",
    "                         estimKeyFn='HNORMAL', estimAdjustFn='COSINE', estimCriterion='AIC', cvInterval=95)\n",
    "\n",
    "sRes = anlys.run()\n",
    "\n",
    "assert sRes[('run output', 'run status', 'Value')] == 2, 'Should have run with warnings (run code = 2)'\n",
    "sRes[('run output', 'files folder', 'Value')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sRes[('run output',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyses massives ACDC Papier 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraireJeuDonnees(dfTout, espece, passages=['A', 'B'], duree='10mn'):\n",
    "    \n",
    "    assert all(p in ['A', 'B'] for p in passages)\n",
    "    assert duree in ['5mn', '10mn']\n",
    "    assert espece in dfTout.ESPECE.unique()\n",
    "    \n",
    "    # Passages\n",
    "    dfJeu = dfTout[(dfTout.ESPECE == espece) & (dfTout.PASSAGE.isin(passages))].copy()\n",
    "    \n",
    "    # Durée\n",
    "    if duree == '10mn':\n",
    "        dfJeu['NOMBRE'] = dfJeu[['PER5MN', 'PER10MN']].sum(axis='columns')\n",
    "    else:\n",
    "        dfJeu['NOMBRE'] = dfJeu['PER5MN']\n",
    "    dfJeu.drop(dfJeu[dfJeu.NOMBRE.isnull()].index, inplace=True)\n",
    "    assert all(dfJeu.NOMBRE == 1)\n",
    "        \n",
    "    # Effort\n",
    "    dfJeu['EFFORT'] = len(passages)\n",
    "        \n",
    "    # Nettoyage\n",
    "    dfJeu.drop(['PER5MN', 'PER10MN'], axis='columns', inplace=True)\n",
    "    \n",
    "    return dfJeu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajouterAbsences(dfJeu, effort, pointsPapier):\n",
    "    \n",
    "    assert not dfJeu.empty, 'Erreur : Il n\\'y aurait que des absences !'\n",
    "\n",
    "    zone, surface, espece = dfJeu.iloc[0][['ZONE', 'HA', 'ESPECE']]\n",
    "    dAbsence = { 'ZONE': zone, 'HA': surface, 'POINT': None, 'ESPECE': espece,\n",
    "                 'DISTANCE': np.nan, 'EFFORT': effort, 'MALE': None,\n",
    "                 'NOMBRE': np.nan, 'DATE': pd.NaT, 'OBSERVATEUR': None, 'PASSAGE': None }\n",
    "\n",
    "    pointsManquants = [p for p in pointsPapier if p not in dfJeu.POINT.unique()]\n",
    "    for p in pointsManquants:\n",
    "        dAbsence.update(POINT=p)\n",
    "        dfJeu = dfJeu.append(dAbsence, ignore_index=True)\n",
    "    \n",
    "    dfJeu.sort_values(by=['POINT'], inplace=True)\n",
    "\n",
    "    return dfJeu, len(pointsManquants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres généraux.\n",
    "workDir = os.path.join('AutoDS', 'acdc-auto')\n",
    "runEngine = True # Pas d'appel à l'exe si False, juste pour les fichiers d'entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tous les points effectués (pour absences).\n",
    "pointsPapier = \\\n",
    "    list(map(int, \"\"\"23,39,40,41,42,55,56,57,58,59,60,72,73,74,75,76,88,89,90,91,\n",
    "                     105,106,109,110,112,113,122,123,125,126,127,128,129,130,141,142,143,144,145,146,\n",
    "                     147,148,157,158,159,160,161,162,163,164,165,166,174,175,176,177,178,179,180,181,\n",
    "                     182,183,184,185,192,193,194,195,196,197,198,199,200,201,202,210,211,212,213,214,\n",
    "                     215,216,218,219,228,229,232,233,245,246,247,250,262,263,265,266,280,281,282,283,\n",
    "                     284,299,300,301\"\"\".split(',')))\n",
    "\n",
    "# Données brutes saisies par les observateurs, déjà individualisées, que les mâles.\n",
    "ficDonnees = os.path.join('AutoDS', 'refin', 'ACDC2019-Papyrus-DonneesBrutesPourAutoDS.xlsx')\n",
    "\n",
    "dfMales = pd.read_excel(ficDonnees, sheet_name='ResultIndivMales')\n",
    "dfMales.rename(columns={ 'ha': 'HA', 'Distance en m': 'DISTANCE', 'Mâle\\xa0?': 'MALE', 'Date': 'DATE',\n",
    "                         'Période': 'PASSAGE', '0-5mn': 'PER5MN', '5-10 mn': 'PER10MN' }, inplace=True)\n",
    "\n",
    "assert all(dfMales.MALE.str.lower() == 'oui')\n",
    "\n",
    "print('Nb mâles   :', len(dfMales))\n",
    "print('Nb espèces :', len(dfMales.ESPECE.unique()))\n",
    "\n",
    "# Les espèces et passages à traiter.\n",
    "dfToDo = pd.read_excel(ficDonnees, sheet_name='AFaire')\n",
    "toDoCols = ['ESPECE', 'MALES', 'PERIODE']\n",
    "assert all(col in dfToDo.columns for col in toDoCols)\n",
    "dfToDo = dfToDo.reindex(toDoCols, axis='columns')\n",
    "dfToDo.sort_values(by='MALES', ascending=False, inplace=True)\n",
    "\n",
    "print('Espèces à traiter :', len(dfToDo))\n",
    "\n",
    "# Les paramètres de toutes les analyses à faire à chaque fois.\n",
    "dfParams = pd.read_excel(ficDonnees, sheet_name='ParamsAnalyses')\n",
    "paramCols = ['KeyFn', 'AdjustFn', 'Criterion', 'CVInterval']\n",
    "assert all(col in paramCols for col in dfParams.columns)\n",
    "dfParams = dfParams.reindex(paramCols, axis='columns')\n",
    "\n",
    "print('Variantes d\\'analyses :', len(dfParams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = implib.reload(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToDo[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Le moteur\n",
    "mcds = ads.MCDSEngine(workDir=workDir,\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Point', distanceType='Radial')\n",
    "\n",
    "# Les résultats d'analyse\n",
    "miCustColumns = pd.MultiIndex.from_tuples([('id', 'index', 'Value'),\n",
    "                                           ('sample', 'species', 'Value'),\n",
    "                                           ('sample', 'periods', 'Value'),\n",
    "                                           ('sample', 'duration', 'Value'),\n",
    "                                           ('variant', 'precision', 'Value')])\n",
    "resultats = ads.ResultsSet(analysisClass=ads.MCDSAnalysis, customColumns=miCustColumns)\n",
    "\n",
    "#Pour chaque espèce à traiter\n",
    "for index, sToDo in dfToDo[:2].iterrows():\n",
    "\n",
    "    espece, nbIndivs, passage = sToDo\n",
    "    passages = [p for p in passage]\n",
    "\n",
    "    # Pour les 2 durées d'inventaire (sur chaque point)\n",
    "    for duree in ['5mn', '10mn']:\n",
    "\n",
    "        # Sélection des données\n",
    "        dfJeu = extraireJeuDonnees(dfMales, espece, passages, duree)\n",
    "        nMales = len(dfJeu)\n",
    "\n",
    "        # Ajout des lignes d'absence\n",
    "        dfJeu, nAbsences = ajouterAbsences(dfJeu, effort=len(passages), pointsPapier=pointsPapier)\n",
    "\n",
    "        # Pour chaque précision numérique sur la distance (en décroissant)\n",
    "        for precDist in [None, 1]:\n",
    "            \n",
    "            print(espece, passage, duree, ':', nMales, 'mâles,', nAbsences, 'absences')\n",
    "\n",
    "            # Arrondi à la précision.\n",
    "            if precDist is not None:\n",
    "                dfJeu.DISTANCE = dfJeu.DISTANCE.apply(round, ndigits=precDist)\n",
    "            \n",
    "            # Voici donc le jeu de données\n",
    "            jeu = ads.DataSet(dfJeu, decimalFields=['EFFORT', 'DISTANCE', 'NOMBRE'])\n",
    "            \n",
    "            # Pour chaque jeu de paramètres d'analyse\n",
    "            for index, sParams in dfParams.iterrows():\n",
    "\n",
    "                precision = ('tt' if precDist is None else str(precDist)) + 'dec'\n",
    "                prfxAnalyse = '{}-{}-{}-{}-{}'.format(espece, duree, passage, precision, index)\n",
    "                analyse = ads.MCDSAnalysis(engine=mcds, dataSet=jeu, namePrefix=prfxAnalyse,\n",
    "                                           estimKeyFn=sParams['KeyFn'], estimAdjustFn=sParams['AdjustFn'],\n",
    "                                           estimCriterion=sParams['Criterion'], cvInterval=sParams['CVInterval'])\n",
    "\n",
    "                sEntete = pd.Series(data=[index, espece, passage, duree, precision], index=miCustColumns)\n",
    "                \n",
    "                sResultat = analyse.run(realRun=runEngine)\n",
    "                \n",
    "                resultats.append(sCustom=sEntete, sResult=sResultat)\n",
    "                                \n",
    "                #raise StopIteration()\n",
    "                \n",
    "            print()\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "resultats.dfData.to_excel(os.path.join(workDir, 'ACDC2019-Papyrus-ResultatsAutoAnalyses.xlsx'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats.dfData.to_excel(os.path.join(workDir, 'ACDC2019-Papyrus-ResultatsAutoAnalyses.xlsx'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultats.dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise au point décodage sorties de MCDS : fichier de stats\n",
    "\n",
    "TODO: Add french translation of variables / parameters names and descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nom et description des colonnes du tableau de stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'mcds-stat-row-specs.txt'\n",
    "\n",
    "fStatRowSpecs = open(fileName, mode='r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statRowSpecLines = [line.rstrip('\\n') for line in fStatRowSpecs.readlines() if not line.startswith('#')]\n",
    "statRowSpecs =  [(statRowSpecLines[i].strip(), statRowSpecLines[i+1].strip()) \\\n",
    "                 for i in range(0, len(statRowSpecLines)-2, 3)]\n",
    "dfStatRowSpecs = pd.DataFrame(columns=['Name', 'Description'], data=statRowSpecs).set_index('Name')\n",
    "\n",
    "dfStatRowSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatRowSpecs.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numéro et description des modules et statistiques associées\n",
    "\n",
    "(colonnes Module et Statistic du tableau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'mcds-stat-mod-specs.txt'\n",
    "\n",
    "fStatModSpecs = open(fileName, mode='r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nMaxAdjParams = 10\n",
    "\n",
    "statModSpecLines = [line.rstrip('\\n') for line in fStatModSpecs.readlines() if not line.startswith('#')]\n",
    "reModSpecNumName = re.compile('(.+) – (.+)')\n",
    "statModSpecs = list()\n",
    "moModule = None\n",
    "for line in statModSpecLines:\n",
    "    if not line:\n",
    "        continue\n",
    "    if moModule is None:\n",
    "        moModule = reModSpecNumName.match(line.strip())\n",
    "        continue\n",
    "    if line == ' ':\n",
    "        moModule = None\n",
    "        continue\n",
    "    moStatistic = reModSpecNumName.match(line.strip())\n",
    "    modNum, modDesc, statNum, statDescNotes = \\\n",
    "        moModule.group(1), moModule.group(2), moStatistic.group(1), moStatistic.group(2)\n",
    "    for i in range(len(statDescNotes)-1, -1, -1):\n",
    "        if not re.match('[\\d ,]', statDescNotes[i]):\n",
    "            statDesc = statDescNotes[:i+1]\n",
    "            statNotes = statDescNotes[i+1:].replace(' ', '')\n",
    "            break\n",
    "    modNum = int(modNum)\n",
    "    if statNum.startswith('101 '):\n",
    "        for num in range(nMaxAdjParams): # Assume no more than that ... a bit hacky !\n",
    "            statModSpecs.append((modNum, modDesc, 101+num, # Make statDesc unique for later indexing\n",
    "                                 statDesc.replace('each', 'A({})'.format(num+1)), statNotes))\n",
    "    else:\n",
    "        statNum = int(statNum)\n",
    "        if modNum == 2 and statNum == 3: # Actually, there are 0 or 3 of these ...\n",
    "            for num in range(3):\n",
    "                statModSpecs.append((modNum, modDesc, num+201,\n",
    "                                     # Change statNum & Make statDesc unique for later indexing\n",
    "                                     statDesc+' (distance set {})'.format(num+1), statNotes))\n",
    "        else:\n",
    "            statModSpecs.append((modNum, modDesc, statNum, statDesc, statNotes))\n",
    "dfStatModSpecs = pd.DataFrame(columns=['modNum', 'modDesc', 'statNum', 'statDesc', 'statNotes'],\n",
    "                              data=statModSpecs).set_index(['modNum', 'statNum'])\n",
    "\n",
    "dfStatModSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "dfStatModSpecs.modDesc.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Notes sur les statistiques des modules\n",
    "\n",
    "(infos supplémentaire indiquant comment utiliser ou pas les 5 dernières colonnes Value, Cv, Lcl, Ucl, Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'mcds-stat-mod-notes.txt'\n",
    "\n",
    "fStatModNotes = open(fileName, mode='r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statModNoteLines = [line.rstrip('\\n') for line in fStatModNotes.readlines() if not line.startswith('#')]\n",
    "statModNotes =  [(int(line[:2]), line[2:].strip()) for line in statModNoteLines if line]\n",
    "\n",
    "dfStatModNotes = pd.DataFrame(data=statModNotes, columns=['Note', 'Text']).set_index('Note')\n",
    "\n",
    "dfStatModNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lecture du tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = mcds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.statsFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatRows = pd.read_csv(eng.statsFileName, sep=' +', engine='python', names=dfStatRowSpecs.index)\n",
    "dfStatRows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Décodage du tableau\n",
    "\n",
    "Attention: On suppose 1 seule strate '0' (Stratum), 1 seul échantillon '0' (Sample) et 1 seul estimateur '1' (Estimator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Suppression des colonnes Stratum, Sample et Estimator\n",
    "\n",
    "(puisqu'on se limite ici aux cas où il n'y a qu'1 de chaque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStatRows.drop(columns=['Stratum', 'Sample', 'Estimator'], inplace=True)\n",
    "dfStatRows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Nettoyage des données sans objets\n",
    "\n",
    "(selon les notes descriptives des statistiques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Empilage des \"chiffres\" (Figures) Value, Cv, Lcl, Ucl, Df pour chaque statistique / module\n",
    "dfStats = dfStatRows.set_index(['Module', 'Statistic'], append=True).stack() \\\n",
    "                    .reset_index().rename(columns={'level_0': 'id', 'level_3': 'Figure', 0: 'Value'})\n",
    "dfStats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Fix multiple Module=2 & Statistic=3 rows (before joining with self.DfStatModSpecs)\n",
    "newStatNum = 200\n",
    "for lbl, sRow in dfStats[(dfStats.Module == 2) & (dfStats.Statistic == 3)].iterrows():\n",
    "    if dfStats.loc[lbl, 'Figure'] == 'Value':\n",
    "        newStatNum += 1\n",
    "    dfStats.loc[lbl, 'Statistic'] = newStatNum\n",
    "dfStats[(dfStats.Module == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des colonnes de description/nommage des modules et statistiques\n",
    "dfStats = dfStats.join(dfStatModSpecs, on=['Module', 'Statistic'])\n",
    "dfStats.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfStats[(dfStats.Module == 2) & (dfStats.Statistic > 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification que les chiffres sans objet le sont vraiment (tous à 0.0 ?)\n",
    "# Attention: Il doit y avoir un bug dans MCDS avec Module 2 / Statistic 10x : certains Cv ne sont pas nuls ...\n",
    "sKeepOnlyValueFig = ~dfStats.statNotes.str.contains('1')\n",
    "sFigs2Drop = (dfStats.Figure != 'Value') & sKeepOnlyValueFig\n",
    "assert ~dfStats[sFigs2Drop & ((dfStats.Module != 2) | (dfStats.Statistic < 100))].Value.any(), \\\n",
    "       'Attention: Des chiffres supposés \"sans objet\" on des valeurs non nulles !'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nde vérif. visuelle\n",
    "dfStats[sFigs2Drop & dfStats.Value != 0].sort_values(by='Value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des lignes / chiffres sans objet.\n",
    "dfStats.drop(dfStats[sFigs2Drop].index, inplace=True)\n",
    "dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStats = dfStats.reindex(columns=['modDesc', 'statDesc', 'Figure', 'Value'])\n",
    "dfStats.set_index(['modDesc', 'statDesc', 'Figure'], inplace=True)\n",
    "dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStats.T.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bac à sable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending series to Series ... index order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=pd.MultiIndex.from_tuples([('B', 'b'), ('B', 'a'), ('A', 'c')]), data=[1, 2, 3], name=0)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.append(pd.Series(index=[('A', 'b'), ('A', 'a'), ('B', 'c')], data=[1, 2, 3], name=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending series to DataFrame ... columns order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=pd.MultiIndex.from_tuples([('B', 'b'), ('B', 'a'), ('A', 'c')]), data=[1, 2, 3], name=0)\n",
    "#df = df.append(s, ignore_index=False) # => df.columns pas MultiIndex !\n",
    "df = df.append([s], ignore_index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('A', 'c'), ('B', 'b'), ('B', 'a')], data=[4, 5, 6], name=1)  # Mêmes colonnes : append ne retrie pas\n",
    "#s = pd.Series(index=[('A', 'a'), ('A', 'b'), ('B', 'c')], data=[4, 5, 6], name=1)  # Nouvelle colonne : append retrie\n",
    "df = df.append([s], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('A', 'a'), ('B', 'c')], data=[7, 8])\n",
    "df = df.append(s, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series(index=[], data=[])\n",
    "df = df.append([s], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('C', 'd')], data=[9])\n",
    "df = df.append([s], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('d',)], data=[10])\n",
    "df = df.append(s, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=pd.MultiIndex.from_tuples([('B', 'b'), ('B', 'a'), ('A', 'c')]), data=[1, 2, 3], name=0)\n",
    "df = pd.concat([df, s], axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(index=[('B', 'b'), ('B', 'a'), ('A', 'c')], data=[4, 5, 6], name=1) # Mêmes colonnes : concat ne retrie pas\n",
    "#s = pd.Series(index=[('A', 'a'), ('A', 'b'), ('B', 'c')], data=[4, 5, 6], name=1) # Nouvelle colonne : concat retrie\n",
    "df = pd.concat([df, s], axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Restore desired columns order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = pd.MultiIndex.from_tuples([('C', 'd'), ('A', 'c'), ('A', 'a'), ('B', 'c'), ('B', 'b'), ('B', 'a')])\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex(i, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Auto table of contents -->\n",
    "<h1 class='tocIgnore'>Visionature : DS via points d'écoute printaniers</h1>\n",
    "<p>N.B. A partir de la version 0.9.2 (22/01/2022), pyaudisam peut-être utilisé en ligne de commande pour rendre\n",
    "   les mêmes services que ce Notebook à partir du chapitre <a href=\"#XII.-Chargement-des-donn%C3%A9es-pr%C3%AAtes-pour-l'analyse-DS\">XII</a> (exemple: Cf. <a href=\"./donnees/acdc/acdc-2019-ds-params.py\">acdc-2019-ds-params.py</a>).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import pathlib as pl\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.api.types as pdt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment-out to use \"official\" site-packages pyaudisam version.\n",
    "sys.path.insert(0, '../pyaudisam')  # Or not ... to use local  development tree\n",
    "\n",
    "import pyaudisam as ads\n",
    "\n",
    "print('pyaudisam', ads.__version__, 'from', pl.Path(ads.__path__[0]).resolve().as_posix())\n",
    "\n",
    "ads.runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory if not yet done.\n",
    "tmpDir = pl.Path('tmp')\n",
    "tmpDir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration.\n",
    "ads.log.configure(handlers=[sys.stdout, tmpDir / 'vndspt.log'], reset=True,\n",
    "                  loggers=[dict(name='matplotlib', level=ads.WARNING),\n",
    "                           dict(name='ads', level=ads.INFO2),\n",
    "                           dict(name='ads.eng', level=ads.INFO),\n",
    "                           dict(name='ads.exr', level=ads.INFO),\n",
    "                           #dict(name='ads.dat', level=ads.DEBUG),\n",
    "                           #dict(name='ads.rep', level=ads.DEBUG),\n",
    "                           dict(name='ads.anr', level=ads.DEBUG1),\n",
    "                           dict(name='ads.onr', level=ads.DEBUG),\n",
    "                           dict(name='visionat', level=ads.INFO),\n",
    "                           dict(name='geocarto', level=ads.INFO),\n",
    "                           dict(name='vndspt', level=ads.DEBUG)])\n",
    "\n",
    "logger = ads.logger('vndspt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup(fpn, to='.', tsFmt='.%y%m%d'):\n",
    "    \"\"\"Backup given file to target folder with custom-formatted timestamp in name\"\"\"\n",
    "    fpn = pl.Path(fpn)\n",
    "    tn = fpn.stem + pd.Timestamp.now().strftime(tsFmt) + fpn.suffix\n",
    "    tp = pl.Path(to) if to != '.' else fpn.parent\n",
    "    logger.info('Backing up to ' + (tp / tn).as_posix())\n",
    "    shutil.copy(fpn, tp / tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Paramètres de l'étude : import / filtrage des données, ...\n",
    "\n",
    "* fichier source provenant d'un export VisioNature,\n",
    "* source Faune France ou Faune Auvergne (avec éventuellement qq colonnes en plus préparées ailleurs)\n",
    "* colonnes à conserver, ignorer, renommer,\n",
    "* lignes à ignorer\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par défaut.\n",
    "# a. VisionatureDataSet\n",
    "feuille = 0\n",
    "source = 'FA' # Faune-Auvergne\n",
    "ignorerLignes = []\n",
    "\n",
    "colLongTrace = None\n",
    "avecTraces = False\n",
    "\n",
    "renommerCols = dict()\n",
    "calculerCols = dict()\n",
    "\n",
    "colEspece = 'Espèce'\n",
    "colPassage = 'Passage'\n",
    "colDistance = 'Distance'\n",
    "\n",
    "garderCols = ['ID liste', 'Liste complète ?', 'Commentaire de la liste',\n",
    "              'Date', 'Ref', 'Horaire', 'Lieu-dit', 'Commune', colEspece,\n",
    "              'Estimation', 'Nombre', 'Détails', 'Code atlas',\n",
    "              'Lat (WGS84)', 'Lon (WGS84)', 'Remarque']\n",
    "garderColsListes = []\n",
    "\n",
    "dCategoriesImbriquees = dCategoriesImbriqueesTout = dict()\n",
    "\n",
    "# b. Pour simple affichage\n",
    "obsBrutesColsAff = ['Date', 'ID liste', 'Point', 'Ref', 'Horaire', colEspece, 'Nombre', 'Détails', 'Code atlas']\n",
    "comptesColsAff = ['nMalAd', 'nAutAd', 'nJuv', 'nVol']\n",
    "\n",
    "# c. FieldDataSet\n",
    "inventaireCols = ['Observateur', 'ID liste', 'Date', colPassage, 'Point']\n",
    "\n",
    "effectifCols = ['nMalAd', 'nAutAd']  # Colonnes d'effectifs à prendre en compte (on ignore les autres)\n",
    "\n",
    "def categorieAdulte(sEffectifs):  # Calcul catégorie \"Adulte\" = _m_âle ou _a_utre.\n",
    "    return 'm' if 'Mal' in sEffectifs[sEffectifs > 0].index[0] else 'a'\n",
    "\n",
    "ajouterMonoCatCols = dict(Adulte=categorieAdulte)\n",
    "\n",
    "obsIndivCols = ['Observateur', 'ID liste', 'Date', colPassage, 'Point',\n",
    "                'Ref', 'Horaire', colEspece, 'Adulte', colDistance]\n",
    "\n",
    "# d. Analyse DS\n",
    "distanceUnit = 'Meter'\n",
    "areaUnit = 'Sq. Kilometer'\n",
    "surveyType = 'Point'\n",
    "distanceType = 'Radial'\n",
    "\n",
    "groupage = False\n",
    "colEffort = 'Effort'\n",
    "effortConst = 1 # Valeur d'effort constante = 1 par passage sur chaque point.\n",
    "colsSpeSelEchant = ['Adulte']  # Colonnes de sélection des échantillons : en plus de Espèce et Passage. \n",
    "\n",
    "# e. Carto, rapports d'analyses ...\n",
    "nomEtude = None\n",
    "sousEtude = ''\n",
    "fusionnerSousEtudes = []\n",
    "titreEtude = None\n",
    "descrEtude = '<pas de description>'\n",
    "motsClesEtude = ''\n",
    "\n",
    "# f. Divers\n",
    "\n",
    "# Fin de Par défaut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACDC 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commun à toutes les sous études ACDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossier = pl.Path('donnees/acdc')\n",
    "\n",
    "# a. VisionatureDataSet et stats échantillons\n",
    "\n",
    "def categoriesDuree(sObs):\n",
    "    return ['10mn'] if sObs['Minute'] >= 5 else ['5mn', '10mn']\n",
    "dCategoriesImbriquees = {'Durée': categoriesDuree}\n",
    "dCategoriesImbriqueesTout = {'Durée': '10mn'}\n",
    "\n",
    "# d. Analyse DS\n",
    "distanceUnit = 'Meter'\n",
    "areaUnit = 'Sq. Kilometer'\n",
    "surveyType = 'Point'\n",
    "distanceType = 'Radial'\n",
    "\n",
    "dZoneEtude = dict(Zone='ACDC', Surface=24) # km2\n",
    "colsSpeSelEchant = ['Adulte', 'Durée']  # Colonnes de sélection des échantillons : en plus de Espèce et Passage. \n",
    "\n",
    "# e. Carto, rapports d'analyses ...\n",
    "nomEtude = 'ACDC2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Naturalist\n",
    "\n",
    "(source : exports FA individuels rassemblés, nettoyés, filtrés et enrichis des colonnes 'Passage', 'Point', 'Minute'\n",
    " via [NB ACDC-donnees-Naturalist](./ACDC-donnees-Naturalist.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. VisionatureDataSet\n",
    "\n",
    "# Exports FA individuels rassemblés, nettoyés, filtrés et enrichis des colonnes 'Passage', 'Point', 'Minute'\n",
    "# via NB ACDC-donnees-naturalist.\n",
    "ficSrcVN = [dossier / 'ACDC2019-Naturalist-ObsBrutesNettoyees.xlsx']\n",
    "\n",
    "source = 'FA' # Faune-Auvergne\n",
    "avecTraces = False\n",
    "\n",
    "renommerCols = {'Nom latin': colEspece}  # Attention : 'Nom scientifique' sur FF\n",
    "\n",
    "def idObservateur(sObs):\n",
    "    return sObs['Prénom'] + ' ' + sObs['Nom']\n",
    "def minuteDInventaire(sObs):\n",
    "    dateHeure = dt.datetime.combine(sObs['Date'].date(), dt.time.fromisoformat(sObs['Horaire']))\n",
    "    return (dateHeure - sObs['Heure début']).total_seconds() / 60\n",
    "calculerCols = dict(Observateur=idObservateur, Minute=minuteDInventaire)\n",
    "\n",
    "garderCols += ['Minute']\n",
    "garderColsListes = ['Observateur', colPassage, 'Point']\n",
    "\n",
    "# b. Divers pour simple affichage\n",
    "obsBrutesColsAff = ['Observateur', colPassage] + obsBrutesColsAff\n",
    "\n",
    "# c. FieldDataSet\n",
    "inventaireCols = ['Observateur', 'ID liste', 'Date', colPassage, 'Point']\n",
    "obsIndivCols = ['Observateur', 'ID liste', 'Date', colPassage, 'Durée',\n",
    "                'Ref', 'Point', 'Horaire', colEspece, 'Adulte', colDistance]\n",
    "\n",
    "# e. Carto, rapports d'analyses ...\n",
    "sousEtude = '-Nat'\n",
    "titreEtude = 'ACDC 2019 Naturalist'\n",
    "descrEtude = \"Estimation des populations d'oiseaux du plateau de Cournols - Olloix - Montaigut-le-Blanc en 2019\" \\\n",
    "             \" par points d'écoute Distance Sampling sur smartphone (mêmes points que pour l'étude Papyrus)\"\n",
    "motsClesEtude = 'ACDC, Cournols, Olloix, 2019, DS, Naturalist, Smartphone'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[XII. Chargement des données prêtes pour l'analyse DS](#XII.-Chargement-des-donn%C3%A9es-pr%C3%AAtes-pour-l'analyse-DS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XII. Chargement des données prêtes pour l'analyse DS\n",
    "\n",
    "Pour éviter de tout refaire, exécuter d'abord (et seulement) tout jusqu'à I. inclus, avant ce qui suit.\n",
    "\n",
    "Attention: Dans ce cas, on observe parfois des différences (minimes) sur les distances observateur - oiseau,\n",
    "           avec arrondi des 1, 2 ou 3 derniers chiffres significatifs (lors du passage dans Excel) ;\n",
    "           ce qui correspond, pour des distances <= 1000m, à 10^-14m ... pas très grave ;-)\n",
    "           \n",
    "<p>N.B. A partir de la version 0.9.2 (22/01/2022), pyaudisam peut-être utilisé en ligne de commande pour rendre\n",
    "   exactement les mêmes services que ceux des chapitres qui suivent (exemple: Cf. <a href=\"./donnees/acdc/acdc-2019-ds-params.py\">acdc-2019-ds-params.py</a>).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn = dossier / f'{nomEtude}{sousEtude}-ObsIndivDist.xlsx'\n",
    "with pd.ExcelFile(fpn) as xlsFile:\n",
    "    dfObsCatIndiv = pd.read_excel(xlsFile, sheet_name='Donnees')\n",
    "    dfTransects = pd.read_excel(xlsFile, sheet_name='Inventaires')\n",
    "\n",
    "print(dict(etude=nomEtude+sousEtude, donnees=len(dfObsCatIndiv), inventaires=len(dfTransects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsCatIndiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Annexe. Bilan & stats données individualisées](#Annexe.-Bilan-%26-stats-donn%C3%A9es-individualis%C3%A9es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XIII. Sélection des échantillons pour analyses DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes de sélection des échantillons réellement présentes dans dfObsCatIndiv\n",
    "samplingCols = [colEspece, colPassage] + colsSpeSelEchant\n",
    "samplingCols = [col for col in samplingCols if col in dfObsCatIndiv.columns]\n",
    "\n",
    "samplingCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Examen des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsCatIndiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonSpeciesSamplingCols = [col for col in samplingCols if col != colEspece]\n",
    "nonSpeciesSamplingCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'individus par espèce, pour voir quelles espèces on va analyser\n",
    "if groupage: # Clustering lors des analyses DS\n",
    "    \n",
    "    # Attention : Non testé encore !\n",
    "    dfNObsCatIndiv = dfObsCatIndiv[samplingCols + ['Nombre']].groupby(samplingCols).sum()\n",
    "    dfNObsCatIndiv.rename(columns=dict(Nombre='Individus'), inplace=True)\n",
    "    \n",
    "else: # Pas de clustering.\n",
    "    \n",
    "    dfNObsCatIndiv = dfObsCatIndiv[samplingCols + [colDistance]].groupby(samplingCols).count()\n",
    "    dfNObsCatIndiv.rename(columns=dict(Distance='Individus'), inplace=True)\n",
    "\n",
    "dfNObsCatIndiv.reset_index(inplace=True)\n",
    "\n",
    "dfNObsCatIndiv.sort_values(by='Individus', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choix des variantes\n",
    "\n",
    "**Attention** : Variantes \"Passage\" : Présence obligatoire pour les pré-analyses et analyses, même si 1 seul passage !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "variants = dict()  # Clef = nom des catégories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats pour décider : Nombres d'individus contactés par espèce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des effectifs totaux.\n",
    "dfNObsTotIndiv = dfNObsCatIndiv\n",
    "if dCategoriesImbriqueesTout:  # Attention aux catégories imbriquées : données dupliquées exprès !\n",
    "    for colCat, valTout in dCategoriesImbriqueesTout.items():\n",
    "        dfNObsTotIndiv = dfNObsTotIndiv[dfNObsTotIndiv[colCat] == valTout]\n",
    "dfNObsTotIndiv = dfNObsTotIndiv[[colEspece, 'Individus']].groupby(colEspece).sum() \\\n",
    "                    .sort_values(by='Individus', ascending=False)\n",
    "\n",
    "dfNObsTotIndiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNObsTotIndiv[dfNObsTotIndiv.Individus >= 60].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ou : Les espèces avec au moins N individus contactés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les espèces avec un minimum d'individus observés ...\n",
    "nMinTotIndivs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants[colEspece] = list(dfNObsTotIndiv[dfNObsTotIndiv.Individus >= nMinTotIndivs].index)\n",
    "print(len(variants[colEspece]), ', '.join(variants[colEspece]))\n",
    "\n",
    "variants['Adulte'] = ['m', 'm+a']\n",
    "\n",
    "variants[colPassage] = [''] # Tous les passages ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ou : Les N espèces les plus notées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les N les plus notées ...\n",
    "nPlusTotIndivs = 22\n",
    "\n",
    "variants[colEspece] = list(dfNObsTotIndiv.index[:nPlusTotIndivs])\n",
    "print(len(variants[colEspece]), ', '.join(variants[colEspece]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ou : ACDC 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les espèces avec au moins 27 mâles contactés dans les 10mn\n",
    "#nMinMal10 = 27 # Comme ACDC 2019 Papyrus\n",
    "#\n",
    "#dfNObsMal10 = dfNObsCatIndiv[dfNObsCatIndiv.Adulte == 'm']\n",
    "#if dCategoriesImbriqueesTout:  # Attention aux catégories imbriquées : données dupliquées exprès !\n",
    "#    for colCat, valTout in dCategoriesImbriqueesTout.items():\n",
    "#        dfNObsMal10 = dfNObsMal10[dfNObsMal10[colCat] == valTout]\n",
    "#\n",
    "#dfNObsMal10 = dfNObsMal10[[colEspece, 'Individus']].groupby(colEspece).sum() \\\n",
    "#                  .sort_values(by='Individus', ascending=False)\n",
    "#\n",
    "#variants[colEspece] = list(dfNObsMal10[dfNObsMal10.Individus >= nMinMal10].index)\n",
    "#print(', '.join(variants[colEspece]), '=>', len(variants[colEspece]), 'espèces')\n",
    "#\n",
    "#dfNObsMal10.head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitement : ... en gros les 30 espèces les plus notées et analysables en DS\n",
    "variants[colEspece] = ['Sylvia atricapilla', 'Turdus merula', 'Alauda arvensis', 'Sylvia communis',\n",
    "                       'Columba palumbus', 'Luscinia megarhynchos', 'Cuculus canorus', 'Fringilla coelebs',\n",
    "                       'Phylloscopus collybita', 'Parus major', 'Lullula arborea', 'Emberiza cirlus',\n",
    "                       'Erithacus rubecula', 'Saxicola rubicola', 'Emberiza citrinella', 'Cyanistes caeruleus',\n",
    "                       'Turdus philomelos', 'Emberiza calandra', 'Turdus viscivorus', 'Prunella modularis',\n",
    "                       'Phylloscopus bonelli', 'Carduelis cannabina', 'Jynx torquilla', 'Carduelis chloris',\n",
    "                       'Anthus trivialis', 'Upupa epops', 'Lanius collurio', 'Oriolus oriolus',\n",
    "                       'Streptopelia turtur', 'Dendrocopos major']\n",
    "print(len(variants[colEspece]), 'espèces =>', ', '.join(variants[colEspece]))\n",
    "\n",
    "variants[colPassage] = ['b', 'a+b'] # Passage b ou a+b => 2 variantes\n",
    "\n",
    "variants['Durée'] = ['5mn', '10mn'] # 5 1ères mn, ou toutes les 10 => 2 variantes\n",
    "\n",
    "variants['Adulte'] = ['m', 'm+a'] # Les mâles, et ensuite les mâles et autres adultes (=> 2 variantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour info ... et action ? Liste complémentaire (à + de 20 individus) pour Nat+Pap\n",
    "compltNatPap = ['Corvus corone', 'Garrulus glandarius', 'Troglodytes troglodytes',  'Pica pica',\n",
    "                'Picus viridis', 'Hippolais polyglotta', 'Carduelis carduelis', 'Certhia brachydactyla',\n",
    "                'Sylvia borin', 'Coturnix coturnix']\n",
    "exclusNatPap = ['Sturnus vulgaris', 'Streptopelia decaocto', 'Sturnus vulgaris', 'Streptopelia decaocto', ]\n",
    "\n",
    "# N.B. Non encore utilisé ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spec. implicite des variantes\n",
    "\n",
    "=> combinaisons à générer automatiquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dImplSampleSpecs = variants\n",
    "dImplSampleSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilitaire : génération du fichier de specs (implicite) correspondant\n",
    "# nSampSpecRows = max(len(vals) for vals in dImplSampleSpecs.values())\n",
    "# dfImplSampSpecs = pd.DataFrame({col: vals + [np.nan] * (nSampSpecRows - len(vals)) for col, vals in dImplSampleSpecs.items()})\n",
    "# dfImplSampSpecs.loc[0, 'Commentaire'] = 'Toutes combinaisons de ces 4 colonnes'\n",
    "# fpn = dossier / f'{nomEtude}-Echantillons.xlsx'\n",
    "# dfImplSampSpecs.to_excel(fpn, index=False, sheet_name='Echantillons_impl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pour info., qq stats sur les échantillons ainsi spécifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les specs explicitées donneront ...\n",
    "dfExplSampleSpecs = ads.DSAnalyser.explicitVariantSpecs(dict(_impl=dImplSampleSpecs))\n",
    "dfExplSampleSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance max et nombre d'individus pour chaque échantillon, dans l'ordre d'analyse (Cf. XIII)\n",
    "# a. Colonnes réelles de sélection des échantillons (certaines peuvent être vides)\n",
    "dfSampleOrd = dfExplSampleSpecs.dropna(axis='columns', how='all')\n",
    "indexCols = [col for col in samplingCols if col in dfSampleOrd.columns]\n",
    "\n",
    "# b. Ordre des espèces dans les échantillons\n",
    "dfSampleOrd = dfSampleOrd.drop_duplicates(subset=[colEspece])[[colEspece]].reset_index(drop=True)\n",
    "dfSampleOrd = dfSampleOrd.reset_index(drop=False).rename(columns=dict(index='order'))\n",
    "dfSampleOrd = dfSampleOrd.set_index(colEspece)\n",
    "\n",
    "# c. Distances max pour les valeurs uniques des catégories (ex: Adulte => m, a)\n",
    "dfSampleStats = dfObsCatIndiv[indexCols + [colDistance]].groupby(indexCols).agg(['min', 'max', 'count'])\n",
    "dfSampleStats.columns = ['Distance Min', 'Distance Max', 'NTot Obs']\n",
    "dfSampleStats = dfSampleStats.reset_index()\n",
    "\n",
    "# d. Categories pour combinaisons + tri \"simple\" dans le bon ordre\n",
    "speciesOrder = list(dfSampleOrd.index) + [e for e in dfSampleStats[colEspece].unique() if e not in dfSampleOrd.index]\n",
    "\n",
    "dCategories = {colEspece: speciesOrder, colPassage: ['a', 'b', 'a+b'],\n",
    "               'Adulte': ['m', 'a', 'm+a'], 'Durée': ['5mn', '10mn']}\n",
    "dCategoryTypes = { cat: pdt.CategoricalDtype(categories=values, ordered=True) for cat, values in dCategories.items()}\n",
    "\n",
    "for col in indexCols:\n",
    "    dfSampleStats[col] = dfSampleStats[col].astype(dCategoryTypes[col])\n",
    "\n",
    "# e. Distances max pour les valeurs combinées des catégories non imbriquées (ex: Adulte => m+a)\n",
    "cols2OrCombine = [col for col in nonSpeciesSamplingCols if col in indexCols and col not in dCategoriesImbriquees.keys()]\n",
    "for col2OrComb in cols2OrCombine:\n",
    "    indexNoCol2CombCols = [col for col in indexCols if col != col2OrComb]\n",
    "    dfSampleStatsOrComb = \\\n",
    "        dfSampleStats[indexNoCol2CombCols + ['Distance Min', 'Distance Max', 'NTot Obs']].groupby(indexNoCol2CombCols) \\\n",
    "            .agg({'Distance Min': 'min', 'Distance Max': 'max', 'NTot Obs': 'sum'})\n",
    "    dfSampleStatsOrComb.columns = ['Distance Min', 'Distance Max', 'NTot Obs']\n",
    "    dfSampleStatsOrComb = dfSampleStatsOrComb.dropna().reset_index()  # Why Nans appear in index ? A mystery !\n",
    "    dfSampleStatsOrComb[col2OrComb] = '+'.join(dfSampleStats[col2OrComb].sort_values().unique())\n",
    "    dfSampleStatsOrComb[col2OrComb] = dfSampleStatsOrComb[col2OrComb].astype(dCategoryTypes[col2OrComb])\n",
    "    dfSampleStats = dfSampleStats.append(dfSampleStatsOrComb, ignore_index=True)\n",
    "    \n",
    "# d. Tri dans l'ordre des espèces, et des autres colonnes de sélection d'échantillon    \n",
    "dfSampleStats.sort_values(by=indexCols, inplace=True)  # Magic ! (thanks to CategoricalDtype)\n",
    "\n",
    "dfSampleStats.reset_index(inplace=True, drop=True)\n",
    "\n",
    "dfSampleStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde.\n",
    "fpn = dossier / f'{nomEtude}{sousEtude}-StatsEchantillons.xlsx'\n",
    "\n",
    "dfSampleStats.to_excel(fpn, index=False)\n",
    "\n",
    "logger.info(fpn.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XIV. Export pour analyses \"manuelles\" dans Distance\n",
    "\n",
    "(exécuter d'abord jusqu'à I ; puis II à XI (sauf IX), ou alors juste XIII et XIV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paramètres pour l'export et les (pré-)analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des données\n",
    "transectPlaceCols = ['Point']\n",
    "passIdCol = colPassage\n",
    "\n",
    "effortCol = colEffort\n",
    "sampleDistCol = colDistance\n",
    "sampleDecCols = [effortCol, sampleDistCol]\n",
    "\n",
    "sampleNumCol = 'Echant'\n",
    "sampleSelCols = [colEspece, passIdCol] + colsSpeSelEchant\n",
    "\n",
    "sampleAbbrevCol = 'Abrev. Echant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaîne courte d'identification d'une spec. d'échantillon.\n",
    "def sampleAbbrev(sSamp):\n",
    "    abbrvs = [''.join(word[:4].title() for word in sSamp[colEspece].split(' ')[:2])]\n",
    "    if colPassage in sSamp.index and not pd.isnull(sSamp.Passage) and sSamp.Passage:\n",
    "        abbrvs.append(sSamp.Passage.replace('+', ''))\n",
    "    if 'Durée' in sSamp.index:\n",
    "        abbrvs.append(sSamp['Durée'].replace('+', ''))\n",
    "    if 'Adulte' in sSamp.index:\n",
    "        abbrvs.append(sSamp.Adulte.replace('+', ''))\n",
    "    return '-'.join(abbrvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[XV. Pré-analyses automatiques](#XV.-Pr%C3%A9-analyses-automatiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[XVI. Analyses automatiques](#XVI.-Analyses-automatiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Export Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dossier de sortie : résultats, rapports ... etc.\n",
    "workDir = dossier / dt.datetime.now().strftime('%y%m%d-%H%M')\n",
    "workDir.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objet PreAnalyser pour l'export.\n",
    "pranlysr = ads.MCDSPreAnalyser(dfObsCatIndiv, dfTransects=dfTransects, effortConstVal=effortConst, dSurveyArea=dZoneEtude, \n",
    "                               transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                               sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleIndCol=sampleNumCol,\n",
    "                               abbrevCol=sampleAbbrevCol, abbrevBuilder=sampleAbbrev,\n",
    "                               distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                               surveyType=surveyType, distanceType=distanceType, clustering=groupage,\n",
    "                               workDir=workDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export au format Distance des échantillons sélectionnés.\n",
    "pranlysr.exportDSInputData(implSampleSpecs=dict(_impl=dImplSampleSpecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XV. Pré-analyses automatiques\n",
    "\n",
    "(exécuter d'abord jusqu'à I ; puis II à XI (sauf IX), ou alors juste XIII et XIV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paramètres de pré-analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécuter XIV.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[XIV.1. Paramètres pour l'export et les (pré-)analyses](#1.-Param%C3%A8tres-pour-l'export-et-les-(pr%C3%A9-)analyses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Ou: Exécution des pré-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dossier de sortie : résultats, rapports ... etc.\n",
    "workDir = dossier / dt.datetime.now().strftime('%y%m%d-%H%M')\n",
    "\n",
    "presFileName = workDir / f'{nomEtude}{sousEtude}-PreAnalyses-resultats.xlsx'\n",
    "\n",
    "presFileName.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objet PréAnalyser.\n",
    "pranlysr = ads.MCDSPreAnalyser(dfObsCatIndiv, dfTransects=dfTransects, effortConstVal=effortConst, dSurveyArea=dZoneEtude, \n",
    "                               transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                               sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleIndCol=sampleNumCol,\n",
    "                               abbrevCol=sampleAbbrevCol, abbrevBuilder=sampleAbbrev,\n",
    "                               distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                               surveyType=surveyType, distanceType=distanceType, clustering=groupage,\n",
    "                               resultsHeadCols=dict(before=[sampleNumCol], sample=sampleSelCols, after=[sampleAbbrevCol]),\n",
    "                               workDir=workDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des specs de pré-analyse (échantillons)\n",
    "dfExplSampleSpecs, userParamSpecCols, intParamSpecCols, unmUserParamSpecCols, verdict, reasons = \\\n",
    "    pranlysr.explicitParamSpecs(implParamSpecs=dict(_impl=dImplSampleSpecs), dropDupes=True, check=True)  \n",
    "\n",
    "logger.info(dict(nSamples=len(dfExplSampleSpecs)))\n",
    "\n",
    "assert userParamSpecCols == [] # No analysis params here (auto. generated by PreAnalyser)\n",
    "assert intParamSpecCols == [] # Idem\n",
    "assert verdict\n",
    "assert not reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratégie choix modèles.\n",
    "lModelStrategy = [dict(keyFn=kf, adjSr=js, estCrit='AIC', cvInt=95)\n",
    "                  for js in['COSINE', 'POLY']  #, 'HERMITE'] # Hermite : allonge les calculs, pour des bricoles (?)\n",
    "                  for kf in['HNORMAL', 'HAZARD', 'UNIFORM']]  #, 'NEXPON']] # NegExpon : Pb car g'(0) << 0 !!!\n",
    "pd.DataFrame(lModelStrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "preResults = pranlysr.run(implSampleSpecs=dict(_impl=dImplSampleSpecs), dModelStrategy=lModelStrategy, threads=12)\n",
    "\n",
    "preAnalysed = True\n",
    "\n",
    "pranlysr.shutdown()\n",
    "\n",
    "# Qq specs supplémentaires\n",
    "if 'dfSampleStats' in dir():\n",
    "    preResults.updateSpecs(sampleStats=dfSampleStats)\n",
    "\n",
    "# Sauvegarde résultats\n",
    "preResults.toExcel(presFileName)\n",
    "\n",
    "backup(presFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances figures on a 4-core HT i5-8350U Ruindows 10 laptop with PCI-e SSD,\n",
    "\"optimal performance power scheme\", 12 threads, Python 3.8 :\n",
    "* ACDC2019 3mn40s à 3mn54s 240 analyses, 12 modèles\n",
    "* ACDC2019 Pap 2mn09s 240 analyses, 6 modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Ou: Chargement des résultats des pré-analyses déjà faites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'preAnalysed' not in dir():\n",
    "    preAnalysed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not preAnalysed:\n",
    "    \n",
    "    resFolders = [fn.name for fn in dossier.glob('[0-9]'*6+'-'+'[0-9]'*4)\n",
    "                  if (fn / f'{nomEtude}{sousEtude}-PreAnalyses-resultats.xlsx').is_file()]\n",
    "    \n",
    "    logger.info('Résultats disponibles : ' + ', '.join(resFolders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not preAnalysed:\n",
    "    \n",
    "    workDir = dossier / resFolders[1]  # <=== Choisir le dossier de résultats ici.\n",
    "    \n",
    "    presFileName = workDir / f'{nomEtude}{sousEtude}-PreAnalyses-resultats.xlsx'\n",
    "    \n",
    "    logger.info(f'Fichier choisi : {presFileName}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not preAnalysed:\n",
    "    \n",
    "    # An analyser object knowns how to build an empty results object ...\n",
    "    panlysr = ads.MCDSPreAnalyser(dfObsCatIndiv, dfTransects=dfTransects, effortConstVal=effortConst, dSurveyArea=dZoneEtude, \n",
    "                                  transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                                  sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleIndCol=sampleNumCol,\n",
    "                                  abbrevCol=sampleAbbrevCol, abbrevBuilder=sampleAbbrev,\n",
    "                                  distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                                  surveyType=surveyType, distanceType=distanceType, clustering=groupage,\n",
    "                                  resultsHeadCols=dict(before=[sampleNumCol], sample=sampleSelCols, after=[sampleAbbrevCol]))\n",
    "    \n",
    "    preResults = panlysr.setupResults()\n",
    "    \n",
    "    # Load results from file\n",
    "    preResults.fromFile(presFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    logger.info('Déjà calculé, pas de rechargement ...')\n",
    "    \n",
    "logger.info('... {} pré-analyses prêtes pour un rapport'.format(len(preResults)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rapports Excel et HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preResults._dfData = preResults._dfData.iloc[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preResults.dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes pour les tableaux du pré-rapport\n",
    "# a. Page principale : Colonne 1 (haut), de description de l'échantillon\n",
    "preRepSampleCols = [('header (sample)', col, 'Value') for col in samplingCols]\n",
    "\n",
    "# b. Page principale : Colonne 1 (bas), des paramètres du modèle d'analyse\n",
    "preRepParamCols = \\\n",
    "[\n",
    "    ('parameters', 'estimator key function', 'Value'),\n",
    "    ('parameters', 'estimator adjustment series', 'Value'),\n",
    "    ('parameters', 'CV interval', 'Value')\n",
    "]\n",
    "\n",
    "# c. Page principale : Colonne 2 et 3, des résultats (juste avant les 4, 5, et 6 avec les courbes)\n",
    "preRepResultCols = \\\n",
    "[\n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    ('encounter rate', 'right truncation distance (w)', 'Value'),\n",
    "    ('encounter rate', 'effort (L or K or T)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "    \n",
    "    ('density/abundance', 'number of animals, if survey area is specified', 'Value'),\n",
    "    ('density/abundance', 'number of animals, if survey area is specified', 'Lcl'),\n",
    "    ('density/abundance', 'number of animals, if survey area is specified', 'Ucl')\n",
    "   \n",
    "]\n",
    "\n",
    "# d. Pages ppale et de détails : Tableau de synthèse.\n",
    "preRepSynthCols = preRepSampleCols + preRepParamCols \\\n",
    "+ [\n",
    "    ('run output', 'run status', 'Value'),\n",
    "    \n",
    "    ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "    ('encounter rate', 'right truncation distance (w)', 'Value'),\n",
    "    ('encounter rate', 'effort (L or K or T)', 'Value'),\n",
    "    \n",
    "    ('detection probability', 'AIC value', 'Value'),\n",
    "    ('detection probability', 'chi-square test probability determined', 'Value'),\n",
    "    ('detection probability', 'Kolmogorov-Smirnov test probability', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Cv'),\n",
    "    \n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Value'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Lcl'),\n",
    "    ('detection probability', 'effective strip width (ESW) or effective detection radius (EDR)', 'Ucl'),\n",
    "    \n",
    "    ('density/abundance', 'density of animals', 'Value'),\n",
    "    ('density/abundance', 'density of animals', 'Lcl'),\n",
    "    ('density/abundance', 'density of animals', 'Ucl'),\n",
    "    \n",
    "    ('detection probability', 'probability of detection (Pw)', 'Value'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Lcl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Ucl'),\n",
    "    ('detection probability', 'probability of detection (Pw)', 'Df'),\n",
    "\n",
    "    ('density/abundance', 'number of animals, if survey area is specified', 'Value'),\n",
    "    ('density/abundance', 'number of animals, if survey area is specified', 'Lcl'),\n",
    "    ('density/abundance', 'number of animals, if survey area is specified', 'Ucl'),\n",
    "    ('density/abundance', 'number of animals, if survey area is specified', 'Df'),\n",
    "   \n",
    "    ('run output', 'run folder', 'Value')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preReport = ads.MCDSResultsPreReport(resultsSet=preResults,\n",
    "                                     title=titreEtude, subTitle='Rapport de pré-analyse',\n",
    "                                     anlysSubTitle='Détail des pré-analyses', description=descrEtude,\n",
    "                                     keywords=motsClesEtude, pySources=['Visionature-ds-points.ipynb'],\n",
    "                                     lang='fr', #plotImgSize=(640, 400), superSynthPlotsHeight=288,\n",
    "                                     #plotImgQuality=80, plotImgFormat='jpg', # Same final size as raw PNG :-(\n",
    "                                     sampleCols=preRepSampleCols, paramCols=preRepParamCols,\n",
    "                                     resultCols=preRepResultCols, synthCols=preRepSynthCols,\n",
    "                                     tgtFolder=workDir, tgtPrefix=f'{nomEtude}{sousEtude}-PreAnalyses-rapport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsxPreRep = preReport.toExcel()\n",
    "\n",
    "backup(xlsxPreRep)\n",
    "\n",
    "HTML(f'Rapport Excel : <a href=\"{xlsxPreRep}\" target=\"blank\">{xlsxPreRep}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "htmlPreRep = preReport.toHtml(generators=6)\n",
    "\n",
    "backup(htmlPreRep)\n",
    "\n",
    "HTML(f'Pré-rapport HTML : <a href=\"{htmlPreRep}\" target=\"blank\">{htmlPreRep}</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances figures on a 4-core HT i5-8350U Ruindows 10 laptop with PCI-e SSD,\n",
    "\"optimal performance power scheme\", 12 threads, Python 3.8 :\n",
    "* CretesPlombCantalZPS2020 : 55s for 1 generator, >= 28s for 4 or 6 or 8 generators (but old).\n",
    "* ACDC2019 240 samples (6 generators) : 2mn30s, then 3mn50s (why ?), then 4mn30s (added fixed bin hist)\n",
    "  then 5mn30s (3 superimposed fixed bin hists).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveauté Pandas 1.1, mais hélas, pas de colorisation via style en 1.1.3 :-(\n",
    "#odsPreRep = preReport.toOpenDoc()\n",
    "\n",
    "#HTML(f'Rapport OpenDoc/Spreadsheet : <a href=\"{odsPreRep}\" target=\"blank\">{odsPreRep}</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XVI. Analyses automatiques\n",
    "\n",
    "(avec optimisation de troncatures éventuelles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaîne courte d'identification d'une analyse.\n",
    "def analysisAbbrev(sAnlys):\n",
    "    \n",
    "    # Sample abbreviation\n",
    "    abbrevs = [sampleAbbrev(sAnlys)]\n",
    "\n",
    "    # Model + Parameters abbreviation\n",
    "    abbrevs += [sAnlys['FonctionClé'][:3].lower(), sAnlys['SérieAjust'][:3].lower()]\n",
    "    dTroncAbbrv = { 'l': 'TrGche' if 'TrGche' in sAnlys.index else 'TroncGche',\n",
    "                    'r': 'TrDrte' if 'TrDrte' in sAnlys.index else 'TroncDrte',\n",
    "                    'm': 'NbTrModel' if 'NbTrModel' in sAnlys.index else  'NbTrchMod',\n",
    "                    'd': 'NbTrDiscr' }\n",
    "    for abbrev, name in dTroncAbbrv.items():\n",
    "        if name in sAnlys.index and not pd.isnull(sAnlys[name]):\n",
    "            abbrevs.append('{}{}'.format(abbrev, sAnlys[name][0].lower() if isinstance(sAnlys[name], str)\n",
    "                                                 else int(sAnlys[name])))\n",
    "   \n",
    "    return '-'.join(abbrevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optAnalysed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paramètres d'optanalyse\n",
    "\n",
    "(exécuter d'abord jusqu'à I ; puis II à X, ou alors juste XII ; puis XIV.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Description des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cf. XIV.1 pour les paramètres utiles pour l'export et les pré-analyses\n",
    "\n",
    "# 2. Compléments pour les optanalyses.\n",
    "anlysIndCol = 'Analyse'\n",
    "anlysAbbrevCol = 'Abrev. Analyse'\n",
    "anlysParamCols = ['FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Paramètres d'optimisation par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defEstimKeyFn = 'HNORMAL'\n",
    "defEstimAdjustFn = 'COSINE'\n",
    "defEstimCriterion = 'AIC'\n",
    "defCVInterval = 95\n",
    "\n",
    "defMinDist = None\n",
    "defMaxDist = None, \n",
    "defFitDistCuts = None\n",
    "defDiscrDistCuts = None\n",
    "\n",
    "defExpr2Optimise = 'chi2'\n",
    "defMinimiseExpr = False\n",
    "defOutliersMethod = 'tucquant'\n",
    "defOutliersQuantCutPct = 5\n",
    "defFitDistCutsFctr = dict(min=2/3, max=3/2)\n",
    "defDiscrDistCutsFctr = dict(min=1/3, max=1)\n",
    "\n",
    "defSubmitTimes = 2\n",
    "defSubmitOnlyBest = 1\n",
    "dDefSubmitOtherParams = dict()\n",
    "\n",
    "defCoreEngine = 'zoopt'\n",
    "defCoreMaxIters = 200\n",
    "defCoreTermExprValue = None\n",
    "defCoreAlgorithm = 'racos'\n",
    "defCoreMaxRetries = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Paramètres pour les post-calculs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldTruncIntrvSpecs = [dict(col='left', minDist=5.0, maxLen=5.0),\n",
    "                     dict(col='right', minDist=25.0, maxLen=25.0)]\n",
    "truncIntrvEpsilon = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Analyses à faire : variante d'études\n",
    "\n",
    "(sources = fichiers Excel / ODF de specs d'opt-analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomFicSpecs = f'{nomEtude}-OptAnalysesAFaire'\n",
    "ignorerSpecs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ou : Qq soit l'étude : la totale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varEtude = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ou : ACDC 2019, sans les analyses optimisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varEtude = 'SansOptim'\n",
    "ignorerSpecs = ['TroncaturesAuto_impl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ou : ACDC 2019, avec les analyses optimisées, mais sans refaire les optimisations\n",
    "\n",
    "(recharger les résultats au préalable, via [1b. Ou: Chargement des résultats des opt-analyses](#1b.-Ou%3A-Chargement-des-r%C3%A9sultats-des-opt-analyses) ci-dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varEtude = 'SansReOptim'\n",
    "nomFicSpecs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExplOptAnlysSpecs = results.dfTransData('fr')[['Espèce', 'Passage', 'Adulte', 'Durée', 'FonctionClé', 'SérieAjust',\n",
    "                                                 'TrGche', 'TrDrte', 'NbTrchMod', 'OptimTrunc']]\n",
    "dfExplOptAnlysSpecs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ou : ZPS Cantal 2020 : pour comparer aux analyses manuelles de Mathis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varEtude = 'CommeMathis'\n",
    "nomFicSpecs = f'{nomEtude}-OptAnalysesAFaire-{varEtude}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Analyses à faire : fichiers de specs, ou specs explicites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(etude=varEtude, specs=nomFicSpecs if nomFicSpecs else 'dfExplOptAnlysSpecs', ignorer=ignorerSpecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les analyses à faire (avec specs d'optimisation dedans si nécessaire)\n",
    "if nomFicSpecs:\n",
    "    \n",
    "    dfExplOptAnlysSpecs = None\n",
    "    \n",
    "    optAnlysSpecFileExts = ['.ods', '.xlsx']\n",
    "    for ext in optAnlysSpecFileExts:\n",
    "        optAnlysSpecs = dossier / f'{nomFicSpecs}{ext}'\n",
    "        if optAnlysSpecs.is_file():\n",
    "            break\n",
    "\n",
    "    assert optAnlysSpecs.is_file(), \\\n",
    "           '{} n\\'existe pas, ni les autres extensions possibles [{}] !' \\\n",
    "           .format(optAnlysSpecs.as_posix(), ', '.join(optAnlysSpecFileExts[:-1]))\n",
    "\n",
    "    logger.info('Implicites, via ' + optAnlysSpecs.as_posix())\n",
    "\n",
    "    if ignorerSpecs:\n",
    "        optAnlysSpecs = pd.read_excel(optAnlysSpecs, sheet_name=None)\n",
    "        for spec in ignorerSpecs:\n",
    "            del optAnlysSpecs[spec]\n",
    "        logger.info('Retiré ' + str(ignorerSpecs))\n",
    "        logger.info('Restent ' + str(list(optAnlysSpecs.keys())))\n",
    "        \n",
    "else:\n",
    "    \n",
    "    optAnlysSpecs = None\n",
    "    \n",
    "    assert not dfExplOptAnlysSpecs.empty\n",
    "    \n",
    "    logger.info('Explicites, via dfExplOptAnlysSpecs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Ou: Exécution des opt-analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True for recovering when interrupted during optimisations.\n",
    "recoverOptims = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List possible folders for recovery.\n",
    "if recoverOptims:\n",
    "    \n",
    "    logger.info('Dossiers possibles pour reprise :')\n",
    "    \n",
    "    bkupFileNamePat = 'optr-resbak-[01].pickle.xz'\n",
    "    resFolders = list()\n",
    "    folderInd = 0\n",
    "    for fpn in sorted(dossier.glob('[0-9]'*6+'-'+'[0-9]'*4)):\n",
    "        \n",
    "        bkupFilePathNames = list(fpn.glob(bkupFileNamePat))\n",
    "        if bkupFilePathNames:\n",
    "            \n",
    "            logger.info(f'  #{folderInd} {fpn.name}')\n",
    "            for bfpn in bkupFilePathNames:\n",
    "                logger.info('    {} {}'.format(bfpn.name, pd.Timestamp.fromtimestamp(bfpn.stat().st_mtime)))\n",
    "            \n",
    "            resFolders.append(fpn.name)\n",
    "            folderInd += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select run folder : for recovery or a brand new one.\n",
    "if recoverOptims:\n",
    "    \n",
    "    # Choose manually the folder to recover from / go on working inside.\n",
    "    resFolder = resFolders[1]  # <===== Here, set the chosen index\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # A brand new one.\n",
    "    resFolder = dt.datetime.now().strftime('%y%m%d-%H%M')\n",
    "    \n",
    "# Dossier de sortie : résultats, rapports ... etc.\n",
    "workDir = dossier / resFolder\n",
    "\n",
    "workDir.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier de résultats\n",
    "resFileName = workDir / f'{nomEtude}{sousEtude}-OptAnalyses{varEtude}-resultats.xlsx'\n",
    "\n",
    "resFileName.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optanlr = \\\n",
    "    ads.MCDSTruncationOptanalyser(dfObsCatIndiv, dfTransects=dfTransects, effortConstVal=effortConst, dSurveyArea=dZoneEtude, \n",
    "                                  transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                                  sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleDistCol=sampleDistCol,\n",
    "                                  abbrevCol=anlysAbbrevCol, abbrevBuilder=analysisAbbrev,\n",
    "                                  anlysIndCol=anlysIndCol, sampleIndCol=sampleNumCol,\n",
    "                                  distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                                  surveyType=surveyType, distanceType=distanceType, clustering=groupage,\n",
    "                                  resultsHeadCols=dict(before=[anlysIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                                       after=anlysParamCols + [anlysAbbrevCol]),\n",
    "                                  ldTruncIntrvSpecs=ldTruncIntrvSpecs, truncIntrvEpsilon=truncIntrvEpsilon,\n",
    "                                  workDir=workDir, runMethod='subprocess.run', runTimeOut=300,\n",
    "                                  defEstimKeyFn=defEstimKeyFn, defEstimAdjustFn=defEstimAdjustFn,\n",
    "                                  defEstimCriterion=defEstimCriterion, defCVInterval=defCVInterval,\n",
    "                                  defExpr2Optimise=defExpr2Optimise, defMinimiseExpr=defMinimiseExpr,\n",
    "                                  defOutliersMethod=defOutliersMethod, defOutliersQuantCutPct=defOutliersQuantCutPct,\n",
    "                                  defFitDistCutsFctr=defFitDistCutsFctr, defDiscrDistCutsFctr=defDiscrDistCutsFctr,\n",
    "                                  defSubmitTimes=defSubmitTimes, defSubmitOnlyBest=defSubmitOnlyBest,\n",
    "                                  dDefSubmitOtherParams=dDefSubmitOtherParams,\n",
    "                                  dDefOptimCoreParams=dict(core=defCoreEngine, maxIters=defCoreMaxIters,\n",
    "                                                           termExprValue=defCoreTermExprValue,\n",
    "                                                           algorithm=defCoreAlgorithm, maxRetries=defCoreMaxRetries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExplOptAnlysSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des specs d'opt-analyse\n",
    "dfExplOptAnlysSpecs, userParamSpecCols, intParamSpecCols, unmUserParamSpecCols, verdict, reasons = \\\n",
    "    optanlr.explicitParamSpecs(implParamSpecs=optAnlysSpecs, dfExplParamSpecs=dfExplOptAnlysSpecs, dropDupes=True, check=True)  \n",
    "\n",
    "if not verdict:\n",
    "    logger.info('Optanalysis specs errors:')\n",
    "    logger.info('\\n'.join(reasons))\n",
    "else:\n",
    "    logger.info('Optanalysis specs OK')\n",
    "\n",
    "logger.info(dict(specs=', '.join(optAnlysSpecs.keys()) if isinstance(optAnlysSpecs, dict)\n",
    "                       else optAnlysSpecs.as_posix() if optAnlysSpecs else 'Explicit',\n",
    "                 nOptAnalyses=len(dfExplOptAnlysSpecs), userParamSpecCols=', '.join(userParamSpecCols),\n",
    "                 intParamSpecCols=', '.join(intParamSpecCols), unmUserParamSpecCols=', '.join(unmUserParamSpecCols)))\n",
    "\n",
    "assert verdict\n",
    "assert not reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les voici explicitées (juste pour voir ... à moins que ...)\n",
    "dfExplOptAnlysSpecs.to_excel(dossier / f'{nomEtude}{sousEtude}-ExplOptAnlysSpecs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification que les échantillons concernés ont été pré-analysés.\n",
    "if 'dfExplSampleSpecs' in dir():\n",
    "    \n",
    "    dfOptAnlysSpecsCheck = dfExplOptAnlysSpecs[sampleSelCols].drop_duplicates()\n",
    "    dfOptAnlysSpecsCheck['OptAnalyses'] = True\n",
    "    dfOptAnlysSpecsCheck.set_index(sampleSelCols, inplace=True)\n",
    "\n",
    "    dfPreAnlysSpecsCheck = dfExplSampleSpecs.copy()\n",
    "    dfPreAnlysSpecsCheck['PreAnalyses'] = True\n",
    "    dfPreAnlysSpecsCheck.set_index(sampleSelCols, inplace=True)\n",
    "    \n",
    "    dfCheck = dfOptAnlysSpecsCheck.join(dfPreAnlysSpecsCheck, how='outer').reset_index()\n",
    "    \n",
    "else:\n",
    "    \n",
    "    dfCheck = pd.DataFrame(columns=['PreAnalyses', 'OptAnalyses'])\n",
    "    \n",
    "logger.info(f'{len(dfCheck} échantillons pré-analysés ou à analyser, au total.')\n",
    "logger.info('Voici ceux qui n\\'ont pas été préanalysés :')\n",
    "dfCheck[dfCheck.PreAnalyses.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment-out to force using explicit specs.\n",
    "#optAnlysSpecs = None\n",
    "\n",
    "# Use implicit specs if given (not deduced explicit ones).\n",
    "if optAnlysSpecs:\n",
    "    dfExplOptAnlysSpecs = None\n",
    "    \n",
    "# Last checks.\n",
    "dict(recoverOptims=recoverOptims, dfExplOptAnlysSpecs=len([] if dfExplOptAnlysSpecs is None else dfExplOptAnlysSpecs),\n",
    "     optAnlysSpecs=optAnlysSpecs.as_posix() if optAnlysSpecs else None, workDir=workDir.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Exécution des (opt-)analyses.\n",
    "results = optanlr.run(dfExplParamSpecs=dfExplOptAnlysSpecs, implParamSpecs=optAnlysSpecs,\n",
    "                      recoverOptims=recoverOptims, threads=12)\n",
    "\n",
    "#results = optanlr.run(dfExplOptAnlysSpecs.iloc[0:2], threads=2)\n",
    "\n",
    "optAnalysed = True\n",
    "\n",
    "optanlr.shutdown()\n",
    "\n",
    "# Qq specs supplémentaires\n",
    "if 'dfSampleStats' in dir():\n",
    "    results.updateSpecs(sampleStats=dfSampleStats)\n",
    "\n",
    "# Sauvegarde résultats\n",
    "results.toExcel(resFileName)\n",
    "\n",
    "backup(resFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optanlr.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.dfData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Ou: Chargement des résultats des opt-analyses\n",
    "\n",
    "(choisir le dossier parmis ceux qui sont présents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'optAnalysed' not in dir():\n",
    "    optAnalysed = False\n",
    "    \n",
    "if not optAnalysed:\n",
    "    \n",
    "    resFolders = [fn.name for fn in dossier.glob('[0-9]'*6+'-'+'[0-9]'*4)\n",
    "                  if (fn / f'{nomEtude}{sousEtude}-OptAnalyses{varEtude}-resultats.xlsx').is_file()]\n",
    "    \n",
    "    logger.info('Résultats disponibles : ' + ', '.join(resFolders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not optAnalysed:\n",
    "    \n",
    "    workDir = dossier / resFolders[0]  # <=== Choisir le dossier de résultats ici.\n",
    "    \n",
    "    resFileName = workDir / f'{nomEtude}{sousEtude}-OptAnalyses{varEtude}-resultats.xlsx'\n",
    "    \n",
    "    logger.info(f'Fichier choisi : {resFileName.as_posix()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not optAnalysed:\n",
    "    \n",
    "    # An optanalyser object knowns how to build an empty results object ...\n",
    "    optanlr = \\\n",
    "        ads.MCDSTruncationOptanalyser(dfObsCatIndiv, dfTransects=dfTransects,\n",
    "                                      effortConstVal=effortConst, dSurveyArea=dZoneEtude, \n",
    "                                      transectPlaceCols=transectPlaceCols, passIdCol=passIdCol, effortCol=effortCol,\n",
    "                                      sampleSelCols=sampleSelCols, sampleDecCols=sampleDecCols, sampleDistCol=sampleDistCol,\n",
    "                                      abbrevCol=anlysAbbrevCol, abbrevBuilder=analysisAbbrev,\n",
    "                                      anlysIndCol=anlysIndCol, sampleIndCol=sampleNumCol,\n",
    "                                      distanceUnit=distanceUnit, areaUnit=areaUnit,\n",
    "                                      surveyType=surveyType, distanceType=distanceType, clustering=groupage,\n",
    "                                      ldTruncIntrvSpecs=ldTruncIntrvSpecs, truncIntrvEpsilon=truncIntrvEpsilon,\n",
    "                                      resultsHeadCols=dict(before=[anlysIndCol, sampleNumCol], sample=sampleSelCols,\n",
    "                                                           #after=anlysParamCols + [optimTruncCol, anlysAbbrevCol]))\n",
    "                                                           after=anlysParamCols + [anlysAbbrevCol])) # TODO: test !\n",
    "    \n",
    "    results = optanlr.setupResults()\n",
    "    \n",
    "    # Load results from file\n",
    "    results.fromFile(resFileName)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    logger.info('Déjà calculé, pas de rechargement ...')\n",
    "    \n",
    "logger.info('... {} opt-analyses pour rapport'.format(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibilité ascendante pour résultats d'avant fin août 2021 : ajout des stats échantillons.\n",
    "if not optAnalysed and any(col not in results._dfData.columns for col in ads.MCDSEngine.MIStatSampCols):\n",
    "    \n",
    "    # Add sample stats a posteriori (these stats had not been implemented when the historical results were saved to disk)\n",
    "    #if 'dfSampleStats' not in dir():  # TODO: make this work is dfSampleStats already defined\n",
    "    dfSampleStats = pd.read_excel(dossier / f'{nomEtude}{sousEtude}-StatsEchantillons.xlsx')\n",
    "    dfSampleStats.rename(columns={'NTot Obs': 'NTot Obs0'}, inplace=True)\n",
    "    dfSampleStats.insert(dfSampleStats.columns.to_list().index('Distance Min'), 'NTot Obs', dfSampleStats['NTot Obs0'])\n",
    "    dfSampleStats.drop(columns=['NTot Obs0'], inplace=True)\n",
    "\n",
    "    miSampleCols = pd.MultiIndex.from_tuples([('header (sample)', colEspece, 'Value'),\n",
    "                                              ('header (sample)', colPassage, 'Value'),\n",
    "                                              ('header (sample)', colsSpeSelEchant[0], 'Value'),\n",
    "                                              ('header (sample)', colsSpeSelEchant[1], 'Value')])\n",
    "    dfSampleStats.columns = miSampleCols.append(ads.MCDSEngine.MIStatSampCols)\n",
    "\n",
    "    results.setData(results._dfData.join(dfSampleStats.set_index(miSampleCols.to_list()), on=miSampleCols.to_list()))\n",
    "    \n",
    "    logger.info('Ajout stats échantillons => {} opt-analyses pour rapport'.format(len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibilité ascendante pour résultats d'avant fin août 2021 : ajout des infos 'runtime' (supposées).\n",
    "if not optAnalysed and 'runtime' not in results.specs:\n",
    "    \n",
    "    oldRuntime = {'WARNING': 'Actually, not precisely what\\'s listed below, but for sure something very close ...',\n",
    "                  'platform': 'win32',\n",
    "                  'cpython': '3.8.2 | packaged by conda-forge | (default, Apr 24 2020, 07:34:03) [MSC v.1916 64 bit (AMD64)]',\n",
    "                  'numpy': '1.19.4',\n",
    "                  'pandas': '1.2.5',\n",
    "                  'pickle': '4.0',\n",
    "                  'zoopt': '0.4.0',\n",
    "                  'matplotlib': '3.4.2',\n",
    "                  'jinja2': '3.0.1'}\n",
    "    \n",
    "    results.updateSpecs(runtime=pd.Series(oldRuntime, name='Version'))\n",
    "    \n",
    "    logger.info('Ajout infos plateforme de calcul supposée')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtrage / sélection des résultats avant rapport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au cas où, à ce stade, on désire supprimer les résultats pour certains échantillons, certaines analyses ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour l'instant, pas de cas d'usage identifié"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rapports Excel et HTML auto-filtrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = ads.MCDSTruncOptanalysisResultsSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-synthesis: Select analysis results columns for the 3 textual columns on the left\n",
    "sampleFilSorRepCols = \\\n",
    "[('header (head)', sampleNumCol, 'Value')] \\\n",
    "+ [('header (sample)', col, 'Value') for col in samplingCols] \\\n",
    "+ [('sample stats', 'total number of observations', 'Value'),\n",
    "   ('sample stats', 'maximal observation distance', 'Value')]\n",
    "\n",
    "paramFilSorRepCols = \\\n",
    "[\n",
    "    R.CLParEstKeyFn, R.CLParEstAdjSer,\n",
    "    #R.CLParEstSelCrit, R.CLParEstCVInt,\n",
    "    R.CLParTruncLeft, R.CLParTruncRight, R.CLParModFitDistCuts,\n",
    "]\n",
    "    \n",
    "resultFilSorRepCols = \\\n",
    "[\n",
    "    ('header (head)', anlysIndCol, 'Value'),\n",
    "    R.CLRunStatus,\n",
    "    R.CLEffort, R.CLNObs, R.CLSightRate, R.CLNAdjPars,\n",
    "    R.CLAic, R.CLChi2, R.CLKS, R.CLDCv,\n",
    "    R.CLCmbQuaBal3, R.CLCmbQuaBal2, R.CLCmbQuaBal1,\n",
    "     \n",
    "    R.CLEswEdr,\n",
    "    R.CLPDetec, R.CLDensity, R.CLDensityMin, R.CLDensityMax,\n",
    "    R.CLNumber, R.CLNumberMin, R.CLNumberMax\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesis: Select columns of the filtered table\n",
    "synthFilSorRepCols = \\\n",
    "[('header (head)', sampleNumCol, 'Value')] \\\n",
    "+ [('header (sample)', col, 'Value') for col in samplingCols] \\\n",
    "+ [('header (head)', anlysIndCol, 'Value'),\n",
    "   ('header (tail)', 'FonctionClé', 'Value'),\n",
    "   ('header (tail)', 'SérieAjust', 'Value'),\n",
    "   ('header (tail)', 'TrGche', 'Value'),\n",
    "   ('header (tail)', 'TrDrte', 'Value'),\n",
    "   ('header (tail)', 'NbTrchMod', 'Value'),\n",
    " \n",
    "   R.CLRunStatus,\n",
    "   R.CLEffort, R.CLNTotObs, R.CLNObs, R.CLNAdjPars,\n",
    "   R.CLDeltaAic, R.CLChi2, R.CLKS, R.CLCvMUw, R.CLCvMCw, R.CLDCv, \n",
    "   \n",
    "   R.CLDensity, R.CLDensityMin, R.CLDensityMax,\n",
    "   R.CLEswEdr, R.CLEswEdrMin, R.CLEswEdrMax,\n",
    "   R.CLNumber, R.CLNumberMin, R.CLNumberMax,\n",
    "   R.CLPDetec, R.CLPDetecMin, R.CLPDetecMax,\n",
    "\n",
    "   R.CLSightRate,\n",
    "   R.CLCmbQuaBal3, R.CLCmbQuaBal2, R.CLCmbQuaBal1,\n",
    "   R.CLCmbQuaChi2, R.CLCmbQuaKS, R.CLCmbQuaDCv,\n",
    "\n",
    "   R.CLGroupTruncLeft, R.CLGroupTruncRight,\n",
    "   \n",
    "   R.CLGrpOrdSmTrAic,\n",
    "   R.CLGrpOrdClTrChi2KSDCv, #R.CLGrpOrdClTrChi2,\n",
    "   R.CLGrpOrdClTrDCv,\n",
    "   R.CLGrpOrdClTrQuaBal1, R.CLGrpOrdClTrQuaBal2, R.CLGrpOrdClTrQuaBal3, R.CLGrpOrdClTrQuaChi2,\n",
    "   R.CLGrpOrdClTrQuaKS, R.CLGrpOrdClTrQuaDCv,\n",
    "   R.CLGblOrdChi2KSDCv, R.CLGblOrdQuaBal1, R.CLGblOrdQuaBal2, R.CLGblOrdQuaBal3,\n",
    "   R.CLGblOrdQuaChi2, R.CLGblOrdQuaKS, R.CLGblOrdQuaDCv,\n",
    "   R.CLGblOrdDAicChi2KSDCv\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filter and sort schemes to apply\n",
    "whichBestQua = [R.CLGrpOrdClTrChi2KSDCv, R.CLGrpOrdClTrDCv, R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3,\n",
    "                R.CLGrpOrdClTrQuaChi2, R.CLGrpOrdClTrQuaKS, R.CLGrpOrdClTrQuaDCv]\n",
    "\n",
    "dupSubset = [R.CLNObs, R.CLEffort, R.CLDeltaAic, R.CLChi2, R.CLKS, R.CLCvMUw, R.CLCvMCw, R.CLDCv, \n",
    "             R.CLPDetec, R.CLPDetecMin, R.CLPDetecMax, R.CLDensity, R.CLDensityMin, R.CLDensityMax]\n",
    "dDupRounds = {R.CLDeltaAic: 1, R.CLChi2: 2, R.CLKS: 2, R.CLCvMUw: 2, R.CLCvMCw: 2, R.CLDCv: 2, \n",
    "              R.CLPDetec: 3, R.CLPDetecMin: 3, R.CLPDetecMax: 3, R.CLDensity: 2, R.CLDensityMin: 2, R.CLDensityMax: 2}\n",
    "\n",
    "whichFinalQua = R.CLCmbQuaBal3\n",
    "ascFinalQua = False\n",
    "\n",
    "filSorRepSchemes = [dict(method=R.filterSortOnExCAicMulQua,\n",
    "                         deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                         filterSort=dict(sightRate=97.5, nBestAIC=2, nBestQua=1, whichBestQua=whichBestQua,\n",
    "                                         nFinalRes=8, whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                         preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                         preselAscs=False, preselThrhs=0.4, preselNum=3),\n",
    "                    dict(method=R.filterSortOnExCAicMulQua,\n",
    "                         deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                         filterSort=dict(sightRate=95, nBestAIC=2, nBestQua=1, whichBestQua=whichBestQua,\n",
    "                                         nFinalRes=10, whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                         preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                         preselAscs=False, preselThrhs=0.3, preselNum=4),\n",
    "                    dict(method=R.filterSortOnExCAicMulQua,\n",
    "                         deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                         filterSort=dict(sightRate=92.5, nBestAIC=3, nBestQua=1, whichBestQua=whichBestQua,\n",
    "                                         nFinalRes=12, whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                         preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                         preselAscs=False, preselThrhs=0.2, preselNum=5),\n",
    "                    dict(method=R.filterSortOnExecCode,\n",
    "                         deduplicate=dict(dupSubset=dupSubset, dDupRounds=dDupRounds),\n",
    "                         filterSort=dict(whichFinalQua=whichFinalQua, ascFinalQua=ascFinalQua),\n",
    "                         preselCols=[R.CLCmbQuaBal1, R.CLCmbQuaBal2, R.CLCmbQuaBal3],\n",
    "                         preselAscs=False, preselThrhs=0.1, preselNum=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final sorting for report tables\n",
    "sortFilSorRepCols = [('header (head)', sampleNumCol, 'Value'), whichFinalQua]\n",
    "sortFilSorRepAscend = [True, False]\n",
    "\n",
    "assert len(sortFilSorRepCols) == len(sortFilSorRepAscend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filSorReport = ads.MCDSResultsFilterSortReport(resultsSet=results,\n",
    "                                               sampleCols=sampleFilSorRepCols, paramCols=paramFilSorRepCols,\n",
    "                                               resultCols=resultFilSorRepCols, synthCols=synthFilSorRepCols,\n",
    "                                               sortCols=sortFilSorRepCols, sortAscend=sortFilSorRepAscend,\n",
    "                                               filSorSchemes=filSorRepSchemes, lang='fr', \n",
    "                                               title=titreEtude, description=descrEtude, anlysSubTitle='Détails',\n",
    "                                               subTitle=\"Rapport d'analyse auto-filtré, méthode {fsId}\",\n",
    "                                               keywords=motsClesEtude, pySources=['Visionature-ds-points.ipynb'],\n",
    "                                               tgtFolder=workDir,\n",
    "                                               tgtPrefix=f'{nomEtude}{sousEtude}-OptAnalyses{varEtude}-rapport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xlsxFilSorRep = filSorReport.toExcel()\n",
    "\n",
    "backup(xlsxFilSorRep)\n",
    "\n",
    "logger.info('Rapport Excel filtré : ' + pl.Path(xlsxFilSorRep).as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "htmlFilSorScheme = next(schm for schm in filSorRepSchemes\n",
    "                        if schm['method'] is R.filterSortOnExCAicMulQua and schm['filterSort']['sightRate'] == 92.5)\n",
    "\n",
    "htmlFilSorRep = filSorReport.toHtml(htmlFilSorScheme)\n",
    "\n",
    "backup(htmlFilSorRep)\n",
    "\n",
    "afsId = results.filSorSchemeId(htmlFilSorScheme)\n",
    "logger.info(f'Rapport HTML auto-filtré (méthode {afsId}):\\n=> ' + pl.Path(htmlFilSorRep).resolve().as_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "# Pandas 1.1 permet l'export ODF, mais hélas, pas encore de support pour le styling (via Style) :-(\n",
    "#odsAFXRep = report.toOpenDoc()\n",
    "#\n",
    "#logger.info('Rapport OpenDoc/Spreadsheet : ' + pl.Path(htmlFilSorRep).resolve().as_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.startfile(xlsxFilSorRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.startfile(odsAFXRep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rapports Excel et HTML simple\n",
    "\n",
    "(rapport 'Full', toutes analyses, sans filtre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super-synthesis: Select analysis results columns for the 3 textual columns on the left\n",
    "sampleRepCols = \\\n",
    "[('header (head)', sampleNumCol, 'Value')] \\\n",
    "+ [('header (sample)', col, 'Value') for col in samplingCols] \\\n",
    "+ [('sample stats', 'total number of observations', 'Value'),\n",
    "   ('sample stats', 'maximal observation distance', 'Value')]\n",
    "\n",
    "paramRepCols = \\\n",
    "[\n",
    "    R.CLParEstKeyFn, R.CLParEstAdjSer,\n",
    "    #R.CLParEstSelCrit, R.CLParEstCVInt,\n",
    "    R.CLParTruncLeft, R.CLParTruncRight, R.CLParModFitDistCuts,\n",
    "]\n",
    "    \n",
    "resultRepCols = \\\n",
    "[\n",
    "    ('header (head)', anlysIndCol, 'Value'),\n",
    "    R.CLRunStatus,\n",
    "    R.CLEffort, R.CLNObs, R.CLSightRate, R.CLNAdjPars,\n",
    "    R.CLAic, R.CLChi2, R.CLKS, R.CLDCv,\n",
    "    R.CLCmbQuaBal3, R.CLCmbQuaBal2, R.CLCmbQuaBal1,\n",
    "     \n",
    "    R.CLEswEdr,\n",
    "    R.CLPDetec, R.CLDensity, R.CLDensityMin, R.CLDensityMax,\n",
    "    R.CLNumber, R.CLNumberMin, R.CLNumberMax\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes pour les tableaux de synthèse du rapport\n",
    "synthRepCols = \\\n",
    "[('header (head)', col, 'Value') for col in [anlysIndCol, sampleNumCol]] \\\n",
    "+ [('header (sample)', col, 'Value') for col in samplingCols] \\\n",
    "+ [R.CLParEstKeyFn, R.CLParEstAdjSer,\n",
    "   #R.CLParEstSelCrit, R.CLParEstCVInt,\n",
    "   R.CLParTruncLeft, R.CLParTruncRight, R.CLParModFitDistCuts,\n",
    "   \n",
    "   R.CLRunStatus,\n",
    "   \n",
    "   R.CLEffort, R.CLNObs, R.CLSightRate, R.CLNAdjPars,\n",
    "   R.CLAic, R.CLChi2, R.CLKS, R.CLDCv,\n",
    "   R.CLCmbQuaBal3, R.CLCmbQuaBal2, R.CLCmbQuaBal1,\n",
    "    \n",
    "   R.CLEswEdr,\n",
    "   R.CLPDetec, R.CLDensity, R.CLDensityMin, R.CLDensityMax,\n",
    "   R.CLNumber, R.CLNumberMin, R.CLNumberMax\n",
    "   \n",
    "   ('encounter rate', 'number of observations (n)', 'Value'),\n",
    "   ('encounter rate', 'right truncation distance (w)', 'Value'),\n",
    "   R.CLEffort,\n",
    "   \n",
    "   R.CLDeltaAic, R.CLAic, R.CLChi2, R.CLKS, R.CLDCv, R.CLCvMUw, R.CLCvMCw,\n",
    "   \n",
    "   R.CLEswEdr, CLEswEdrMin, CLEswEdrMax,   \n",
    "   R.CLDensity, R.CLDensityMin, R.CLDensityMax, R.CLDeltaDCv,\n",
    "   R.CLPDetec, R.CLPDetecMin, R.CLPDetecMax, R.CLPDetecDf,\n",
    "   R.CLNumber, R.CLNumberMin, R.CLNumberMax, R.CLNumberDf,\n",
    "   \n",
    "   ('run output', 'run folder', 'Value')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortRepCols = \\\n",
    "[('header (head)', sampleNumCol, 'Value')] \\\n",
    "+ [('header (sample)', col, 'Value') for col in samplingCols] \\\n",
    "+ [R.CLParTruncLeft, R.CLParTruncRight,\n",
    "   R.CLDeltaAic, R.CLChi2, R.CLKS,  # R.CLDCv,\n",
    "   R.CLRunStatus]\n",
    "\n",
    "sortRepAscend = [True]*(1+len(samplingCols)+3) + [False]*2 + [True]\n",
    "\n",
    "assert len(sortRepCols) == len(sortRepAscend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ads.MCDSResultsFullReport(resultsSet=results, \n",
    "                                   sampleCols=sampleRepCols, paramCols=paramRepCols,\n",
    "                                   resultCols=resultRepCols, synthCols=synthRepCols,\n",
    "                                   sortCols=sortRepCols, sortAscend=sortRepAscend,\n",
    "                                   title=titreEtude, subTitle='Rapport d\\'analyse brut',\n",
    "                                   anlysSubTitle='Détail de toutes les analyses', description=descrEtude,\n",
    "                                   keywords=motsClesEtude, pySources=['Visionature-ds-points.ipynb'],\n",
    "                                   lang='fr', plotImgSize=(768, 384),\n",
    "                                   #plotImgQuality=80, plotImgFormat='jpg', # Same final size as raw PNG :-(\n",
    "                                   tgtFolder=workDir, tgtPrefix=f'{nomEtude}{sousEtude}-OptAnalyses{varEtude}-rapport-brut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xlsxRep = report.toExcel()\n",
    "\n",
    "backup(xlsxRep)\n",
    "\n",
    "logger.info('Rapport Excel : ' + pl.Path(xlsxRep).as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "htmlRep = report.toHtml()\n",
    "\n",
    "backup(htmlRep)\n",
    "\n",
    "logger.info('Rapport HTML : ' + pl.Path(htmlRep).as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison aux résultats DS \"manuels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cSclYellow, cSclOrange, cSclRed = '#fbfbba', '#f9da56', '#fe835a'\n",
    "scaled2Colors = ['white', cSclRed]\n",
    "scaled3Colors = ['white', cSclOrange, cSclRed]\n",
    "scaled4Colors = ['white', cSclYellow, cSclOrange, cSclRed]\n",
    "\n",
    "def scaledColorV(v, thresholds, colors, gt=True): # len(thresholds) == len(colors) - 1\n",
    "        if pd.isnull(v):\n",
    "            return cSclRed\n",
    "        if gt:\n",
    "            for ind, thresh in enumerate(thresholds):\n",
    "                if abs(v) > thresh:\n",
    "                    return colors[ind]\n",
    "        else:\n",
    "            for ind, thresh in enumerate(thresholds):\n",
    "                if abs(v) < thresh:\n",
    "                    return colors[ind]\n",
    "        return colors[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. ZPS Cantal 2020 : analyses manuelles de Mathis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compCols = ['Nb données', 'GOF Chi-p', 'D CV', 'N', 'N LCL', 'N UCL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfManuRep = pd.read_excel(dossier / 'CretesPlombCantalZPS2020-AnalysesD73Mathis-resultats.xlsx')\n",
    "dfManuRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultats auto : trié par meilleur AIC, colonnes traduites\n",
    "results.sortRows(by=[col for col in sortRepCols if col in results.columns], ascending=sortRepAscend)\n",
    "\n",
    "dfAutoRes = results.dfTransData('fr')\n",
    "dfAutoRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que la (1ère) analyse de meilleur AIC\n",
    "dfAutoResBest = dfAutoRes.groupby([colEspece, 'Adulte', 'Dist Tronc Drte', 'Tranch Dist Mod'],\n",
    "                                  dropna=False, sort=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaîne courte d'identification d'un échantillon + paramètres troncature.\n",
    "def echantTruncId(sRes):\n",
    "    \n",
    "    # Sample abbreviation\n",
    "    abbrevs = [sampleAbbrev(sRes)]\n",
    "\n",
    "    # Truncation parameters abbreviation\n",
    "    dTroncAbbrv = { 'l': 'TrGche' if 'TrGche' in sRes.index else 'TroncGche',\n",
    "                    'r': 'TrDrte' if 'TrDrte' in sRes.index else 'TroncDrte',\n",
    "                    'm': 'NbTrches' if 'NbTrches' in sRes.index else 'NbTrModel'\n",
    "                                    if 'NbTrModel' in sRes.index else  'NbTrchMod',\n",
    "                    'd': 'NbTrDiscr' }\n",
    "    for abbrev, name in dTroncAbbrv.items():\n",
    "        if name in sRes.index and not pd.isnull(sRes[name]):\n",
    "            abbrevs.append('{}{}'.format(abbrev, sRes[name][0].lower() if isinstance(sRes[name], str)\n",
    "                                                 else int(sRes[name])))\n",
    "   \n",
    "    return '-'.join(abbrevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en forme pour se rapprocher du tableau de résultats manuels\n",
    "dfAutoResBest = dfAutoResBest.reindex(columns=['NObs', 'Chi2 P', 'CoefVar Densité',\n",
    "                                               'Nombre', 'Min Nombre', 'Max Nombre'])\n",
    "dfAutoResBest.reset_index(inplace=True)\n",
    "dfAutoResBest.rename(columns={'NObs': 'Nb données', 'Chi2 P': 'GOF Chi-p', 'CoefVar Densité': 'D CV',\n",
    "                              'Nombre': 'N', 'Min Nombre': 'N LCL', 'Max Nombre': 'N UCL',\n",
    "                              'Dist Tronc Drte': 'TrDrte', 'Tranch Dist Mod': 'NbTrches' }, inplace=True)\n",
    "dfAutoResBest.insert(0, 'Id EchTronc', dfAutoResBest.apply(echantTruncId, axis='columns'))\n",
    "dfAutoResBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison 1: Indicateur de proximité\n",
    "# a. Calcul\n",
    "dfProx = ads.ResultsSet.compareDataFrames(dfAutoResBest, dfManuRep, indexCols=['Id EchTronc'], subsetCols=compCols,\n",
    "                                          dropCloser=np.inf)\n",
    "\n",
    "# b. Ordre des lignes d'origine\n",
    "dfProx = dfProx.join(dfAutoResBest.reset_index(drop=False)[['Id EchTronc', 'index']].set_index('Id EchTronc'))\n",
    "dfProx.sort_values(by='index', inplace=True)\n",
    "dfProx.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Colorisation\n",
    "def proxColor(v):\n",
    "    return 'background-color: ' + scaledColorV(v, thresholds=[1.4999, 0.9999, 0.5999], colors=scaled4Colors)\n",
    "dfsProx = dfProx.reset_index().style.applymap(proxColor, subset=compCols).format('{:g}', subset=compCols)\n",
    "dfsProx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison 2 : Différence colonne à colonne\n",
    "# a. calcul\n",
    "dfDiff = dfAutoResBest.join(dfManuRep[compCols + ['Id EchTronc']].set_index('Id EchTronc'),\n",
    "                            on='Id EchTronc', rsuffix=' (m)')\n",
    "dfDiff.rename(columns={nm: nm + ' (a)' for nm in compCols}, inplace=True)\n",
    "\n",
    "for col in compCols:\n",
    "    dfDiff[col + ' (a - m)'] = dfDiff[col + ' (a)'] - dfDiff[col + ' (m)']\n",
    "\n",
    "# b. Ordre des colonnes\n",
    "colOrder = headCols = ['Id EchTronc', colEspece, 'Adulte', 'TrDrte', 'NbTrches']\n",
    "for col in compCols:\n",
    "    colOrder += [col + ' (a)', col + ' (m)', col + ' (a - m)']\n",
    "dfDiff = dfDiff.reindex(columns=colOrder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Colorisation\n",
    "def diffChi2Color(v):\n",
    "    return 'background-color: ' + scaledColorV(v, thresholds=[0.01, 0.05], colors=scaled3Colors, gt=False)\n",
    "def diffCvColor(v):\n",
    "    return 'background-color: ' + scaledColorV(v, thresholds=[0.01, 0.05], colors=scaled3Colors, gt=False)\n",
    "def diffNColor(v):\n",
    "    return 'background-color: ' + scaledColorV(v, thresholds=[1e-12], colors=scaled2Colors, gt=False)\n",
    "dfsDiff = dfDiff.style.applymap(diffChi2Color, subset=['GOF Chi-p (a - m)']) \\\n",
    "                      .applymap(diffCvColor, subset=['D CV (a - m)']) \\\n",
    "                      .applymap(diffNColor, subset=[col + ' (a - m)' for col in compCols if col.startswith('N')])\n",
    "dfsDiff.format('{:g}', subset=[col for col in dfDiff.columns if col not in headCols])\n",
    "dfsDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(dossier / 'CretesPlombCantalZPS2020-AnalysesMathis-ComparD73Auto.xlsx') as xlsWrtr:\n",
    "    dfAutoResBest.to_excel(xlsWrtr, index=False, sheet_name='Auto Meilleur AIC')\n",
    "    dfsProx.to_excel(xlsWrtr, index=False, sheet_name='ProximiteLog')\n",
    "    dfsDiff.to_excel(xlsWrtr, index=False, sheet_name='Difference')\n",
    "    dfAutoRes.to_excel(xlsWrtr, index=False, sheet_name='Auto Toutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexe. Bilan & stats données individualisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{nomEtude}{sousEtude}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects.Observateur.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects[['Observateur', 'Passage', 'Point']].groupby(['Observateur', 'Passage']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransects.Passage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Données individualisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsCatIndiv['Durée'].replace('5mn', '05mn', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsCatIndiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb total d'espèces \n",
    "display(dfObsCatIndiv['Espèce'].nunique())\n",
    "\n",
    "# Nb d'espèces par passage et durée\n",
    "df = dfObsCatIndiv[['Passage', 'Durée', 'Espèce']].groupby(['Passage', 'Durée']).nunique().unstack(-2).unstack(-1).to_frame().T\n",
    "df.columns = df.columns.droplevel(0)\n",
    "for p in ['a', 'b']:\n",
    "    df[(p, '10mn/05mn')] = (df[(p, '10mn')] - df[(p, '05mn')]) / df[(p, '05mn')]\n",
    "df.sort_index(axis='columns', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des espèces contactées par passage et durée d'inventaire (tous adultes)\n",
    "df = dfObsCatIndiv[['Passage', 'Durée', 'Espèce', 'Distance']].copy()\n",
    "df['Adulte'] = adulte = 'Tous adultes'\n",
    "df['Méthode'] = sousEtude[1:]\n",
    "\n",
    "df = df.groupby(['Espèce', 'Méthode', 'Adulte', 'Passage', 'Durée']).count().unstack(-4).unstack(-3).unstack(-2).unstack(-1)\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df.fillna(0, inplace=True)\n",
    "for duree in ['05mn', '10mn']:\n",
    "    df[(sousEtude[1:], adulte, 'b+a', duree)] = \\\n",
    "        df[(sousEtude[1:], adulte, 'a', duree)] + df[(sousEtude[1:], adulte, 'b', duree)]\n",
    "\n",
    "df.sort_values(by=[(sousEtude[1:], adulte, 'b+a', '10mn')], ascending=False, inplace=True)\n",
    "df.sort_index(axis='columns', inplace=True)\n",
    "df1 = df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des espèces contactées par passage et durée d'inventaire (mâles uniquement)\n",
    "df = dfObsCatIndiv.loc[dfObsCatIndiv.Adulte == 'm', ['Passage', 'Durée', 'Espèce', 'Distance']].copy()\n",
    "df['Adulte'] = adulte = 'Mâles uniquement'\n",
    "df['Méthode'] = sousEtude[1:]\n",
    "\n",
    "df = df.groupby(['Espèce', 'Méthode', 'Adulte', 'Passage', 'Durée']).count().unstack(-4).unstack(-3).unstack(-2).unstack(-1)\n",
    "df.columns = df.columns.droplevel(0)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "for duree in ['05mn', '10mn']:\n",
    "    df[(sousEtude[1:], adulte, 'b+a', duree)] = \\\n",
    "        df[(sousEtude[1:], adulte, 'a', duree)] + df[(sousEtude[1:], adulte, 'b', duree)]\n",
    "\n",
    "df.sort_values(by=[(sousEtude[1:], adulte, 'b+a', '10mn')], ascending=False, inplace=True)\n",
    "df.sort_index(axis='columns', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des espèces contactées par passage et durée d'inventaire (tous adultes et mâles uniquement en vis à vis)\n",
    "df1.join(df, how='outer').sort_values(by=[(sousEtude[1:], 'Tous adultes', 'b+a', '10mn')],\n",
    "                                      ascending=False) # .to_excel(f'donnees/acdc/bilan-especes{sousEtude}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idem, mais en ajoutant l'autre sous-étude en vis à vis\n",
    "autreSousEtude = '-Pap' if 'Nat' in sousEtude else '-Nat'\n",
    "df2 = pd.read_excel(f'donnees/acdc/bilan-especes{autreSousEtude}.xlsx', header=[0, 1, 2, 3], skiprows=[4], index_col=0)\n",
    "df2 = df1.join(df, how='outer').join(df2, how='outer')\n",
    "df3 = df2.sort_values(by=[(autreSousEtude[1:], 'Tous adultes', 'b+a', '10mn'), (sousEtude[1:], 'Tous adultes', 'b+a', '10mn')],\n",
    "                      ascending=False) # .to_excel('donnees/acdc/bilan-especes.xlsx')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Croisement des effectifs et des échantillons à opt-analyser (enfin ... pour les mâles a+b uniquement)\n",
    "df4 = df3[[(autreSousEtude[1:], 'Mâles uniquement', 'b+a', '05mn'), (sousEtude[1:], 'Mâles uniquement', 'b+a', '05mn'),\n",
    "           (autreSousEtude[1:], 'Mâles uniquement', 'b+a', '10mn'), (sousEtude[1:], 'Mâles uniquement', 'b+a', '10mn')]]\n",
    "df4 = df4.stack(-2)\n",
    "df4.sort_index(axis='columns', inplace=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.columns = [sousEtude[1:] + ' 05mn', sousEtude[1:] + ' 10mn',\n",
    "               autreSousEtude[1:] + ' 05mn', autreSousEtude[1:] + ' 10mn']\n",
    "df4.reset_index(inplace=True)\n",
    "df4.rename(columns=dict(level_0='Espèce'), inplace=True)\n",
    "df4['Adulte'] = 'm'\n",
    "df4.Passage.replace('b+a', 'a+b', inplace=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExplOptAnlysSpecs = pd.read_excel(dossier / f'{nomEtude}{sousEtude}-ExplOptAnlysSpecs.xlsx', index_col=0)\n",
    "dfSubEchants = dfExplOptAnlysSpecs[['Espèce', 'Passage', 'Adulte']].drop_duplicates()\n",
    "dfSubEchants.join(df4.set_index(['Espèce', 'Passage', 'Adulte']),\n",
    "                  on=['Espèce', 'Passage', 'Adulte']).to_excel('donnees/acdc/bilan-echants.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbre d'individus adultes contactés par passage et durée d'inventaire\n",
    "df = dfObsCatIndiv\n",
    "\n",
    "df = df[['Passage', 'Durée', 'Adulte']].groupby(['Passage', 'Durée']).count().unstack(-2)\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df.sort_index(axis='columns', inplace=True)\n",
    "\n",
    "print('05mn => 10mn : +', 100 * (df.loc['10mn'].sum() - df.loc['05mn'].sum()) / df.loc['05mn'].sum(), '%')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.unstack(-1).to_frame().T\n",
    "for p in ['a', 'b']:\n",
    "    df[(p, '10mn/05mn')] = (df[(p, '10mn')] - df[(p, '05mn')]) / df[(p, '05mn')]\n",
    "df.sort_index(axis='columns', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbre d'individus mâles contactés par passage et durée d'inventaire\n",
    "df = dfObsCatIndiv[dfObsCatIndiv.Adulte == 'm']\n",
    "\n",
    "df = df[['Passage', 'Durée', 'Adulte']].groupby(['Passage', 'Durée']).count().unstack(-2)\n",
    "df.columns = df.columns.droplevel(0)\n",
    "\n",
    "print('05mn => 10mn : +', 100 * (df.loc['10mn'].sum() - df.loc['05mn'].sum()) / df.loc['05mn'].sum(), '%')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.unstack(-1).to_frame().T\n",
    "for p in ['a', 'b']:\n",
    "    df[(p, '10mn/5mn')] = (df[(p, '10mn')] - df[(p, '05mn')]) / df[(p, '05mn')]\n",
    "df.sort_index(axis='columns', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexe. Tests non régression suite évolutions pyaudisam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non régression rapports auto-filtrés\n",
    "\n",
    "* suite optimisation calcul indicateurs qualité 28/11/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load reference and target = \"current\" report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference report\n",
    "fpnRefRep, cmpSfx = workDir / 'ACDC2019-Nat-OptAnalyses-rapport.q3.211104.ods', 'q3211104'\n",
    "#fpnRefRep = workDir / 'ACDC2019-Nat-OptAnalyses-rapport.211121.xlsx'\n",
    "\n",
    "ddfRefRep = pd.read_excel(fpnRefRep, sheet_name=None)\n",
    "\n",
    "# Get \"all results\" sheet (ref report)\n",
    "dfRefRes = ddfRefRep['Détails']\n",
    "\n",
    "print(', '.join(ddfRefRep.keys()))\n",
    "\n",
    "#snRefPrfx = 'AFSM-'\n",
    "snRefPrfx = 'MFTA-'\n",
    "{sn[len(snRefPrfx):]: len(ddfRefRep[sn]) for sn in ddfRefRep if sn.startswith(snRefPrfx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last generated report\n",
    "#fpnCurRep, curSfx = workDir / 'ACDC2019-Nat-OptAnalyses-rapport.211121.xlsx', '1121'\n",
    "fpnCurRep, curSfx = workDir / 'ACDC2019-Nat-OptAnalyses-rapport.211128.xlsx', '1128'\n",
    "\n",
    "cmpSfx += curSfx\n",
    "\n",
    "ddfCurRep = pd.read_excel(fpnCurRep, sheet_name=None)\n",
    "\n",
    "# Get \"all results\" sheet (last report)\n",
    "dfCurRes = ddfCurRep['Détails']\n",
    "\n",
    "print(', '.join(ddfCurRep.keys()))\n",
    "\n",
    "snCurPrfx = 'MFTA-'\n",
    "{sn[len(snCurPrfx):]: len(ddfCurRep[sn]) for sn in ddfCurRep if sn.startswith(snCurPrfx)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compare quality indicators\n",
    "\n",
    "(for all results, not only filterd ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quaCols = [col for col in dfRefRes.columns if col.startswith('Qual ')]\n",
    "\n",
    "dfRelDiff = ads.DataSet.compareDataFrames(dfRefRes, dfRes, indexCols=[anlysIndCol], subsetCols=quaCols,\n",
    "                                          dropCloser=14, dropCloserCols=True)\n",
    "\n",
    "dfRelDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other comparison of QualBal1\n",
    "dfComp = dfRefRes[['Qual Equi 1']].compare(dfRes[['Qual Equi 1']])\n",
    "dfComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other comparison of QualBal1\n",
    "dfComp = dfRefRes[['Qual Equi 3']].compare(dfRes[['Qual Equi 3']])\n",
    "dfComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBadRes = dfRes.loc[dfComp.index]\n",
    "\n",
    "#dfBadRes.to_excel('tmp/_.xlsx')\n",
    "\n",
    "assert dfBadRes[~dfBadRes['Chi2 P'].isnull() & (dfBadRes['Chi2 P'] > 0.1)].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare lists of auto-filtered analyses and check differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampParamCols = ['Echant', 'Espèce', 'Passage', 'Adulte', 'Durée',\n",
    "                 'FonctionClé', 'SérieAjust', 'TrGche', 'TrDrte', 'NbTrchMod']\n",
    "mcdsQuaCols = ['Taux Obs', 'NbPars SérAjust', 'Delta AIC', 'Chi2 P', 'KS P', 'CvM Uw P', 'CvM Cw P', 'CoefVar Densité']\n",
    "balQuaCols = ['Qual Equi 1', 'Qual Equi 2', 'Qual Equi 3']  # , 'Qual Chi2+', 'Qual KS+', 'Qual DCv+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1 reference auto-filtered sheet\n",
    "snAfsRefRes = 'ExAicMQua-r925d12'  # q3.211104\n",
    "#snAfsRefRes = 'ExAicMQua-r925m8q3d12'  # 211121 and on ...\n",
    "\n",
    "dfAfsRefRes = ddfRefRep[snRefPrfx + snAfsRefRes]\n",
    "\n",
    "dfAfsRefRes[[anlysIndCol] + sampParamCols + mcdsQuaCols + balQuaCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1 last report auto-filtered sheet\n",
    "snAfsCurRes = 'ExAicMQua-r925m8q3d12'  # 211121 and on ...\n",
    "cmpSfx += '-' + snAfsCurRes.split('-')[-1]\n",
    "dfAfsCurRes = ddfCurRep[snPrfx + snAfsCurRes]\n",
    "\n",
    "dfAfsCurRes[[anlysIndCol] + sampParamCols + mcdsQuaCols + balQuaCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKptAnls = dfRefRes[[anlysIndCol] + sampParamCols + mcdsQuaCols + balQuaCols].copy()\n",
    "\n",
    "dfKptAnls.loc[dfKptAnls[anlysIndCol].isin(dfAfsRefRes[anlysIndCol]), 'Ref'] = 1\n",
    "dfKptAnls.loc[dfKptAnls[anlysIndCol].isin(dfAfsCurRes[anlysIndCol]), 'Cur'] = 1\n",
    "\n",
    "dfKptAnls = dfKptAnls.join(dfCurRes[[anlysIndCol] + balQuaCols].set_index(anlysIndCol), on=anlysIndCol, rsuffix=' Cur')\n",
    "for quaCol in balQuaCols:\n",
    "    dfKptAnls[quaCol + ' Cur - Ref'] = dfKptAnls[quaCol] - dfKptAnls[quaCol + ' Cur']\n",
    "\n",
    "dfKptAnls = dfKptAnls[(dfKptAnls.Ref == 1) | (dfKptAnls.Cur == 1)]\n",
    "\n",
    "dfKptAnls.sort_values(by=['Echant', 'TrGche', 'TrDrte'], ascending=True, na_position='first', inplace=True)\n",
    "\n",
    "dfKptAnls.to_excel(workDir / f'{nomEtude}{sousEtude}{varEtude}-nonreg.{cmpSfx}.xlsx', index=False)\n",
    "\n",
    "dfKptAnls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non régression ACDC 2019 suite correction décodage effectifs 09/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn = dossier / f'{nomEtude}{sousEtude}-ObsIndivDist.xlsx'\n",
    "\n",
    "with pd.ExcelFile(fpn) as xlsFile:\n",
    "    \n",
    "    dfNewObs = pd.read_excel(xlsFile, sheet_name='Donnees')\n",
    "    dfNewInv = pd.read_excel(xlsFile, sheet_name='Inventaires')\n",
    "\n",
    "dict(etude=nomEtude, donnees=len(dfNewObs), inventaires=len(dfNewInv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn = dossier / 'ACDC2019-Naturalist-ObsIndivAvecDist.deprec.xlsx'\n",
    "\n",
    "with pd.ExcelFile(fpn) as xlsFile:\n",
    "    \n",
    "    dfOldObs = pd.read_excel(xlsFile, sheet_name='Donnees')\n",
    "    dfOldInv = pd.read_excel(xlsFile, sheet_name='Inventaires')\n",
    "\n",
    "dict(etude=nomEtude, donnees=len(dfOldObs), inventaires=len(dfOldInv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obs. individualisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNewObs = dfObsCatIndiv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewObs = dfNewObs[['Observateur', 'Point', 'Passage', 'Date', 'Horaire', 'Espèce', 'Distance', 'Adulte', 'Durée']]\n",
    "dfNewObs['DateHeure'] = dfNewObs[['Date', 'Horaire']].apply(lambda s: pd.Timestamp(s.Date) + pd.Timedelta(s.Horaire + ':00'),\n",
    "                                                            axis='columns')\n",
    "dfNewObs.Distance = dfNewObs.Distance.round(6)\n",
    "dfNewObs = dfNewObs.reindex(columns=['Observateur', 'Point', 'Passage', 'DateHeure', 'Espèce', 'Distance', 'Adulte', 'Durée'])\n",
    "dfNewObs.sort_values(by=list(dfNewObs.columns), inplace=True)\n",
    "dfNewObs.reset_index(inplace=True, drop=True)\n",
    "dfNewObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOldObs.Distance = dfOldObs.Distance.round(6)\n",
    "dfOldObs.sort_values(by=list(dfNewObs.columns), inplace=True)\n",
    "dfOldObs.reset_index(inplace=True, drop=True)\n",
    "dfOldObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewObs.equals(dfOldObs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewObs[dfNewObs.Durée != dfOldObs.Durée]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawObs = vnds.sightings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawObs.loc[(dfRawObs.Observateur == 'Romain Riols') & (dfRawObs['Espèce'] == 'Passer domesticus')\n",
    "             & (dfRawObs.Distance.round(1).isin([42.6, 57.0, 85.6])), obsBrutesColsAff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawObs.loc[(dfRawObs.Observateur == 'Romain Riols') & (dfRawObs['Espèce'] == 'Passer domesticus')\n",
    "              & (dfRawObs['Code atlas'] == 5), obsBrutesColsAff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inventaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNewInv = dfInventaires.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewInv = dfNewInv.drop(columns=['ID liste']).sort_values(by=['Point', 'Passage']).reset_index(drop=True)\n",
    "dfNewInv['Effort'] = effortConst\n",
    "dfNewInv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOldInv = dfOldInv[dfNewInv.columns].sort_values(by=['Point', 'Passage']).reset_index(drop=True)\n",
    "dfOldInv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dfNewInv.equals(dfOldInv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non régression ZPS Cantal 2020 suite généralisation NB 11/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repCols4Comp = ['Echant',\n",
    "                'NObs', 'Effort', 'AIC', 'Chi2 P', 'KS P',\n",
    "                'CoefVar Densité', 'EDR/ESW', 'Min EDR/ESW',\n",
    "                'Max EDR/ESW', 'Densité', 'Min Densité', 'Max Densité',\n",
    "                'PDetec', 'Min PDetec', 'Max PDetec',\n",
    "                'DegLib PDetec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewRep = pd.read_excel(dossier / '201116-1938/CretesPlombCantalZPS2020-OptAnalyses-CommeMathis-rapport.xlsx', index_col=0)\n",
    "dfNewRep = dfNewRep.set_index('Analyse', drop=True)[repCols4Comp].sort_index()\n",
    "dfNewRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOldRep = pd.read_excel(dossier / '201010-2206/CretesPlombCantalZPS2020-OptAnalyses-CommeMathis-rapport.xlsx', index_col=0)\n",
    "dfOldRep = dfOldRep.set_index('Analyse', drop=True)[repCols4Comp].sort_index()\n",
    "dfOldRep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewRep.equals(dfOldRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewRep.compare(dfOldRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bac à sable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

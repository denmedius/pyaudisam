{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Auto table of contents -->\n",
    "<h1 class='tocIgnore'>Naturalist : Extraction et exploitation des traces</h1>\n",
    "<ul>\n",
    "  <li>présentes dans les formulaires à partir Naturalist V0.128 (ou beta mai 2019),</li>\n",
    "  <li>à condition de cocher la case \"Enregistrer ma trace\" en début de formulaire,</li>\n",
    "  <li>via l'export Excel exclusivement\n",
    "      (pas encore d'API pour ça, et absent des exports XML, JSON, KML, CSV en décembre 2019),</li>\n",
    "  <li>avec la colonne \"trace\" sélectionnée dans l'export,</li>\n",
    "  <li>uniquement via Faune-France (pas dispo. via les sites régionaux).</li>\n",
    "</ul>\n",
    "<p>Lecture XLSX et carto. publiée avec données anonymisées sur https://framagit.org/lpo/partage-de-codes le 25/01/2020</p>\n",
    "<div style=\"overflow-y: auto\">\n",
    "  <h2 class='tocIgnore'>Table des matières</h2>\n",
    "  <div id=\"toc\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib as pl\n",
    "import datetime as dt\n",
    "from lxml import etree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import folium\n",
    "import folium.plugins\n",
    "\n",
    "import pyproj\n",
    "from shapely import geometry\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict as odict\n",
    "import json\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import autods as ads\n",
    "import visionat as vsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging.\n",
    "import logging\n",
    "\n",
    "# Setup given logger.\n",
    "def setupLogger(logr, level=logging.ERROR, handlers=[sys.stdout], fileMode='w',\n",
    "                format='%(asctime)s %(name)s %(levelname)s\\t%(message)s'):\n",
    "    \n",
    "    # Cleanup any default handler (jupyter does some logging initialisation itself ...)\n",
    "    while logr.handlers:\n",
    "        logr.removeHandler(logr.handlers[-1])\n",
    "\n",
    "    # Set new handlers\n",
    "    formatter = logging.Formatter(format)\n",
    "    \n",
    "    # Set level\n",
    "    logr.setLevel(level)\n",
    "    \n",
    "    # Setup new handlers\n",
    "    for hdlr in handlers:\n",
    "        if isinstance(hdlr, str):\n",
    "            handler = logging.FileHandler(hdlr, mode=fileMode)\n",
    "        else:\n",
    "            handler = logging.StreamHandler(stream=hdlr)\n",
    "        handler.setFormatter(formatter)\n",
    "        logr.addHandler(handler)\n",
    "    \n",
    "    def handlerId(hdlr):\n",
    "        return 'File({})'.format(hdlr) if isinstance(hdlr, str) else 'Stream({})'.format(hdlr.name)\n",
    "    logr.info('Logging to {}.'.format(', '.join(handlerId(hdlr) for hdlr in handlers)))\n",
    "\n",
    "    return logr\n",
    "\n",
    "# Local (NB) logger\n",
    "setupLogger(logging.getLogger('autods'), level=logging.INFO,\n",
    "            handlers=[sys.stdout, 'tmp/natrans.log'])\n",
    "setupLogger(logging.getLogger('visionat'), level=logging.INFO,\n",
    "            handlers=[sys.stdout, 'tmp/natrans.log'])\n",
    "logger = setupLogger(logging.getLogger('natrans'), level=logging.DEBUG,\n",
    "                     handlers=[sys.stdout, 'tmp/natrans.log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Chargement des données (issues d'exports de Faune-France)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paramètres d'import / filtrage (fichier, observateur, commentaire liste, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracesManu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACDC 2019 JPM (en fait, trace enregistrée uniquement sur le 2nd passage, et pour 15 points sur 17)\n",
    "ficSrcVN = 'tmp/ACDC2019-Naturalist-FormulairesJPM2019040720190602ff.xlsx'\n",
    "obser, obserAbbv = 'Jean-Philippe Meuret', 'JPM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulaires Romain avec trace du 25/05/2019 au 25/01/2020 (tous)\n",
    "# * Impluvium: \"epoc\" & Saint-Ours, Pulvérières, Charbonnière-les-Varennes\n",
    "# * et le reste : des EPOC et des transects\n",
    "ficSrcVN = 'tmp/FormulairesRR-traces-20190525-20200125ff.xlsx'\n",
    "comntRE = 'ACDC'\n",
    "obser, obserAbbv = 'Romain Riols', 'RR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACDC 2019 Romain 25/05/2019\n",
    "ficSrcVN = 'tmp/ACDC2019-Naturalist-FormulairesRR20190425ff.xlsx'\n",
    "comntRE = 'ACDC'\n",
    "obser, obserAbbv = 'Romain Riols', 'RR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JPM jardin 23/05/2019\n",
    "#ficSrcVN = f'tmp/NaturalistTestTrace-JardinJPM20190523ff.xlsx'\n",
    "#comntRegexp = '???'\n",
    "#obser, obserAbbv = 'Jean-Philippe Meuret', 'JPM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transects Vergers de Tallende Cyrille printemps 2020\n",
    "ficSrcVN = 'transects/ExportTransects2020T2-CJS-FF.xlsx'\n",
    "comntRE = 'verger.*tallende'\n",
    "obser, obserAbbv = 'Cyrille Jallageas', 'CJS'\n",
    "tracesManu = True # False pour utiliser les traces Naturalist (bruitées !)\n",
    "nomEtude = 'TallendeVergers2020'\n",
    "dZoneEtude = dict(Zone='Vergers de Tallende', Surface=150) # ha\n",
    "groupage = False # Clustering analyses DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsCols = ['ID liste', 'Liste complète ?', 'Commentaire de la liste',\n",
    "           'Date', 'Ref', 'Horaire', 'Lieu-dit', 'Commune', 'Nom scientifique',\n",
    "           'Estimation', 'Nombre', 'Détails', 'Code atlas',\n",
    "           'Lat (WGS84)', 'Lon (WGS84)', 'UTM X [m]', 'UTM Y [m]', 'Remarque', 'Trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions pour certaines colonnes calculées.\n",
    "def nomTransect(sSight):\n",
    "    \n",
    "    listCmnt = sSight['Commentaire de la liste']\n",
    "    if pd.isnull(listCmnt):\n",
    "        return None\n",
    "    \n",
    "    if listCmnt.lower().find('transect s') >= 0:\n",
    "        return 'Sud2'  # Attention: Il y aura un Sud1 \"fait à la main\" (voir ci-dessous).\n",
    "    \n",
    "    return 'Nord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sightCountsParser = vsn.SightingCountsParser(atlasCodex='EBCC',  # Le codex des codes Atlas est l'EBCC sur FF !\n",
    "                                             categoryCols=['nMalAd', 'nAutAd', 'nJuv', 'nVol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds = vsn.VisionatureDataSet(ficSrcVN, keepCols=obsCols, dCompCols=dict(Transect=nomTransect), \n",
    "                              listExtraCols=['Transect'], \n",
    "                              listsHaveTrace=True, listTraceLengthCol='Longueur',\n",
    "                              sightCountsParser=sightCountsParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData['Commentaire de la liste'].nunique(), vnds.dfData['Commentaire de la liste'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Filtrage des données\n",
    "\n",
    "* formulaires\n",
    "* avec commentaire ad-hoc (si spécifié via comntRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquement les données des formulaires\n",
    "vnds.cleanup(nonLists=True)\n",
    "#vnds.dropRows(vnds.dfData['ID liste'] == 0)\n",
    "len(vnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquement les données respectant le critère de commentaire liste\n",
    "if comntRE:\n",
    "    vnds.dropRows(vnds.dfData['Commentaire de la liste'].isnull())\n",
    "    vnds.dropRows(~vnds.dfData['Commentaire de la liste'].str.contains(comntRE, case=False))\n",
    "len(vnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquement les formulaires avec trace si on ne les a pas par ailleurs\n",
    "if not tracesManu:\n",
    "    vnds.cleanup(emptyTraces=True)\n",
    "\n",
    "len(vnds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Autres filtrages / traitements spécifiques des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transects de Cyrille dans les vergers de Tallende au printemps 2020\n",
    "\n",
    "* séparation du 1er transect (28/03) en 2 transects : le Nord (comme les autres jours),\n",
    "  et un Sud2 jamais refait (étape 1 : suppression des données ; il restera à nettoyer la trace, Cf. ci-dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des données entre le demi-transect  Nord et le demi-Sud2 (1er tronçons ~N-S)\n",
    "vnds.dropRows((vnds.dfData['Date'] == '2020-03-28')\n",
    "              & (vnds.dfData['Horaire'] > '09:37') & (vnds.dfData['Horaire'] < '09:45'))\n",
    "\n",
    "# Suppression des données entre le demi-transect Sud2 et retour au point de dé part (2nd tronçons ~N-S)\n",
    "vnds.dropRows((vnds.dfData['Date'] == '2020-03-28') & (vnds.dfData['Horaire'] > '10:13'))\n",
    "\n",
    "# Création d'une nouvelle liste pour le demi-tracsect Sud2\n",
    "idNouvListe = vnds.dfData.loc[vnds.dfData['Date'] == '2020-03-28', 'ID liste'].iloc[0] + 1\n",
    "assert idNouvListe not in vnds.dfData['ID liste']\n",
    "\n",
    "vnds.dfData.loc[(vnds.dfData['Date'] == '2020-03-28')\n",
    "                & (vnds.dfData['Horaire'] >= '09:45') & (vnds.dfData['Horaire'] <= '10:13'),\n",
    "                ['ID liste', 'Transect']] = idNouvListe, 'Sud1'\n",
    "\n",
    "len(vnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData[['Transect', 'ID liste', 'Date', 'Commentaire de la liste', 'Trace']] \\\n",
    "    .drop_duplicates(['Date', 'ID liste'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Examen des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs = vnds.dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toutes des listes complètes ?\n",
    "dfObs[dfObs['Liste complète ?'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier que la trace de chaque liste est présente à l'identique dans toutes les données de la liste\n",
    "dfObs[['ID liste', 'Date', 'Trace']].groupby(['ID liste', 'Date']).nunique().Trace.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb de traces identique par liste\n",
    "dfObs[['ID liste', 'Date', 'Trace']].groupby(['ID liste', 'Date']).nunique().Trace.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les formulaires à traiter\n",
    "dfObs[['ID liste', 'Liste complète ?', 'Commentaire de la liste']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbres de données par liste\n",
    "dfObs.groupby(['Transect', 'ID liste', 'Date']).count()[['Nombre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbres de données moyen par transect type\n",
    "dfObs.groupby(['Transect', 'ID liste', 'Date']).count()[['Nombre']] \\\n",
    "     .reset_index().groupby('Transect').mean()[['Nombre']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Extraction / décodage des traces GPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A partir des données de terrain (colonne Trace)\n",
    "\n",
    "(mais ... attention à la qualité ... imprécision GPS !)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Extraction / décodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tracesManu:\n",
    "    \n",
    "    dfTracesGps = vnds.listTraces()\n",
    "    \n",
    "    print(dfTracesGps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Correction spécifiques après décodage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Transects de Cyrille dans les vergers de Tallende au printemps 2020\n",
    "\n",
    "Après III.1, les 2 1ères listes ont la même trace trop longue correspondant à la boucle du 28/03 ;\n",
    "il faut donc les néttoyer pour obtenir : liste 876746 = transet Nord, liste 876747 = transect Sud1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tracesManu:\n",
    "    \n",
    "    print('avant :', len(dfTracesGps))\n",
    "    \n",
    "    # Nettoyage de la trace de la 876746 => transect Nord\n",
    "    sLabels2Drop = dfTracesGps[(dfTracesGps['ID liste'] == 876746) & ~(dfTracesGps.ptIndx.between(8, 170))].index\n",
    "    dfTracesGps.drop(sLabels2Drop, inplace=True)\n",
    "    \n",
    "    # Nettoyage de la trace de la 876747 => transect Sud1\n",
    "    sLabels2Drop = dfTracesGps[(dfTracesGps['ID liste'] == 876747) & ~(dfTracesGps.ptIndx.between(199, 325))].index\n",
    "    dfTracesGps.drop(sLabels2Drop, inplace=True)\n",
    "\n",
    "    print('après :', len(dfTracesGps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tracesManu:\n",
    "    \n",
    "    print(dfTracesGps[dfTracesGps['ID liste'] == 876746])\n",
    "    print(dfTracesGps[dfTracesGps['ID liste'] == 876747])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Remplacement des traces dans le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tracesManu:\n",
    "    \n",
    "    # Ecrasement des traces du jeu de données\n",
    "    vnds.setListTraces(dfTracesGps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tracesManu:\n",
    "    \n",
    "    dfTracesGps = vnds.listTraces()\n",
    "    print(len(dfTracesGps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tracesManu:\n",
    "    \n",
    "    print(dfTracesGps[dfTracesGps['ID liste'] == 876746])\n",
    "    print(dfTracesGps[dfTracesGps['ID liste'] == 876747])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A partir de traces précises obtenues par ailleurs\n",
    "\n",
    "* tracés précisément à la main via GeoPortail,\n",
    "* pas de pb avec l'imprécision crasse du GPS,\n",
    "* en remplacement des traces relevées ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.lists().drop(columns='Trace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Transects de Cyrille dans les vergers de Tallende au printemps 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tracesManu:\n",
    "    \n",
    "    dTraces = { sList['ID liste']: f'transects/Transect{sList.Transect}-VergersTallende-CJS-2020T2.kml' \\\n",
    "                for _, sList in vnds.lists().iterrows() }\n",
    "\n",
    "    vnds.setListTraces(dTraces)\n",
    "    \n",
    "    print(vnds.listTraces().head(10))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('On va utiliser les traces Naturalist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. (optionnel) Cartographie des données et traces des formulaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serveurs et couches carto. pour folium / Leaflet\n",
    "mdOSM = dict(tiles='http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', \n",
    "             attr='Open Street Map',\n",
    "             name='Open Street Map', max_zoom=22, photo=False)\n",
    "\n",
    "mdOTM = dict(tiles='http://{s}.tile.opentopomap.org/{z}/{x}/{y}.png',\n",
    "             attr='<a href=\"https://opentopomap.org/\">OpenTopoMap</a> '\n",
    "                  '(<a href=\"https://creativecommons.org/licenses/by-sa/3.0/\">CC-BY-SA</a>)',\n",
    "             name='Open Topo Map', max_zoom=22, photo=False)\n",
    "mdThOut = dict(tiles='https://{s}.tile.thunderforest.com/outdoors/{z}/{x}/{y}.png',\n",
    "               attr='Thunderforest Outdoors', \n",
    "               name='Thunderforest Outdoors', max_zoom=22, photo=False)\n",
    "\n",
    "mdSatArcGis = dict(tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "                   attr='Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid,'\n",
    "                        ' IGN, IGP, UPR-EGP, and the GIS User Community',\n",
    "                   name='ArcGIS Satellite', max_zoom=22, photo=True)\n",
    "\n",
    "def sight2String(sSight):\n",
    "    \n",
    "    ref = sSight['Ref'] if 'Ref' in sSight.index else ''\n",
    "    \n",
    "    esp = ''.join(w[:4].title() for w in sSight['Nom scientifique'].split())\n",
    "    \n",
    "    if 'nMalAd' in sSight.index:\n",
    "        nbre = ', '.join('{}={}'.format(col, int(sSight[col])) \\\n",
    "                         for col in ['nMalAd', 'nAutAd', 'nJuv', 'nVol'] \\\n",
    "                         if col in sSight.index and not pd.isnull(sSight[col]) and sSight[col] > 0)\n",
    "    else:\n",
    "        nbre = str(int(sSight.Nombre))\n",
    "        if not pd.isnull(sSight['Détails']):\n",
    "            nbre += '[{}]'.format(sSight['Détails'])\n",
    "        \n",
    "    dist = ('d='+str(int(sSight['Distance']))) if 'Distance' in sSight.index else ''\n",
    "    codAtlas = 0 if pd.isnull(sSight['Code atlas']) else int(sSight['Code atlas'])\n",
    "                                \n",
    "    return '#{} {} {} {} {} (code {}) {}'.format(ref, sSight.Date.date().isoformat(), sSight.Horaire,\n",
    "                                                 esp, nbre, codAtlas, dist)\n",
    "    \n",
    "# Colors for sightings and traces, wether the map layer is a photo (dark) or not (clear).\n",
    "DColors = { True: dict(sight='greenyellow', trace=dict(point='magenta', segment='cyan')), \n",
    "            False: dict(sight='green', trace=dict(point='red', segment='mediumblue')) }\n",
    "\n",
    "def color(mapSrc, sightPoint=False, tracePoint=False, traceSegment=False):\n",
    "    isMapDark = mapSrc['photo']\n",
    "    dColors = DColors[isMapDark]\n",
    "    if sightPoint:\n",
    "        clr = dColors['sight']\n",
    "    elif tracePoint:\n",
    "        clr = dColors['trace']['point']\n",
    "    elif traceSegment:\n",
    "        clr = dColors['trace']['segment']\n",
    "    else:\n",
    "        raise Exception('No target selected for color')\n",
    "        \n",
    "    return clr\n",
    "    \n",
    "def showOnMap(dfTrace, dfSights, trTitle='', mapSrc=mdOSM, sight2String=sight2String):\n",
    "    \n",
    "    mp = folium.Map(**mapSrc)\n",
    "\n",
    "    # La trace\n",
    "    # a. Les lignes reliant les points\n",
    "    dfTrace = dfTrace.append(dfTrace.iloc[-1]) # Duplicate last points to keep all after shift below\n",
    "    dfTrace['lon_sfd'] = dfTrace.lon.shift(-1)\n",
    "    dfTrace['lat_sfd'] = dfTrace.lat.shift(-1)\n",
    "    dfTrace.dropna(inplace=True)\n",
    "\n",
    "    lines = list(zip(zip(dfTrace.lat, dfTrace.lon), zip(dfTrace.lat_sfd, dfTrace.lon_sfd)))[:-1]\n",
    "    pline = folium.PolyLine(lines, color=color(mapSrc, traceSegment=True),\n",
    "                            weight=1, opacity=0.6, popup=folium.Popup(trTitle))\n",
    "    pline.add_to(mp)\n",
    "\n",
    "    # b. Les points\n",
    "    for _, sPt in dfTrace.iterrows():\n",
    "        mrk = folium.CircleMarker(location=(sPt.lat, sPt.lon), \n",
    "                                  popup=folium.Popup('#{}: {}'.format(sPt['ID liste'], sPt.ptIndx)),\n",
    "                                  color=color(mapSrc, tracePoint=True),\n",
    "                                  radius=2, weight=2, fill=True)\n",
    "        mrk.add_to(mp)\n",
    "\n",
    "    # Les données\n",
    "    for indSight, sSight in dfSights.iterrows():\n",
    "        mrk = folium.CircleMarker(location=(sSight.lat, sSight.lon), radius=3, \n",
    "                                  color=color(mapSrc, sightPoint=True), fill=True,\n",
    "                                  popup=folium.Popup('#{}: {}'.format(indSight, sight2String(sSight))))\n",
    "        mrk.add_to(mp)\n",
    "\n",
    "    mp.fit_bounds(mp.get_bounds())\n",
    "    \n",
    "    return mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(', '.join(str(date.date()) for date in vnds.dfData.Date.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les listes\n",
    "vnds.lists().drop(columns='Trace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sélection des listes à tracer en même temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.lists().groupby('Date').apply(lambda df: df['ID liste'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soit en dur.\n",
    "dfListes = vnds.lists(ids=[876746]) #[955938, 956038] #[880581, 880582] #[876746]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soit: Iteration sur les listes du jeu de données, groupées par dates\n",
    "itListes = iter(vnds.lists().groupby('Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListes = next(itListes)[1]\n",
    "dfListes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extraction des points des traces du jour et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsListes = dfListes['ID liste'].values\n",
    "\n",
    "dfTracesJour = vnds.listTraces(listIds=idsListes)\n",
    "\n",
    "dfObsJour = vnds.sightings(listIds=idsListes)\n",
    "\n",
    "dict(listes=idsListes, obs=len(dfObsJour), traces=len(dfObsJour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsJour[['Lon (WGS84)', 'Lat (WGS84)', 'Date', 'Horaire',\n",
    "           'Nom scientifique', 'Détails', 'Nombre', 'Code atlas']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tracé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOnMap(dfTracesJour,\n",
    "          dfObsJour.rename(columns={'Lon (WGS84)': 'lon', 'Lat (WGS84)': 'lat' }), mapSrc=mdOSM,\n",
    "          trTitle='#{} {}'.format(','.format(list(idsListes)), list(vnds.lists(ids=idsListes)['Transect'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfListes.drop(columns='Trace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Décodage des effectifs comptés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vnds.computeSightingCounts()\n",
    "\n",
    "vnds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData[['ID liste', 'Horaire', 'Date', 'Nom scientifique',\n",
    "             'Nombre', 'Détails', 'Code atlas', 'nMalAd', 'nAutAd', 'nJuv', 'nVol']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData[['nMalAd', 'nAutAd', 'nJuv', 'nVol']].sum().sum(), vnds.dfData['Nombre'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.toExcel('tmp/after.xlsx') # => Vérifier à l'oeil les effectifs de détail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData['Détails'].fillna('').str.contains('vol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.dfData.loc[vnds.dfData['Détails'].fillna('').str.contains('vol'),\n",
    "                ['ID liste', 'Horaire', 'Date', 'Nom scientifique',\n",
    "                 'Nombre', 'Détails', 'Code atlas', 'nMalAd', 'nAutAd', 'nJuv', 'nVol']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII. Calcul des distances observateur - oiseau\n",
    "\n",
    "(la distance minimale entre l'oiseau et la poly-ligne du transect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.computeTraceSightDistances(distanceCol='Distance')\n",
    "\n",
    "vnds.dfData[['ID liste', 'Horaire', 'Date', 'Nom scientifique',\n",
    "             'Nombre', 'Détails', 'Code atlas', 'nMalAd', 'nAutAd', 'nJuv', 'nVol', 'Distance']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(vnds.dfData.Distance, bins=10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vnds.dfData.Distance.hist(figsize=(16, 4), bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IX. Extraction des inventaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les inventaires (les transects)\n",
    "dfInventaires = vnds.lists(columns=['ID liste', 'Date', 'Transect', 'Longueur']).copy()\n",
    "dfInventaires.Longueur = dfInventaires.Longueur.astype(int)\n",
    "dfInventaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X. Individualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes d'effectifs à prendre en compte (on ignore les autres)\n",
    "countCols =  ['nMalAd', 'nAutAd']\n",
    "\n",
    "# Calcul des catégories : 1 seule, \"Adulte\" = Mâle ou Autre.\n",
    "def count2AdultCat(sCounts):\n",
    "    return 'm' if 'Mal' in sCounts[sCounts > 0].index[0] else 'a'\n",
    "\n",
    "# Création d'un FieldDataSet\n",
    "fds = ads.FieldDataSet(vnds.sightings(), countCols=countCols, addMonoCatCols={ 'Adulte': count2AdultCat })\n",
    "\n",
    "# ... pour individualiser et catégoriser les données.\n",
    "dfObsCatIndiv = fds.individualise()\n",
    "print(dfObsCatIndiv[countCols].sum().to_dict(), 'individus')\n",
    "\n",
    "# On ne garde que les colonnes utiles (comptes à 0 ou 1 <=> catégories), et avec des noms améliorés\n",
    "dfObsCatIndiv = dfObsCatIndiv[['ID liste', 'Date', 'Transect',\n",
    "                               'Horaire', 'Nom scientifique', 'Distance', 'Adulte']].copy()\n",
    "dfObsCatIndiv.rename(columns={ 'Nom scientifique': 'Espèce' }, inplace=True)\n",
    "\n",
    "print(len(dfObsCatIndiv), 'individus au total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les colonnes utiles (comptes à 0 ou 1 <=> catégories), et avec des noms améliorés\n",
    "dfObsCatIndiv = dfObsCatIndiv[['ID liste', 'Date', 'Transect',\n",
    "                               'Horaire', 'Espèce', 'Distance', 'Adulte']].copy()\n",
    "len(dfObsCatIndiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsCatIndiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des données et inventaires.\n",
    "nomFicCible = pl.Path('transects') / f'{nomEtude}-ObsIndiv.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(nomFicCible) as xlsWriter:\n",
    "    \n",
    "    dfObsCatIndiv.to_excel(xlsWriter, index=False, sheet_name='Donnees')\n",
    "    dfInventaires.to_excel(xlsWriter, index=False, sheet_name='Inventaires')\n",
    "    \n",
    "print(nomFicCible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X. Export pour analyses dans Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sélection et définition des échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "especes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examen des données : Nombre d'individus par espèce, pour voir quelles espèces on va analyser\n",
    "if groupage: # Clustering lors des analyses DS\n",
    "    dfIndivCounts = dfObsCatIndiv[['Espèce', 'Nombre']].groupby('Espèce').sum()\n",
    "    dfIndivCounts.rename(columns=dict(Nombre='Individus'), inplace=True)\n",
    "else:\n",
    "    dfIndivCounts = dfObsCatIndiv[['Espèce', 'Distance']].groupby('Espèce').count()\n",
    "    dfIndivCounts.rename(columns=dict(Distance='Individus'), inplace=True)\n",
    "\n",
    "dfIndivCounts.sort_values(by='Individus', ascending=False, inplace=True)\n",
    "\n",
    "dfIndivCounts[dfIndivCounts.Individus >= especes if isinstance(especes, int) else 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec. implicite des variantes (=> combinaisons à générer automatiquement)\n",
    "# a. 1 variante espèce ... par espèce <8-]\n",
    "assert isinstance(especes, list) or isinstance(especes, int)\n",
    "if isinstance(especes, list):\n",
    "    varEspeces = especes\n",
    "else:\n",
    "    varEspeces = list(dfIndivCounts[dfIndivCounts.Individus >= especes].index)\n",
    "\n",
    "# b. Variantes adultes.\n",
    "varAdultes = ['m', 'm+a'] # Tous les adultes ensemble => 1 variante\n",
    "\n",
    "# c. Variantes passages (= dates, car pas plus d'1 passage par jour).\n",
    "varPassages = [''] # Tous les passages ensemble => 1 variante\n",
    "\n",
    "# c. La spec. des variantes\n",
    "dImplSamples = { 'Espèce': varEspeces, 'Adulte': varAdultes, 'Date': varPassages }\n",
    "dImplSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitation des specs.\n",
    "dfExplSampleSpecs = ads.DSAnalyser.explicitVariantSpecs(odict([('echant_impl', dImplSamples)]))\n",
    "dfExplSampleSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsCatIndiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu de données individualisées.\n",
    "mds = ads.MonoCategoryDataSet(dfObsCatIndiv, dfTransects=dfInventaires, dSurveyArea=dZoneEtude,\n",
    "                              transectPlaceCols=['Transect'], passIdCol='Date', effortCol='Longueur',\n",
    "                              sampleDecFields=['Distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir = pl.Path('transects') / (nomEtude + '-dst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaîne courte d'identification d'une spec. d'échantillon.\n",
    "def sampleAbbreviation(sSample):\n",
    "    \n",
    "    abrvSpe = ''.join(word[:4].title() for word in sSample['Espèce'].split(' ')[:2])\n",
    "    \n",
    "    sampAbbrev = '{}-{}'.format(abrvSpe, sSample.Adulte.replace('+', ''))\n",
    "    \n",
    "    return sampAbbrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Export au format Distance : C\\'est parti ...')\n",
    "\n",
    "# Moteur MCDS pour l'export.\n",
    "mcds = ads.MCDSEngine(workDir=workDir,\n",
    "                      distanceUnit='Meter', areaUnit='Hectare',\n",
    "                      surveyType='Line', distanceType='Perpendicular', clustering=groupage)\n",
    "\n",
    "# Pour chaque échantillon :\n",
    "for sampInd, sSamp in dfExplSampleSpecs.iterrows():\n",
    "    \n",
    "    sampAbbrev = sampleAbbreviation(sSamp)\n",
    "\n",
    "    # Selection des données\n",
    "    sds = mds.sampleDataSet(sSamp)\n",
    "    if not sds:\n",
    "        logger.info('#{:02d} : {} => Pas de données, pas de fichier'.format(sampInd+1, sampAbbrev))\n",
    "        continue\n",
    "\n",
    "    # Export au format Distance\n",
    "    fpn = workDir / f'{nomEtude}-{sampAbbrev}-dist.txt'\n",
    "    fpn = mcds.buildDistanceDataFile(sds, tgtFilePathName=fpn)\n",
    "\n",
    "    logger.info('#{:02d} : {} => {}'.format(sampInd+1, sampAbbrev, fpn.name))\n",
    "\n",
    "# Arrêt moteur.\n",
    "mcds.shutdown()\n",
    "\n",
    "# Terminé.\n",
    "logger.info('Terminé.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Essais de simplification / nettoyage / ... des traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTracesForms = vnds.listTraces()\n",
    "len(dfTracesForms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simplification via algo. de Ramer-Douglas-Peucker\n",
    "\n",
    "=> bof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdp_fw as rdp # Optimised Ramer-Douglas-Peucker algorithm (by https://github.com/FlorianWilhelm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCoordsAvant = dfTracesForms[['obseur_lat', 'obseur_lon']]\n",
    "\n",
    "ax = dfCoordsAvant.plot(x='obseur_lon', y='obseur_lat', figsize=(16, 8))\n",
    "_ = dfCoordsAvant.plot(ax=ax, x='obseur_lon', y='obseur_lat', style='ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfCoordsApres = pd.DataFrame(data=rdp.rdp(dfCoordsAvant.values, 0.0001), columns=['obseur_lat', 'obseur_lon'])\n",
    "\n",
    "ax = dfCoordsApres.plot(x='obseur_lon', y='obseur_lat', figsize=(16, 8))\n",
    "_ = dfCoordsApres.plot(ax=ax, x='obseur_lon', y='obseur_lat', style='ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Modélisation par un polynome, par les moindres carrés\n",
    "\n",
    "https://mmas.github.io/least-squares-fitting-numpy-scipy\n",
    "\n",
    "=> bof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCoordsAvant = dfTracesForms[['obseur_lat', 'obseur_lon']]\n",
    "\n",
    "ax = dfCoordsAvant.plot(x='obseur_lon', y='obseur_lat', figsize=(16, 8))\n",
    "_ = dfCoordsAvant.plot(ax=ax, x='obseur_lon', y='obseur_lat', style='ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynôme de degré N = len(pp)\n",
    "def polyN(x, *pp):\n",
    "    y = 0\n",
    "    for n, p in enumerate(pp):\n",
    "        y += p*x**(len(pp) - n)\n",
    "    return y\n",
    "\n",
    "# Erreur entre donnée (x, y) et son estimée via polyN\n",
    "def residual(pp, x, y):\n",
    "    return y - polyN(x, *pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfCoordsAvant['obseur_lon'].values\n",
    "y = dfCoordsAvant['obseur_lat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "p0 = [1.]*n\n",
    "popt, pcov = optimize.leastsq(residual, p0, args=(x, y))\n",
    "\n",
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = np.linspace(min(x), max(x), 10)\n",
    "yn = polyN(xn, *popt)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(x, y, 'or')\n",
    "plt.plot(xn, yn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Filtrage de Kalman simplifié\n",
    "\n",
    "Pb: inutilisable, on n'a pas les timestamps des points GPS ...\n",
    "\n",
    "NON testé !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalman filter processing for lattitude and longitude\n",
    "# https:#stackoverflow.com/questions/1134579/smooth-gps-data/15657798#15657798\n",
    "class GPSKalmanFilter(object):\n",
    "\n",
    "    def __init__(self, Q_metres_per_second):\n",
    "    \n",
    "        self.Q_metres_per_second = Q_metres_per_second\n",
    "\n",
    "        self.MinAccuracy = 1.\n",
    "    \n",
    "        self.TimeStamp_milliseconds = 0\n",
    "        self.lat = 0.\n",
    "        self.lng = 0.\n",
    "            \n",
    "        # P matrix.  Negative means object uninitialised.\n",
    "        # NB: units irrelevant, as long as same units used throughout\n",
    "        self.variance = -1.\n",
    "\n",
    "    def getTimeStamp(self):\n",
    "        return self.TimeStamp_milliseconds\n",
    "    \n",
    "    def getLat(self):\n",
    "        return self.lat\n",
    "    \n",
    "    def getLng(self):\n",
    "        return self.lng\n",
    "    \n",
    "    def getAccuracy(self):\n",
    "        return Math.sqrt(self.variance)\n",
    "\n",
    "    def setState(lat, lng, accuracy, TimeStamp_milliseconds):\n",
    "        self.lat = lat\n",
    "        self.lng = lng\n",
    "        self.variance = accuracy * accuracy\n",
    "        self.TimeStamp_milliseconds = TimeStamp_milliseconds\n",
    "\n",
    "    def process(lat_measurement, lng_measurement, accuracy, TimeStamp_milliseconds):\n",
    "        \n",
    "        \"\"\"Kalman filter processing for lattitude and longitude\n",
    "        :param nlat_measurement_degrees: new measurement of lattidude\n",
    "        :param lng_measurement: new measurement of longitude\n",
    "        :param accuracy: measurement of 1 standard deviation error in metres\n",
    "        :param TimeStamp_milliseconds: time of measurement\n",
    "        :returns: new state\n",
    "        \"\"\"\n",
    "\n",
    "        if accuracy < self.MinAccuracy:\n",
    "            accuracy = self.MinAccuracy\n",
    "\n",
    "        if self.variance < 0:\n",
    "            # if variance < 0, object is uninitialised, so initialise with current values\n",
    "            self.SetState(lat_measurement, lng_measurement, accuracy*accuracy, TimeStamp_milliseconds)\n",
    "        else:\n",
    "            # else apply Kalman filter methodology\n",
    "            TimeInc_milliseconds = TimeStamp_milliseconds - self.TimeStamp_milliseconds\n",
    "\n",
    "            if TimeInc_milliseconds > 0:\n",
    "                \n",
    "                # time has moved on, so the uncertainty in the current position increases\n",
    "                self.variance += TimeInc_milliseconds * self.Q_metres_per_second * self.Q_metres_per_second / 1000\n",
    "                self.TimeStamp_milliseconds = TimeStamp_milliseconds\n",
    "                # TO DO: USE VELOCITY INFORMATION HERE TO GET A BETTER ESTIMATE OF CURRENT POSITION\n",
    "\n",
    "            # Kalman gain matrix K = Covarariance * Inverse(Covariance + MeasurementVariance)\n",
    "            # NB: because K is dimensionless, it doesn't matter that variance has different units to lat and lng\n",
    "            K = self.variance / (self.variance + accuracy * accuracy)\n",
    "            \n",
    "            # apply K\n",
    "            self.lat += K * (lat_measurement - self.lat)\n",
    "            self.lng += K * (lng_measurement - self.lng)\n",
    "            \n",
    "            # new Covarariance  matrix is (IdentityMatrix - K) * Covarariance\n",
    "            self.variance = (1 - K) * self.variance\n",
    "        \n",
    "def kalmanFilter(coords, Q_metres_per_second):\n",
    "    \n",
    "    kf = GPSKalmanFilter(Q_metres_per_second)\n",
    "    updatedCoords = []\n",
    "\n",
    "    for index in range(len(coords)):\n",
    "        lat, lng, accuracy, timestampInMs = coords[index]\n",
    "        updatedCoords[index] = kalmanFilter.process(lat, lng, accuracy, timestampInMs)\n",
    "        \n",
    "    return updatedCoords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Filtrage de Savitzky-Golay\n",
    "\n",
    "https://plotly.com/python/smoothing/\n",
    "\n",
    "C'est mieux, mais il reste du travail ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avant\n",
    "ax = dfTracesForms.plot(x='obseur_lon', y='obseur_lat', figsize=(16, 8))\n",
    "_ = dfTracesForms.plot(ax=ax, x='obseur_lon', y='obseur_lat', style='ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après\n",
    "winLen = 15 # Must be odd\n",
    "polyOrder = 2\n",
    "\n",
    "dfTracesForms['obseur_lon_sg'] = \\\n",
    "    signal.savgol_filter(dfTracesForms['obseur_lon'].values, window_length=winLen, polyorder=polyOrder)\n",
    "dfTracesForms['obseur_lat_sg'] = \\\n",
    "    signal.savgol_filter(dfTracesForms['obseur_lat'].values, window_length=winLen, polyorder=polyOrder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après\n",
    "ax = dfTracesForms.plot(x='obseur_lon_sg', y='obseur_lat_sg', figsize=(12, 6))\n",
    "_ = dfTracesForms.plot(ax=ax, x='obseur_lon_sg', y='obseur_lat_sg', style='ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOnMap(dfTracesForms.rename(columns={'ID liste': 'formId', 'NumPt': 'ptNum',\n",
    "                                      'obseur_lon_sg': 'lon', 'obseur_lat_sg': 'lat'}),\n",
    "          dfObsListe.rename(columns={'Lon (WGS84)': 'lon', 'Lat (WGS84)': 'lat' }), mapSrc=mdOTM,\n",
    "          trTitle='#{} {}'.format(','.format(idsListe), dfTracesForms.iloc[0]['Commentaire de la liste']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Comparaison traces / géolocs \"réelles\"\n",
    "\n",
    "* entre mes formulaires ACDC 2019 2nd passage, quasi-tous \"avec trace\",\n",
    "* et les géolocs \"de mémoire\" (novembre 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données brutes avec géolocs de mémoire (produites via NB ACDC-donnees-naturalist IV.4)\n",
    "dfObsBrutes = pd.read_excel('ACDC/ACDC2019-Naturalist-ObsBrutesAvecDist.xlsx')\n",
    "dfObsBrutes.drop(dfObsBrutes[dfObsBrutes.Observateur != obser].index, inplace=True)\n",
    "dfObsBrutes[['Num point ACDC', 'Passage', 'Date', 'Heure début', 'lon_mem', 'lat_mem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsBrutes['Num point ACDC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des géolocs de mémoire\n",
    "dfGeolocMem = dfObsBrutes[['Num point ACDC', 'Passage', 'Date', 'Heure début', 'lon_mem', 'lat_mem']] \\\n",
    "                .groupby(['Num point ACDC', 'Passage']).first()\n",
    "dfGeolocMem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traces : Ajouts infos Num point ACDC et Passage\n",
    "# (puisque ID liste spécifiques à Faune XX, différent de ceux de Faune France)\n",
    "dfTraces['Num point ACDC'] = dfTraces['Commentaire de la liste'].apply(lambda s: int(s.split(' ')[1]))\n",
    "dfTraces['Passage'] = dfTraces.Date.apply(lambda ts: 'a' if ts < pd.Timestamp('2019-05-15') else 'b')\n",
    "dfTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Jointure avec les traces (en gardant tous les points et passages effectués, pas seulement ceux avec trace)\n",
    "dfTraces = dfTraces.join(dfGeolocMem[['lon_mem', 'lat_mem']], on=['Num point ACDC', 'Passage'], how='right')\n",
    "dfTraces.reset_index(inplace=True)\n",
    "dfTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des traces du passage a (non dispo. à l'époque)\n",
    "dfTraces.drop(dfTraces[dfTraces.Passage == 'a'].index, inplace=True)\n",
    "dfTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTraces['Num point ACDC'].unique(), dfTraces['Passage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartographie des formulaires\n",
    "mp = folium.Map()\n",
    "folium.TileLayer(**mdSatArcGis).add_to(mp)\n",
    "\n",
    "# Le contrôle pour changer de couche\n",
    "folium.LayerControl().add_to(mp)\n",
    "\n",
    "# Pour chaque point ...\n",
    "for numPoint in sorted(dfTraces['Num point ACDC'].unique()):\n",
    "    \n",
    "    # Les données\n",
    "    dfObsListe = dfObsBrutes[dfObsBrutes['Num point ACDC'] == numPoint]\n",
    "    for indObs, sObs in dfObsListe.iterrows():\n",
    "        mrk = folium.CircleMarker(location=(sObs.lat, sObs.lon), \n",
    "                                  radius=2, color='cyan', fill=True,\n",
    "                                  popup=folium.Popup('#{} {} {} {} {} (code {})' \\\n",
    "                                                     .format(indObs, sObs.Date, sObs.Horaire,\n",
    "                                                             sObs.Nombre, sObs['Nom latin'], sObs['Code atlas'])))\n",
    "        mrk.add_to(mp)\n",
    "    \n",
    "    # La position observateur \"de mémoire\", avec cerles concentriques r=10m + STOC EPS pour l'échelle\n",
    "    dfTracesForms = dfTraces[dfTraces['Num point ACDC'] == numPoint].copy()\n",
    "    \n",
    "    latMem, lonMem = dfTracesForms.iloc[0][['lat_mem', 'lon_mem']]\n",
    "    mrk = folium.CircleMarker(location=(latMem, lonMem), \n",
    "                              radius=6, color='orange', fill=True,\n",
    "                              popup=folium.Popup('#{} Géoloc. de mémoire'.format(numPoint)))\n",
    "    mrk.add_to(mp)\n",
    "    crc = folium.Circle(location=(latMem, lonMem), radius=10, color='orange', weight=1,\n",
    "                        popup=folium.Popup('Rayon 10m'))\n",
    "    crc.add_to(mp)\n",
    "    crc = folium.Circle(location=(latMem, lonMem), radius=25, color='orange', weight=1,\n",
    "                        popup=folium.Popup('Rayon 25m'))\n",
    "    crc.add_to(mp)\n",
    "    crc = folium.Circle(location=(latMem, lonMem), radius=100, color='orange', weight=1,\n",
    "                        popup=folium.Popup('Rayon 100m'))\n",
    "    crc.add_to(mp)\n",
    "    crc = folium.Circle(location=(latMem, lonMem), radius=200, color='orange', weight=1,\n",
    "                        popup=folium.Popup('Rayon 200m'))\n",
    "    crc.add_to(mp)\n",
    "    \n",
    "    # La trace si disponible\n",
    "    dfTracesForms.dropna(subset=['ID liste'], inplace=True)\n",
    "\n",
    "    # a. Les lignes reliant les points\n",
    "    if len(dfTracesForms) > 1:\n",
    "        dfTracesForms['obseur_lon_sfd'] = dfTracesForms.obseur_lon.shift(-1)\n",
    "        dfTracesForms['obseur_lat_sfd'] = dfTracesForms.obseur_lat.shift(-1)\n",
    "\n",
    "        commListe = dfTracesForms.iloc[0]['Commentaire de la liste']\n",
    "        compListe = dfTracesForms.iloc[0]['Liste complète ?']\n",
    "        lines = list(zip(zip(dfTracesForms.obseur_lat, dfTracesForms.obseur_lon),\n",
    "                         zip(dfTracesForms.obseur_lat_sfd, dfTracesForms.obseur_lon_sfd)))[:-1]\n",
    "        pline = folium.PolyLine(lines, color='blue', weight=1, opacity=0.6,\n",
    "                                popup=folium.Popup('#{} {} ({}complète)'.format(numPoint, commListe, '' if compListe else 'in')))\n",
    "        pline.add_to(mp)\n",
    "\n",
    "    # b. Les points\n",
    "    if len(dfTracesForms) > 0:\n",
    "        for _, sPt in dfTracesForms.iterrows():\n",
    "            mrk = folium.CircleMarker(location=(sPt.obseur_lat, sPt.obseur_lon), \n",
    "                                      popup=folium.Popup('#{}: {}'.format(numPoint, sPt.NumPt)),\n",
    "                                      radius=5, weight=2, color='red', fill=True)\n",
    "            mrk.add_to(mp)\n",
    "\n",
    "mp.fit_bounds(mp.get_bounds())\n",
    "\n",
    "# Save map as shareable / web-publishable interactive one.\n",
    "mp.save(f'tmp/ACDC2019b-Points{obserAbbv}-ComparaisonGeolocTraceEtMemoire.html')\n",
    "\n",
    "# Display map.\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Filtrage et cartographie des données et traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn, obser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsSel = dfObs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsSel['Commentaire de la liste'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsSel.Commune.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filtrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Impluvium Volvic 2019 Romain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsSelName = 'impluvium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uniquement les EPOC sur Saint-Ours, Pulvérières, Charbonnières-les-Varennes\n",
    "dfObsSel.drop(dfObsSel[dfObsSel['Commentaire de la liste'].isnull()].index, inplace=True)\n",
    "dfObsSel.drop(dfObsSel[~dfObsSel.Commune.isin(['Saint-Ours', 'Pulvérières', 'Charbonnières-les-Varennes'])].index, inplace=True)\n",
    "\n",
    "dfObsSel.drop(dfObsSel[~dfObsSel['Commentaire de la liste'].str.contains('epoc', case=False)].index, inplace=True)\n",
    "\n",
    "len(dfObsSel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsSel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Forêt de Marcenat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsSelName = 'marcenat03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uniquement les EPOC sur Saint-Didier-la-Forêt, Saint-Rémy-en-Rollat (03)\n",
    "dfObsSel.drop(dfObsSel[~dfObsSel.Commune.isin(['Saint-Didier-la-Forêt', 'Saint-Rémy-en-Rollat'])].index, inplace=True)\n",
    "\n",
    "len(dfObsSel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Planèze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsSelName = 'planeze15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commPlaneze = ['Cussac', 'Neuvéglise', 'Ternes (Les)', 'Sériers',\n",
    "               'Tanavelle', 'Valuéjols', 'Paulhac', 'Villedieu', 'Ussel',\n",
    "               'Coltines', 'Talizat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uniquement les EPOC sur Saint-Didier-la-Forêt, Saint-Rémy-en-Rollat (03)\n",
    "dfObsSel.drop(dfObsSel[~dfObsSel.Commune.isin(commPlaneze)].index, inplace=True)\n",
    "\n",
    "len(dfObsSel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extraction et décodage des traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut donc récupérer trace de chaque liste et en extraire les points individuels\n",
    "formIndCols = ['ID liste', 'Date', 'Liste complète ?', 'Commentaire de la liste']\n",
    "dfTraces = dfObsSel[formIndCols + ['Trace']].groupby(formIndCols).first()\n",
    "dfTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfTraces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def decoderTrace(trace):\n",
    "    return [[float(num) for num in xy.strip().split(' ')] for xy in trace[len('LINESTRING('):-len(')')].split(',')]\n",
    "    \n",
    "dfTraces.Trace = dfTraces.Trace.apply(decoderTrace)\n",
    "dfTraces = dfTraces.Trace.apply(pd.Series).stack().reset_index()\n",
    "dfTraces[['obseur_lon', 'obseur_lat']] = dfTraces.loc[:, 0].apply(pd.Series)\n",
    "dfTraces.drop(columns=[0], inplace=True)\n",
    "dfTraces.rename(columns=dict(level_4='NumPt'), inplace=True)\n",
    "dfTraces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cartographie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsSel.Date.min(), dfObsSel.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les formulaires à traiter et leurs nbres de données\n",
    "dfObsSel[['ID liste', 'Trace']].groupby('ID liste').count().rename(columns=dict(Trace='NbObs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsSel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartographie des formulaires\n",
    "# La carte et les couches\n",
    "mp = folium.Map()\n",
    "folium.TileLayer(**mdSatArcGis).add_to(mp)\n",
    "\n",
    "# Le contrôle pour changer de couche\n",
    "folium.LayerControl().add_to(mp)\n",
    "\n",
    "# Pour chaque formulaire sélectionné\n",
    "for idListe in sorted(dfTraces['ID liste'].unique()):\n",
    "    \n",
    "    # Les données\n",
    "    dfObsListe = dfObsSel[dfObsSel['ID liste'] == idListe]\n",
    "    for indObs, sObs in dfObsListe.iterrows():\n",
    "        mrk = folium.CircleMarker(location=(sObs['Lat (WGS84)'], sObs['Lon (WGS84)']), \n",
    "                                  radius=4, color='cyan', fill=True,\n",
    "                                  popup=folium.Popup('#{} {} {} {} {} (code {})' \\\n",
    "                                                     .format(indObs, sObs.Date, sObs.Horaire,\n",
    "                                                             sObs.Nombre, sObs['Nom latin'], sObs['Code atlas'])))\n",
    "        mrk.add_to(mp)\n",
    "    \n",
    "    # La position observateur estimée, avec cerles concentriques r=10m + STOC EPS pour l'échelle\n",
    "    #latMem, lonMem = dfTracesForms.iloc[0][['lat_mem', 'lon_mem']]\n",
    "    #mrk = folium.CircleMarker(location=(latMem, lonMem), \n",
    "    #                          radius=6, color='orange', fill=True,\n",
    "    #                          popup=folium.Popup('#{} Géoloc. de mémoire'.format(numPoint)))\n",
    "    #mrk.add_to(mp)\n",
    "    #crc = folium.Circle(location=(latMem, lonMem), radius=10, color='orange', weight=1,\n",
    "    #                    popup=folium.Popup('Rayon 10m'))\n",
    "    #crc.add_to(mp)\n",
    "    #crc = folium.Circle(location=(latMem, lonMem), radius=25, color='orange', weight=1,\n",
    "    #                    popup=folium.Popup('Rayon 25m'))\n",
    "    #crc.add_to(mp)\n",
    "    #crc = folium.Circle(location=(latMem, lonMem), radius=100, color='orange', weight=1,\n",
    "    #                    popup=folium.Popup('Rayon 100m'))\n",
    "    #crc.add_to(mp)\n",
    "    #crc = folium.Circle(location=(latMem, lonMem), radius=200, color='orange', weight=1,\n",
    "    #                    popup=folium.Popup('Rayon 200m'))\n",
    "    #crc.add_to(mp)\n",
    "    \n",
    "    # La trace\n",
    "    dfTracesForms = dfTraces[dfTraces['ID liste'] == idListe].copy()\n",
    "    \n",
    "    # a. Les lignes reliant les points\n",
    "    if len(dfTracesForms) > 1:\n",
    "        dfTracesForms['obseur_lon_sfd'] = dfTracesForms.obseur_lon.shift(-1)\n",
    "        dfTracesForms['obseur_lat_sfd'] = dfTracesForms.obseur_lat.shift(-1)\n",
    "\n",
    "        commListe = dfTracesForms.iloc[0]['Commentaire de la liste']\n",
    "        lines = list(zip(zip(dfTracesForms.obseur_lat, dfTracesForms.obseur_lon),\n",
    "                         zip(dfTracesForms.obseur_lat_sfd, dfTracesForms.obseur_lon_sfd)))[:-1]\n",
    "        pline = folium.PolyLine(lines, color='blue', weight=2, opacity=0.6,\n",
    "                                popup=folium.Popup('#{} {}'.format(idListe, commListe)))\n",
    "        pline.add_to(mp)\n",
    "\n",
    "    # b. Les points\n",
    "    if len(dfTracesForms) > 0:\n",
    "        for _, sPt in dfTracesForms.iterrows():\n",
    "            mrk = folium.CircleMarker(location=(sPt.obseur_lat, sPt.obseur_lon), \n",
    "                                      popup=folium.Popup('#{}: {}'.format(idListe, sPt.NumPt)),\n",
    "                                      radius=3, weight=2, color='red', fill=True)\n",
    "            mrk.add_to(mp)\n",
    "\n",
    "mp.fit_bounds(mp.get_bounds())\n",
    "\n",
    "# Display map.\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save map as shareable / web-publishable interactive one.\n",
    "mFn = pl.Path(fn).with_suffix(f'.{obsSelName}.html')\n",
    "mp.save(str(mFn))\n",
    "\n",
    "HTML(f'<a href=\"{mFn}\" target=\"_blank\">{mFn}</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Cartographie des communes d'une sélection de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement d'un fichier des sites à peu près à jour\n",
    "dfSites = pd.read_csv('tmp/SitesFA-20190522.csv', sep='\\t', skiprows=1)\n",
    "dfSites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCommunes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Et voici en gros la mairie de chaque commune.\n",
    "dfCommunes = dfSites[dfSites.Nom == dfSites.Commune.apply(lambda s: s + ' (bourg)')]\n",
    "len(dfCommunes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage\n",
    "dfCommunesSel = dfCommunes[dfCommunes.Commune.isin(dfObsSel.Commune.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ou pas filtrage\n",
    "dfCommunesSel = dfCommunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# La carte et les couches\n",
    "mp = folium.Map()\n",
    "folium.TileLayer(**mdSatArcGis).add_to(mp)\n",
    "\n",
    "# Le contrôle pour changer de couche\n",
    "folium.LayerControl().add_to(mp)\n",
    "\n",
    "# Pour chaque formulaire sélectionné\n",
    "for _, sCom in dfCommunesSel.iterrows():\n",
    "    \n",
    "    # La position observateur estimée, avec cerles concentriques r=10m + STOC EPS pour l'échelle\n",
    "    mrk = folium.CircleMarker(location=sCom[['Latitude (D.d)', 'Longitude (D.d)']], \n",
    "                              radius=10, color='fuchsia', fill=True,\n",
    "                              popup=folium.Popup('{} - {:02d} ({}m)'.format(sCom.Nom, int(sCom.INSEE)//1000, sCom.Altitude)))\n",
    "    mrk.add_to(mp)\n",
    "    \n",
    "mp.fit_bounds(mp.get_bounds())\n",
    "\n",
    "# Display map.\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Tests du module visionature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests unitaires automatisés intégrés au module : python visionature.py -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F. Archives : Exploitation traces formulaires\n",
    "\n",
    "Ancien code industrialisé dans module **visionat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Projeteurs WGS84 et UTM31, et transformeur du 1er au 2nd.\n",
    "KProjWgs84 = pyproj.Proj(init='epsg:4326') # WGS 84 : long, lat en degrés\n",
    "KProjUtm31  = pyproj.Proj(init='epsg:32631') # WGS 84 - UTM 31N : long, lat en m\n",
    "\n",
    "KTransformer = pyproj.Transformer.from_proj(KProjWgs84, KProjUtm31)\n",
    "\n",
    "# Conversion WGS84 (long, lat en degrés) => UTM31 (x, y en m)\n",
    "def wgs84toUtm(sLonLat):\n",
    "    return pd.Series(KTransformer.transform(sLonLat[0], sLonLat[1]))\n",
    "\n",
    "# Fonction de calcul de distance sphérique\n",
    "#def sphericalDistance(aLon1, aLat1, aLon2, aLat2):\n",
    "#\n",
    "#    aX1, aY1 = KTransformer.transform(aLon1, aLat1)\n",
    "#\n",
    "#    aX2, aY2 = KTransformer.transform(aLon2, aLat2)\n",
    "#\n",
    "#    return np.hypot(aX2 - aX1, aY2 - aY1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Chargement des données (exports de Faune-France)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Paramètres d'import / filtrage (fichier, observateur, commentaire liste, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracesManu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACDC 2019 JPM (en fait, trace enregistrée uniquement sur le 2nd passage, et pour 15 points sur 17)\n",
    "fn = 'tmp/ACDC2019-Naturalist-FormulairesJPM2019040720190602ff.xlsx'\n",
    "obser, obserAbbv = 'Jean-Philippe Meuret', 'JPM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulaires Romain avec trace du 25/05/2019 au 25/01/2020 (tous)\n",
    "# * Impluvium: \"epoc\" & Saint-Ours, Pulvérières, Charbonnière-les-Varennes\n",
    "# * et le reste : des EPOC et des transects\n",
    "fn = 'tmp/FormulairesRR-traces-20190525-20200125ff.xlsx'\n",
    "comntRE = 'ACDC'\n",
    "obser, obserAbbv = 'Romain Riols', 'RR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACDC 2019 Romain 25/05/2019\n",
    "fn = 'tmp/ACDC2019-Naturalist-FormulairesRR20190425ff.xlsx'\n",
    "comntRE = 'ACDC'\n",
    "obser, obserAbbv = 'Romain Riols', 'RR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JPM jardin 23/05/2019\n",
    "#fn = f'tmp/NaturalistTestTrace-JardinJPM20190523ff.xlsx'\n",
    "#comntRegexp = '???'\n",
    "#obser, obserAbbv = 'Jean-Philippe Meuret', 'JPM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transects Vergers de Tallende Cyrille printemps 2020\n",
    "fn = 'transects/ExportTransects2020T2-CJS-FF.xlsx'\n",
    "comntRE = 'verger.*tallende'\n",
    "obser, obserAbbv = 'Cyrille Jallageas', 'CJS'\n",
    "tracesManu = False # Loaded from KML, not Naturalist traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier\n",
    "dfObs = pd.read_excel(fn)\n",
    "len(dfObs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage colonnes inutiles\n",
    "#dfObs.drop(columns=[col for col in dfObs.columns if col.startswith('SEARCH_EXPORT')], inplace=True)\n",
    "#dfObs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aperçu\n",
    "obsCols = ['ID liste', 'Liste complète ?', 'Commentaire de la liste',\n",
    "           'Date', 'Horaire', 'Lieu-dit', 'Commune', 'Nom espèce',\n",
    "           'Estimation', 'Nombre', 'Détails', 'Code atlas',\n",
    "           'Lat (WGS84)', 'Lon (WGS84)', 'UTM X [m]', 'UTM Y [m]',\n",
    "           'Remarque', 'Remarque privée', 'Trace']\n",
    "\n",
    "dfObs = dfObs[obsCols]\n",
    "dfObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs['Commentaire de la liste'].nunique(), dfObs['Commentaire de la liste'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Filtrage des données\n",
    "\n",
    "* formulaires\n",
    "* avec commentaire ad-hoc (si spécifié via comntRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = dfObs.drop(dfObs[dfObs['Commentaire de la liste'].isnull()].index)\n",
    "#df[~df['Commentaire de la liste'].str.contains(comntRE, case=False)]['Commentaire de la liste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquement les données des formulaires\n",
    "dfObs.drop(dfObs[dfObs['ID liste'] == 0].index, inplace=True)\n",
    "len(dfObs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquement les données respectant le critère de commentaire liste\n",
    "if comntRE:\n",
    "    dfObs.drop(dfObs[dfObs['Commentaire de la liste'].isnull()].index, inplace=True)\n",
    "    dfObs.drop(dfObs[~dfObs['Commentaire de la liste'].str.contains(comntRE, case=False)].index,\n",
    "               inplace=True)\n",
    "len(dfObs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniquement ceux avec trace si on ne les a pas par ailleurs\n",
    "if not tracesManu:\n",
    "    dfObs.drop(dfObs[dfObs['Trace'].isnull()].index, inplace=True)\n",
    "\n",
    "len(dfObs[obsCols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Autres filtrages / traitements spécifiques des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transects de Cyrille dans les vergers de Tallende au printemps 2020\n",
    "\n",
    "* filtrage du 1er transect pour en faire un transect nord décent\n",
    "* ajout colonne \"transect\" (Nord, Sud1, Sud2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs[(dfObs['Date'] == '2020-03-28') & (dfObs['Horaire'] > '09:40')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sLabels2Drop = dfObs[(dfObs['Date'] == '2020-03-28') & (dfObs['Horaire'] > '09:40')].index\n",
    "dfObs.drop(sLabels2Drop, inplace=True)\n",
    "\n",
    "len(dfObs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs['Transect'] = \\\n",
    "    dfObs['Commentaire de la liste'].apply(lambda s: 'Sud' if s.lower().find('transect s') >= 0 else 'Nord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(dfObs[['ID liste', 'Transect']].drop_duplicates() == vnds.dfData[['ID liste', 'Transect']].drop_duplicates()).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Examen des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toutes des listes complètes ?\n",
    "dfObs[dfObs['Liste complète ?'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier que la trace de chaque liste est présente à l'identique dans toutes les données de la liste\n",
    "assert all(dfObs[['ID liste', 'Trace']].groupby('ID liste').nunique().Trace == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les formulaires à traiter\n",
    "dfObs[['ID liste', 'Liste complète ?', 'Commentaire de la liste', 'Trace']].groupby('ID liste').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les formulaires à traiter : nbres de données\n",
    "dfObs[['ID liste', 'Date', 'Trace']].groupby(['Date', 'ID liste']).count().Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbre de données transect sud\n",
    "dfObs.loc[dfObs['Commentaire de la liste'].str.contains('transect s', case=False)].groupby(['Date', 'ID liste']) \\\n",
    "     .count().Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne\n",
    "dfObs.loc[dfObs['Commentaire de la liste'].str.contains('transect s', case=False)].groupby(['Date', 'ID liste']) \\\n",
    "     .count().Trace.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbre de données transect nord\n",
    "dfObs.loc[dfObs['Commentaire de la liste'].str.contains('transect n', case=False)].groupby(['Date', 'ID liste']) \\\n",
    "     .count().Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne\n",
    "dfObs.loc[dfObs['Commentaire de la liste'].str.contains('transect n', case=False)].groupby(['Date', 'ID liste']) \\\n",
    "     .count().Trace.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Extraction et décodage des traces GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut donc récupérer la trace de chaque liste et en extraire les points individuels\n",
    "formIndCols = ['ID liste', 'Date', 'Liste complète ?', 'Commentaire de la liste']\n",
    "dfForms = dfObs[formIndCols + ['Trace']].groupby(formIndCols).first()\n",
    "dfForms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de trace\n",
    "dfForms.iloc[0].Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def decoderTrace(trace):\n",
    "    if pd.isnull(trace):\n",
    "        return []\n",
    "    else:\n",
    "        return [[float(num) for num in xy.strip().split(' ')] \\\n",
    "                for xy in trace[len('LINESTRING('):-len(')')].split(',')]\n",
    "    \n",
    "dfTracesGps = dfForms.copy()\n",
    "\n",
    "dfTracesGps.Trace = dfTracesGps.Trace.apply(decoderTrace)\n",
    "dfTracesGps = dfTracesGps.Trace.apply(pd.Series).stack().reset_index()\n",
    "dfTracesGps[['obseur_lon', 'obseur_lat']] = dfTracesGps.loc[:, 0].apply(pd.Series)\n",
    "dfTracesGps.drop(columns=[0], inplace=True)\n",
    "dfTracesGps.rename(columns=dict(level_4='NumPt'), inplace=True)\n",
    "dfTracesGps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des coordonnées UTM 31 (métriques) de la trace.\n",
    "dfTracesGps[['obseur_lon_utm', 'obseur_lat_utm']] = \\\n",
    "    dfTracesGps[['obseur_lon', 'obseur_lat']].apply(wgs84toUtm, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTracesGps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Filtrages spécifiques des traces GPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transects de Cyrille dans les vergers de Tallende au printemps 2020\n",
    "\n",
    "Couper le 1er transect pour qu'il colle bien avec les transects nord des jours suivants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTracesGps[(dfTracesGps.Date == '2020-03-28') & ~(dfTracesGps.NumPt.between(8, 170))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sLabels2Drop = dfTracesGps[(dfTracesGps.Date == '2020-03-28') & ~(dfTracesGps.NumPt.between(8, 171))].index\n",
    "dfTracesGps.drop(sLabels2Drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTracesGps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Chargement des vrais parcours des transects\n",
    "\n",
    "(tracés précisément à la main via GeoPortail ... pas de pb avec l'imprécision du GPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmlNameSpaces = \\\n",
    "  { 'gx' : 'http://www.google.com/kml/ext/2.2',\n",
    "    'kml' : 'http://www.opengis.net/kml/2.2',\n",
    "    'atom' : 'http://www.w3.org/2005/Atom' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transects de Cyrille dans les vergers de Tallende au printemps 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transect nord\n",
    "if tracesManu:\n",
    "\n",
    "    kmlRoot = etree.ElementTree().parse('transects/TransectNord-VergersTallende-CJS-2020T2.kml')\n",
    "\n",
    "    plMark = kmlRoot.find('kml:Document/kml:Placemark', namespaces=kmlNameSpaces)\n",
    "    transLine = plMark.find('kml:LineString/kml:coordinates',\n",
    "                           namespaces=kmlNameSpaces).text.strip()\n",
    "    dfTransN = pd.DataFrame(data=[[float(v) for v in point.split(',')] for point in transLine.split(' ')],\n",
    "                            columns=['obseur_lon', 'obseur_lat'])\n",
    "    dfTransN = dfTransN.reset_index().rename(columns=dict(index='NumPt'))\n",
    "\n",
    "    print(len(dfTransN), dfTransN.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transect sud\n",
    "if tracesManu:\n",
    "    \n",
    "    kmlRoot = etree.ElementTree().parse('transects/TransectSud-VergersTallende-CJS-2020T2.kml')\n",
    "\n",
    "    plMark = kmlRoot.find('kml:Document/kml:Placemark', namespaces=kmlNameSpaces)\n",
    "    transLine = plMark.find('kml:LineString/kml:coordinates',\n",
    "                           namespaces=kmlNameSpaces).text.strip()\n",
    "    dfTransS = pd.DataFrame(data=[[float(v) for v in point.split(',')] for point in transLine.split(' ')],\n",
    "                            columns=['obseur_lon', 'obseur_lat'])\n",
    "    dfTransS = dfTransS.reset_index().rename(columns=dict(index='NumPt'))\n",
    "    \n",
    "    print(len(dfTransS), dfTransS.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tracesManu:\n",
    "    \n",
    "    dfTransN['Transect'] = 'Nord'\n",
    "    dfTransS['Transect'] = 'Sud'\n",
    "    dfTracesManu = dfTransN.append(dfTransS, ignore_index=True)\n",
    "\n",
    "    print(dfTracesManu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des coordonnées UTM 31 (métriques) des traces.\n",
    "if tracesManu:\n",
    "    \n",
    "    dfTracesManu[['obseur_lon_utm', 'obseur_lat_utm']] = \\\n",
    "        dfTracesManu[['obseur_lon', 'obseur_lat']].apply(wgs84toUtm, axis='columns')\n",
    "    \n",
    "    print(dfTracesManu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Tracé cartographique des données de formulaires et de leur trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(', '.join(\"'{}'\".format(date.date()) for date in dfObs.Date.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sélection des listes à tracer en même temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soit en dur.\n",
    "idsListe = [876746] #[955938, 956038] #[880581, 880582] #[876746]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs.groupby('Date').apply(lambda df: list(df['ID liste'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soit: Iteration sur les jours : liste des IDs de formulaires chaque jour\n",
    "itDates = iter(dfObs.groupby('Date').apply(lambda df: list(df['ID liste'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsListe = next(itDates)\n",
    "idsListe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extraction des points des traces du jour et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tracesManu:\n",
    "    dfTracesForms = pd.DataFrame()\n",
    "    for idListe in idsListe:\n",
    "        comntListe = dfTracesGps[dfTracesGps['ID liste'] == idListe].iloc[0]['Commentaire de la liste']\n",
    "        transect = 'Sud' if comntListe.lower().find('transect s') >= 0 else 'Nord'\n",
    "        dfTraceManu = dfTracesManu[dfTracesManu.Transect == transect].copy()\n",
    "        dfTraceManu['ID liste'] = idListe\n",
    "        dfTraceManu['Commentaire de la liste'] = comntListe\n",
    "        dfTracesForms = dfTracesForms.append(dfTraceManu, ignore_index=True,)\n",
    "else:\n",
    "    dfTracesForms = dfTracesGps.loc[dfTraces['ID liste'].isin(idsListe)].copy()\n",
    "\n",
    "len(dfTracesForms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObsListe = dfObs.loc[dfObs['ID liste'].isin(idsListe),\n",
    "                       ['Lon (WGS84)', 'Lat (WGS84)', 'Date', 'Horaire', 'Nom espèce', 'Nombre', 'Code atlas']]\n",
    "len(dfObsListe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTracesForms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tracé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showOnMap(dfTracesForms.rename(columns={'ID liste': 'formId', 'NumPt': 'ptNum',\n",
    "                                      'obseur_lon': 'lon', 'obseur_lat': 'lat'}),\n",
    "          dfObsListe.rename(columns={'Lon (WGS84)': 'lon', 'Lat (WGS84)': 'lat' }), mapSrc=mdOTM,\n",
    "          trTitle='#{} {}'.format(','.format(idsListe), dfTracesForms.iloc[0]['Commentaire de la liste']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Calcul des distances observateur - oiseau\n",
    "\n",
    "(la distance minimale entre l'oiseau et la poly-ligne du transect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTransPolyLines = dict()\n",
    "def transectPolyLine(sObs):\n",
    "\n",
    "    if tracesManu:\n",
    "        \n",
    "        transect = sObs['Transect']\n",
    "        if transect not in DTransPolyLines:\n",
    "            dfTransTrace = dfTracesManu.loc[dfTracesManu.Transect == transect, ['obseur_lon_utm', 'obseur_lat_utm']]\n",
    "            DTransPolyLines[transect] = \\\n",
    "                geometry.LineString([(x, y) for x, y in dfTransTrace.itertuples(index=False)])\n",
    "            \n",
    "    else:\n",
    "\n",
    "        transect = sObs['ID liste']\n",
    "        if idListe not in DTransPolyLines:\n",
    "            dfTransTrace = dfTracesGps.loc[dfTracesGps['ID liste'] == transect, ['obseur_lon_utm', 'obseur_lat_utm']]\n",
    "            DTransPolyLines[transect] = \\\n",
    "                geometry.LineString([(x, y) for x, y in dfTransTrace.itertuples(index=False)])\n",
    "        \n",
    "    return DTransPolyLines[transect]\n",
    "\n",
    "def distance2Transect(sObs):\n",
    "    \n",
    "    return geometry.Point(sObs['UTM X [m]'], sObs['UTM Y [m]']).distance(transectPolyLine(sObs))\n",
    "    \n",
    "dfObs['Distance'] = \\\n",
    "    dfObs[['ID liste', 'Transect', 'UTM X [m]', 'UTM Y [m]',]].apply(distance2Transect, axis='columns')\n",
    "\n",
    "dfObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs[dfObs['ID liste'] == idListe].Distance.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfObs.Distance.hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G. Archives : Essai extraction traces via format JSON / XML\n",
    "\n",
    "(avant de savoir qu'elles n'y sont sont pas, le 25/01/2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src = 'fa'\n",
    "src = 'ff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'tmp/ACDC2019-Naturalist-FormulairesJPM2019040720190602{src}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'tmp/NaturalistTestTrace-JardinJPM20190523{src}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'tmp/NaturalistTestTrace-FormRomainsAutHiv201920fa.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dObsTr = json.load(open(fn))\n",
    "type(dObsTr), type(dObsTr['data']), dObsTr['data'].keys(), type(dObsTr['data']['forms']), type(dObsTr['data']['sightings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(nbFormulaires=len(dObsTr['data']['forms']), nbObsHorsFormulaires=len(dObsTr['data']['sightings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dObsTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dObsTr['data']['forms'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dForm in dObsTr['data']['forms']:\n",
    "    print(dForm['@id'], ':', dForm['time_start'], dForm['time_stop'], dForm['lat'], dForm['lon'],\n",
    "                             dForm.get('comment', ''), '=>', len(dForm['sightings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenForm(form):\n",
    "    flat = odict()\n",
    "    for k, v in form.items():\n",
    "        if k == 'sightings':\n",
    "            continue\n",
    "        if isinstance(v, dict):\n",
    "            for sk, sv in v.items():\n",
    "                if k != 'protocol' or sk == 'protocol_name':\n",
    "                    flat.update(**{ 'form_'+k+'_'+sk: sv})\n",
    "        else:\n",
    "            flat.update(**{ 'form_'+k: v})\n",
    "    return flat\n",
    "\n",
    "dfForms = pd.DataFrame(data=[flattenForm(form) for form in dObsTr['data']['forms']])\n",
    "dfForms.set_index('form_@id', inplace=True)\n",
    "dfForms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenSight(sight, formId):\n",
    "    flat = odict([('form_@id', formId)])\n",
    "    for k, v in sight.items():\n",
    "        if isinstance(v, list):\n",
    "            v = v[0]\n",
    "        for sk, sv in v.items():\n",
    "            if isinstance(sv, dict):\n",
    "                for ssk, ssv in sv.items():\n",
    "                    flat.update(**{ k+'_'+sk+'_'+ssk: ssv})\n",
    "            else:\n",
    "                flat.update(**{ k+'_'+sk: sv})\n",
    "    return flat\n",
    "\n",
    "ldfSights = list()\n",
    "for form in dObsTr['data']['forms']:\n",
    "    dfSights = pd.DataFrame(data=[flattenSight(sight, form['@id']) for sight in form['sightings']])\n",
    "    dfSights = dfSights.join(dfForms, on=['form_@id'])\n",
    "    ldfSights.append(dfSights)\n",
    "    \n",
    "dfSights = pd.concat(ldfSights, sort=False, ignore_index=True)\n",
    "dfSights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'form_protocol_protocol_name' in dfSights.columns:\n",
    "    dfSights.drop(dfSights[dfSights['form_protocol_protocol_name'] == 'STOC_EPS'].index, inplace=True)\n",
    "dfSights['form_comment'].fillna('', inplace=True)\n",
    "dfSights.drop(dfSights[~dfSights['form_comment'].str.contains('ACDC', case=False)].index, inplace=True)\n",
    "\n",
    "dfSights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSights['date_@ISO8601'].min(), dfSights['date_@ISO8601'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSights[['form_@id']+[col for col in dfSights.columns if col.endswith('lat') or col.endswith('lon')]].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([dict(a=1, b=2), dict(a=3, b=4), dict(a=5, b=6)], index=[1, 2, 3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dIdList2Trans = { 876746: 'Nord',\n",
    "                  880581: 'Nord', 880582: 'Sud', 888657: 'Nord', 888658: 'Sud',\n",
    "                  893072: 'Nord', 893073: 'Sud', 907198: 'Nord', 907199: 'Sud',\n",
    "                  926044: 'Nord', 926208: 'Sud', 938061: 'Nord', 938221: 'Sud',\n",
    "                  945756: 'Nord', 946015: 'Sud', 955938: 'Nord', 956038: 'Sud',\n",
    "                  964083: 'Nord', 964213: 'Sud', 999946: 'Nord', 999947: 'Sud' }\n",
    "if not tracesManu:\n",
    "    del dIdList2Trans[926044]\n",
    "\n",
    "dIdList2Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Chargement des fichiers KML et passage des DataFrame ad-hoc au module\n",
    "print('Setting new GPS traces (one trace table per list) ...')\n",
    "ddfTransects = dict()\n",
    "for trans in set(dIdList2Trans.values()):\n",
    "    kmlRoot = etree.ElementTree().parse(f'transects/Transect{trans}-VergersTallende-CJS-2020T2.kml')\n",
    "    plMark = kmlRoot.find('kml:Document/kml:Placemark', namespaces=kmlNameSpaces)\n",
    "    transLine = plMark.find('kml:LineString/kml:coordinates',\n",
    "                           namespaces=kmlNameSpaces).text.strip()\n",
    "    dfTrans = pd.DataFrame(data=[[float(v) for v in point.split(',')] for point in transLine.split(' ')],\n",
    "                           columns=['lon', 'lat'])\n",
    "    dfTrans = dfTrans.reset_index().rename(columns=dict(index='ptIndx'))\n",
    "    print('Transect \"{}\": {} points'.format(trans, len(dfTrans)))\n",
    "    ddfTransects[trans] = dfTrans\n",
    "\n",
    "dTraces = { lstId: ddfTransects[trans] for lstId, trans in dIdList2Trans.items() }\n",
    "\n",
    "vnds.setListTraces(dTraces)\n",
    "\n",
    "dfTracesGps = vnds.listTraces()\n",
    "\n",
    "dfTracesGps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Soin au module de charger lui-même les fichiers\n",
    "print('Setting new GPS traces (one trace KML file per list) ...')\n",
    "dTraces = { lstId: f'transects/Transect{transect}-VergersTallende-CJS-2020T2.kml' \\\n",
    "            for lstId, transect in dIdList2Trans.items() }\n",
    "\n",
    "vnds.setListTraces(dTraces)\n",
    "\n",
    "dfTracesGps2 = vnds.listTraces()\n",
    "\n",
    "dfTracesGps2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCodesAtlas = pd.read_csv('visionat/VisioNatureCodesAtlas.txt', sep='\\t',\n",
    "                            index_col=0, usecols=['Codes Biolovision', 'Texte FR'])\n",
    "dfCodesAtlas.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"3.1300199031829834,45.66334557709624 3.1302559375762935,45.66330808661448 3.130652904510498,45.66317312067224 3.1309103965759277,45.66306814693661 3.1310713291168213,45.663030656269086 3.13135027885437,45.66300066371696 3.1315112113952637,45.6629781692923 3.1320691108703613,45.662618257268974 3.1323266029357915,45.66252827890162 3.133056163787842,45.66231832881542 3.1333351135253906,45.66222834996603 3.133699893951416,45.66215336748104 3.1348907947540283,45.662070886631625 3.1362748146057133,45.66198840566065 3.1373798847198486,45.66195091427005 3.1380558013916016,45.661905924568174 3.138549327850342,45.66192092113948 3.1392788887023926,45.66198090738453 3.1398689746856694,45.66206338836653\"\n",
    "' '.join(reversed(s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
